{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "PERCENTILE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net,self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                nn.Linear(obs_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation','action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([1.0,2.0,3.0,4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = x.data.numpy()[0]\n",
    "smm = nn.Softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0321, 0.0871, 0.2369, 0.6439])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = smm(x)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0320586 , 0.08714432, 0.23688284, 0.6439143 ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(env, net, batch_size):\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs=env.reset()\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "#         env.render()\n",
    "        \n",
    "        obs_v = torch.FloatTensor([obs])\n",
    "        act_probs_v = sm(net(obs_v))\n",
    "        act_probs = act_probs_v.data.numpy()[0]\n",
    "        \n",
    "        action = np.random.choice(len(act_probs), p = act_probs)\n",
    "        next_obs, rew, is_done, _ = env.step(action)\n",
    "        \n",
    "        episode_reward+=rew\n",
    "        episode_steps.append(EpisodeStep(observation = obs, action = action))\n",
    "        \n",
    "        if is_done:\n",
    "            \n",
    "#             print(episode_reward)\n",
    "            \n",
    "            batch.append(Episode(reward = episode_reward, steps = episode_steps))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps=[]\n",
    "            next_obs = env.reset()\n",
    "            if len(batch)==batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "             \n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch, percentile):\n",
    "    rewards = list(map(lambda s:s.reward, batch))\n",
    "    reward_bound = np.percentile(rewards, percentile)\n",
    "    reward_mean = float(np.mean(rewards))\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    for example in batch:\n",
    "        if example.reward<reward_bound:\n",
    "            continue\n",
    "        train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "        train_act.extend(map(lambda step: step.action, example.steps))\n",
    "    \n",
    "    train_obs_v = torch.FloatTensor(train_obs)\n",
    "    train_act_v = torch.LongTensor(train_act)\n",
    "    return train_obs_v, train_act_v, reward_bound, reward_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main run\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params = net.parameters(), lr=0.01)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=0.691, reward_mean=20.3, reward_bound=23.5\n",
      "1: loss=0.676, reward_mean=25.3, reward_bound=33.0\n",
      "2: loss=0.678, reward_mean=33.6, reward_bound=41.5\n",
      "3: loss=0.666, reward_mean=32.4, reward_bound=36.0\n",
      "4: loss=0.659, reward_mean=27.1, reward_bound=29.0\n",
      "5: loss=0.658, reward_mean=39.9, reward_bound=38.5\n",
      "6: loss=0.639, reward_mean=43.5, reward_bound=59.5\n",
      "7: loss=0.645, reward_mean=49.1, reward_bound=62.0\n",
      "8: loss=0.639, reward_mean=57.2, reward_bound=76.5\n",
      "9: loss=0.634, reward_mean=62.5, reward_bound=64.0\n",
      "10: loss=0.631, reward_mean=62.4, reward_bound=69.5\n",
      "11: loss=0.611, reward_mean=57.4, reward_bound=69.5\n",
      "12: loss=0.625, reward_mean=69.8, reward_bound=85.5\n",
      "13: loss=0.608, reward_mean=76.4, reward_bound=91.5\n",
      "14: loss=0.606, reward_mean=78.9, reward_bound=86.0\n",
      "15: loss=0.608, reward_mean=103.5, reward_bound=117.0\n",
      "16: loss=0.598, reward_mean=84.7, reward_bound=107.0\n",
      "17: loss=0.587, reward_mean=83.2, reward_bound=94.5\n",
      "18: loss=0.599, reward_mean=101.4, reward_bound=130.5\n",
      "19: loss=0.584, reward_mean=104.2, reward_bound=112.0\n",
      "20: loss=0.574, reward_mean=125.4, reward_bound=151.5\n",
      "21: loss=0.563, reward_mean=127.1, reward_bound=131.5\n",
      "22: loss=0.577, reward_mean=135.1, reward_bound=145.5\n",
      "23: loss=0.565, reward_mean=137.6, reward_bound=162.5\n",
      "24: loss=0.551, reward_mean=150.8, reward_bound=198.0\n",
      "25: loss=0.557, reward_mean=161.2, reward_bound=200.0\n",
      "26: loss=0.560, reward_mean=154.8, reward_bound=167.5\n",
      "27: loss=0.545, reward_mean=164.2, reward_bound=200.0\n",
      "28: loss=0.542, reward_mean=157.1, reward_bound=200.0\n",
      "29: loss=0.534, reward_mean=161.1, reward_bound=195.5\n",
      "30: loss=0.542, reward_mean=176.3, reward_bound=200.0\n",
      "31: loss=0.532, reward_mean=180.9, reward_bound=200.0\n",
      "32: loss=0.529, reward_mean=181.6, reward_bound=200.0\n",
      "33: loss=0.517, reward_mean=171.4, reward_bound=200.0\n",
      "34: loss=0.529, reward_mean=192.6, reward_bound=200.0\n",
      "35: loss=0.529, reward_mean=187.1, reward_bound=200.0\n",
      "36: loss=0.521, reward_mean=191.0, reward_bound=200.0\n",
      "37: loss=0.514, reward_mean=197.4, reward_bound=200.0\n",
      "38: loss=0.518, reward_mean=194.1, reward_bound=200.0\n",
      "39: loss=0.502, reward_mean=195.8, reward_bound=200.0\n",
      "40: loss=0.509, reward_mean=199.1, reward_bound=200.0\n",
      "Solved!\n"
     ]
    }
   ],
   "source": [
    "#loop through\n",
    "for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "    obs_v, act_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)\n",
    "    optimizer.zero_grad()\n",
    "    action_scores_v = net(obs_v)\n",
    "    loss_v = objective(action_scores_v, act_v)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    print(\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f\" % (iter_no, loss_v.item(), reward_m, reward_b))\n",
    "    writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "    writer.add_scalar(\"reward_bound\", reward_b, iter_no)\n",
    "    writer.add_scalar(\"reward_mean\", reward_m, iter_no)\n",
    "    \n",
    "    if reward_m > 199:\n",
    "        print(\"Solved!\")\n",
    "        break\n",
    "        writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_trained = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_obs = env.observation_space.sample()\n",
    "sample_obs_v = torch.FloatTensor([sample_obs])\n",
    "sm = nn.Softmax(dim=1)\n",
    "sample_action_prob = sm(net_trained(sample_obs_v))\n",
    "sample_action_probx = sm(net(sample_obs_v))\n",
    "sample_action_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9729e+00, -7.5835e+37,  2.5635e-02,  2.3618e+38]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_obs = env.observation_space.sample()\n",
    "sample_obs_v = torch.FloatTensor([sample_obs])\n",
    "sample_obs_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 129666012503614031267066647994536296448.,\n",
       "         -128649620393555838758781803338091462656.]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_trained(sample_obs_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-293982736963021820106449867453117759488.,\n",
       "          293938845828639517891652445601334820864.]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(sample_obs_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm(net_trained(sample_obs_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = sm(net(sample_obs_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(obs, net):\n",
    "    \n",
    "    obs_v = torch.FloatTensor([obs])\n",
    "    act_probs_v = sm(net(obs_v))\n",
    "    act_probs = act_probs_v.data.numpy()[0]\n",
    "\n",
    "    action = np.random.choice(len(act_probs), p = act_probs)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 4])\n",
      "tensor([[ 0.4520, -0.1001, -0.2828,  0.4591],\n",
      "        [-0.1144, -0.2206, -0.0995,  0.4077],\n",
      "        [ 0.0682, -0.2545,  0.0181, -0.2152],\n",
      "        [ 0.2548, -0.0763, -0.0492, -0.6855],\n",
      "        [-0.1500,  0.3953, -0.2284,  0.5169],\n",
      "        [-0.1900,  0.1336,  0.1711,  0.5318],\n",
      "        [ 0.2807,  0.3126, -0.1798, -0.6473],\n",
      "        [-0.3601, -0.5242, -0.1519, -0.1650],\n",
      "        [-0.0447, -0.2645,  0.1157, -0.1465],\n",
      "        [ 0.1283, -0.0916,  0.0520,  0.2495],\n",
      "        [ 0.0947,  0.0769, -0.5461,  0.4953],\n",
      "        [ 0.0835, -0.4172, -0.4592, -0.3743],\n",
      "        [ 0.0475,  0.1448, -0.2128,  0.5441],\n",
      "        [-0.4228, -0.1739,  0.5728,  0.6046],\n",
      "        [-0.4087,  0.3578,  0.1232,  0.5382],\n",
      "        [-0.4521,  0.3350,  0.2618,  0.4170],\n",
      "        [-0.1213, -0.3892,  0.0413,  0.6677],\n",
      "        [-0.1138,  0.0048,  0.2613, -0.1409],\n",
      "        [-0.1712, -0.2080,  0.0489,  0.5267],\n",
      "        [-0.3367, -0.1048,  0.3936,  0.5652],\n",
      "        [ 0.4768,  0.2750,  0.2368,  0.5588],\n",
      "        [ 0.2789, -0.1509, -0.2651,  0.3678],\n",
      "        [ 0.0648,  0.3854, -0.2902,  0.2743],\n",
      "        [ 0.3527,  0.1138, -0.5436, -0.5388],\n",
      "        [ 0.0579, -0.2612,  0.4401, -0.0194],\n",
      "        [-0.4769,  0.4101, -0.4782,  0.0522],\n",
      "        [ 0.0475,  0.0794, -0.5810, -0.5387],\n",
      "        [ 0.1430,  0.3716, -0.2400, -0.5354],\n",
      "        [-0.3332,  0.1441, -0.6674, -0.1606],\n",
      "        [ 0.4723, -0.4674, -0.1079, -0.5287],\n",
      "        [-0.1588, -0.1183, -0.1124, -0.4758],\n",
      "        [-0.0266,  0.2041, -0.0459,  0.6694],\n",
      "        [ 0.1474, -0.2610, -0.2397,  0.2180],\n",
      "        [-0.5269, -0.4037, -0.1377, -0.5139],\n",
      "        [-0.4017, -0.2385, -0.1461, -0.1008],\n",
      "        [ 0.2796,  0.0868,  0.3969,  0.6300],\n",
      "        [-0.2843,  0.0101,  0.1495, -0.0143],\n",
      "        [-0.4062, -0.0801,  0.0724,  0.3536],\n",
      "        [-0.4505,  0.4280,  0.3872,  0.4752],\n",
      "        [-0.0332,  0.4614,  0.4031,  0.4519],\n",
      "        [-0.2070, -0.3328, -0.2484,  0.4400],\n",
      "        [-0.1885,  0.0962,  0.1169, -0.3406],\n",
      "        [ 0.4641,  0.4693,  0.0705,  0.2356],\n",
      "        [ 0.1319,  0.0900,  0.7948,  0.2949],\n",
      "        [ 0.2218, -0.1590, -0.1824,  0.1023],\n",
      "        [-0.4191, -0.1504,  0.6685,  0.6506],\n",
      "        [ 0.2531,  0.2767, -0.2155,  0.0298],\n",
      "        [-0.5017,  0.3715, -0.2962,  0.0482],\n",
      "        [ 0.0460,  0.0780, -0.3810,  0.0958],\n",
      "        [-0.1250,  0.2433,  0.2242,  0.6635],\n",
      "        [-0.0222, -0.1638, -0.0544, -0.4978],\n",
      "        [-0.2964, -0.1504,  0.1882, -0.1587],\n",
      "        [ 0.2431, -0.5038, -0.2031,  0.3567],\n",
      "        [ 0.1956,  0.3448,  0.7099,  0.4069],\n",
      "        [ 0.2804,  0.0363, -0.0819, -0.0175],\n",
      "        [ 0.4101,  0.4702,  0.0632,  0.2921],\n",
      "        [ 0.2506,  0.0030,  0.2686, -0.0174],\n",
      "        [-0.0264,  0.1532,  0.1513, -0.1709],\n",
      "        [ 0.3996,  0.4535, -0.0477,  0.3056],\n",
      "        [-0.4596, -0.2148, -0.2061,  0.0476],\n",
      "        [ 0.2715,  0.2974,  0.3215, -0.2070],\n",
      "        [ 0.3959,  0.0273,  0.6034,  0.4354],\n",
      "        [ 0.0338, -0.0040,  0.0372,  0.3496],\n",
      "        [-0.4150, -0.0833, -0.7635, -0.3796],\n",
      "        [ 0.0134,  0.2459, -0.7842, -0.1620],\n",
      "        [ 0.1546, -0.1202,  0.0859,  0.3764],\n",
      "        [ 0.2279,  0.1569,  0.2806, -0.3606],\n",
      "        [-0.1070, -0.0290,  0.5197, -0.3325],\n",
      "        [-0.2575,  0.2796, -0.3788, -0.0072],\n",
      "        [-0.3253,  0.3770, -0.3327, -0.5521],\n",
      "        [-0.0256, -0.1754,  0.0679, -0.0047],\n",
      "        [ 0.3106,  0.4098,  0.2497,  0.5121],\n",
      "        [-0.3511, -0.4846, -0.0974, -0.1423],\n",
      "        [-0.1407, -0.3113, -0.4129, -0.1337],\n",
      "        [ 0.3602, -0.3065, -0.1124, -0.2995],\n",
      "        [-0.4919, -0.1073, -0.1928, -0.2382],\n",
      "        [-0.0837, -0.3038,  0.1596,  0.6118],\n",
      "        [ 0.2236, -0.1960,  0.3684,  0.5034],\n",
      "        [ 0.0280,  0.2049,  0.3709,  0.1004],\n",
      "        [ 0.2658, -0.3884,  0.7063,  0.6851],\n",
      "        [ 0.3733, -0.3363, -0.1536, -0.6122],\n",
      "        [ 0.4220, -0.2163,  0.6686,  0.5883],\n",
      "        [-0.2844,  0.0090, -0.0606,  0.2843],\n",
      "        [ 0.0077,  0.0266,  0.2025, -0.6419],\n",
      "        [ 0.1908, -0.3151, -0.2908, -0.0535],\n",
      "        [ 0.2649, -0.5126,  0.6246,  0.4199],\n",
      "        [-0.0583,  0.4808,  0.1933,  0.5504],\n",
      "        [-0.2691,  0.3337, -0.0115,  0.3611],\n",
      "        [ 0.2202, -0.1836, -0.0852,  0.4282],\n",
      "        [-0.0582, -0.3908, -0.1572, -0.0997],\n",
      "        [ 0.3269, -0.4421,  0.7571,  0.3218],\n",
      "        [-0.2035,  0.3333, -0.4199, -0.6221],\n",
      "        [ 0.0676,  0.3427, -0.0763,  0.4104],\n",
      "        [-0.2348, -0.3253, -0.7227, -0.5946],\n",
      "        [ 0.2098, -0.2638,  0.1154, -0.4417],\n",
      "        [-0.1965,  0.2716,  0.0240, -0.3257],\n",
      "        [ 0.1446, -0.1263,  0.0473, -0.0846],\n",
      "        [ 0.5028,  0.2925,  0.2704,  0.0885],\n",
      "        [-0.1079, -0.0396,  0.5901,  0.7452],\n",
      "        [-0.1886,  0.1597,  0.3596, -0.2667],\n",
      "        [ 0.2980, -0.3628,  0.6068,  0.7534],\n",
      "        [ 0.4187,  0.4975,  0.8002,  0.5243],\n",
      "        [-0.2216,  0.3263,  0.0501,  0.1269],\n",
      "        [-0.3733, -0.0929,  0.6659,  0.3879],\n",
      "        [-0.4325,  0.2110, -0.5879, -0.1156],\n",
      "        [-0.2459,  0.1198, -0.0639,  0.2246],\n",
      "        [ 0.3978, -0.2947, -0.4000, -0.3652],\n",
      "        [-0.0089,  0.3766,  0.2189, -0.2272],\n",
      "        [-0.2158,  0.4278,  0.4524,  0.3570],\n",
      "        [ 0.2725,  0.2007, -0.0354,  0.1063],\n",
      "        [ 0.2321, -0.1447,  0.1102,  0.2489],\n",
      "        [-0.0671, -0.1951, -0.4909, -0.1253],\n",
      "        [ 0.3213, -0.1481, -0.2498, -0.2671],\n",
      "        [ 0.0690,  0.0602,  0.0152,  0.2161],\n",
      "        [-0.2548,  0.1287, -0.4961, -0.5390],\n",
      "        [-0.0480, -0.3864, -0.1607, -0.0807],\n",
      "        [-0.1904,  0.3664, -0.2069,  0.1908],\n",
      "        [ 0.0224,  0.2302, -0.2745,  0.6130],\n",
      "        [ 0.3228,  0.3433, -0.0425, -0.4006],\n",
      "        [ 0.2922, -0.0950, -0.6040, -0.3116],\n",
      "        [ 0.0459, -0.3907,  0.7113,  0.1600],\n",
      "        [-0.0350, -0.3995, -0.3090,  0.5869],\n",
      "        [-0.3503,  0.2848,  0.2950, -0.4187],\n",
      "        [-0.1883, -0.5030,  0.4017, -0.0977],\n",
      "        [ 0.4043,  0.4576, -0.4361,  0.1017],\n",
      "        [ 0.1196,  0.3536,  0.5672,  0.6828],\n",
      "        [ 0.1841,  0.1016, -0.4254, -0.0690],\n",
      "        [ 0.2436,  0.1702, -0.2535,  0.2582]])\n",
      "torch.Size([128])\n",
      "tensor([-0.0098, -0.3744, -0.1262,  0.4738,  0.1389,  0.4011,  0.5158,  0.2852,\n",
      "        -0.4794, -0.2355, -0.5301,  0.1623,  0.0737, -0.0378,  0.1516,  0.4075,\n",
      "         0.1908, -0.2269, -0.0551, -0.1397,  0.2181, -0.1918, -0.4003,  0.1263,\n",
      "        -0.0528, -0.3076,  0.1383, -0.1295,  0.0794,  0.2259,  0.1239,  0.0970,\n",
      "        -0.5340, -0.5106, -0.4112,  0.0868, -0.3396,  0.0402,  0.2444,  0.1394,\n",
      "        -0.3777, -0.3817, -0.1277,  0.1205, -0.2818, -0.0304, -0.1897,  0.4804,\n",
      "        -0.1685,  0.2203,  0.1564, -0.2666, -0.3739,  0.2102, -0.4431,  0.0689,\n",
      "        -0.1535, -0.4085,  0.0178,  0.2095, -0.4921,  0.0815, -0.4858,  0.2432,\n",
      "         0.1734,  0.2230, -0.0702, -0.1721, -0.2729,  0.4631, -0.4267, -0.3165,\n",
      "         0.2517, -0.3538,  0.1364, -0.3060, -0.1617,  0.0186,  0.0385,  0.0380,\n",
      "         0.2305,  0.2863, -0.3545,  0.1035, -0.2258, -0.2773,  0.3808, -0.3193,\n",
      "        -0.0653, -0.3973,  0.3919,  0.1660, -0.3390,  0.2278, -0.5120, -0.2098,\n",
      "        -0.1522, -0.2098,  0.2244, -0.0851,  0.1444,  0.1869,  0.2778,  0.0876,\n",
      "         0.0869,  0.3117,  0.2382, -0.4940,  0.2696, -0.4824, -0.3501,  0.3108,\n",
      "        -0.5183,  0.2451,  0.1425,  0.1455, -0.2621, -0.4556, -0.4091,  0.0816,\n",
      "        -0.1071, -0.2254, -0.4969, -0.4557,  0.3844,  0.2643,  0.3769, -0.4145])\n",
      "torch.Size([2, 128])\n",
      "tensor([[-0.1252, -0.0650, -0.0081,  0.1252, -0.1376, -0.0398,  0.1383,  0.1025,\n",
      "         -0.0094, -0.0934, -0.0089,  0.1722, -0.0798, -0.1142, -0.3005, -0.1463,\n",
      "         -0.1055,  0.0559, -0.1936, -0.1398, -0.0644, -0.1264,  0.0505,  0.0867,\n",
      "         -0.0318,  0.0622,  0.1584,  0.1146,  0.0937,  0.1527,  0.1504, -0.1546,\n",
      "         -0.0506, -0.1155, -0.0518, -0.1382, -0.1023, -0.1587, -0.1604, -0.1176,\n",
      "         -0.1144, -0.0129, -0.0717, -0.2405, -0.0592, -0.1738, -0.0784,  0.0562,\n",
      "         -0.0140, -0.2988,  0.1936, -0.1052, -0.0736, -0.2187, -0.0264, -0.1173,\n",
      "         -0.0534, -0.0610, -0.1163, -0.0305,  0.0515, -0.1416, -0.1200,  0.3023,\n",
      "          0.0641, -0.0656,  0.0282,  0.0625,  0.0662,  0.1327,  0.0835, -0.0596,\n",
      "          0.1143, -0.0490,  0.0398, -0.0938, -0.1528, -0.1840, -0.1199, -0.0790,\n",
      "          0.2799, -0.1909,  0.0115,  0.0799, -0.0040, -0.2038, -0.0985, -0.0526,\n",
      "         -0.1767, -0.0913, -0.0942,  0.0778,  0.0286,  0.2776,  0.0064,  0.0837,\n",
      "         -0.1196, -0.0208, -0.1635,  0.0058, -0.1500, -0.1751, -0.0704, -0.2765,\n",
      "          0.0925, -0.0703,  0.1630, -0.0057, -0.1062, -0.0398,  0.0072,  0.0917,\n",
      "         -0.1106, -0.0030,  0.1395,  0.0804,  0.0827,  0.1060, -0.0659,  0.0007,\n",
      "         -0.1349, -0.0301,  0.0542, -0.1330, -0.0115, -0.1455,  0.0452,  0.1093],\n",
      "        [ 0.1139,  0.0548,  0.0366, -0.2027,  0.1744,  0.1575, -0.0948, -0.0864,\n",
      "          0.0547,  0.0178, -0.0039, -0.0990,  0.1506,  0.2105,  0.2759,  0.0757,\n",
      "          0.1560, -0.0229,  0.0765,  0.1730,  0.2077,  0.0120, -0.0546, -0.1159,\n",
      "          0.0367, -0.0248, -0.0672,  0.0059, -0.1606, -0.1974, -0.1301,  0.3009,\n",
      "         -0.0190,  0.1418,  0.1356,  0.2551,  0.0517,  0.0571,  0.2236,  0.1979,\n",
      "          0.0234, -0.0972,  0.0135,  0.2520,  0.0397,  0.2094, -0.0482, -0.0422,\n",
      "          0.0119,  0.2743, -0.0934,  0.1030,  0.0351,  0.1823, -0.0212, -0.0039,\n",
      "         -0.0012, -0.0694,  0.0153, -0.1218,  0.0405,  0.1138,  0.1056, -0.2017,\n",
      "         -0.0471,  0.0134, -0.0050, -0.0166, -0.0903, -0.1030,  0.0585, -0.0211,\n",
      "         -0.0574,  0.0628, -0.1276,  0.0721,  0.1019,  0.1979,  0.0451,  0.2333,\n",
      "         -0.1208,  0.1201,  0.0044, -0.1548,  0.0212,  0.1543,  0.1292, -0.0425,\n",
      "          0.1693, -0.0050,  0.0250, -0.1051, -0.0030, -0.1911,  0.0737, -0.0477,\n",
      "         -0.0073,  0.0320,  0.2156, -0.0448,  0.1731,  0.0988,  0.0154,  0.1526,\n",
      "         -0.1337, -0.0157, -0.1785, -0.0204,  0.1280, -0.0500,  0.0485, -0.1023,\n",
      "         -0.0326,  0.0385, -0.1593, -0.0149, -0.0163,  0.0481,  0.0487, -0.1541,\n",
      "          0.0261,  0.1831,  0.0105,  0.0741, -0.0234,  0.2241, -0.0649, -0.0166]])\n",
      "torch.Size([2])\n",
      "tensor([0.0724, 0.0361])\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data.shape)\n",
    "    print(param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0  Total Reward =  200.0  Total Steps =  200\n",
      "iter 1  Total Reward =  177.0  Total Steps =  177\n",
      "iter 2  Total Reward =  190.0  Total Steps =  190\n",
      "iter 3  Total Reward =  200.0  Total Steps =  200\n",
      "iter 4  Total Reward =  200.0  Total Steps =  200\n",
      "iter 5  Total Reward =  118.0  Total Steps =  118\n",
      "iter 6  Total Reward =  200.0  Total Steps =  200\n",
      "iter 7  Total Reward =  200.0  Total Steps =  200\n",
      "iter 8  Total Reward =  200.0  Total Steps =  200\n",
      "iter 9  Total Reward =  200.0  Total Steps =  200\n",
      "iter 10  Total Reward =  200.0  Total Steps =  200\n",
      "iter 11  Total Reward =  200.0  Total Steps =  200\n",
      "iter 12  Total Reward =  200.0  Total Steps =  200\n",
      "iter 13  Total Reward =  200.0  Total Steps =  200\n",
      "iter 14  Total Reward =  200.0  Total Steps =  200\n",
      "iter 15  Total Reward =  200.0  Total Steps =  200\n",
      "avg rew =  192.8125\n"
     ]
    }
   ],
   "source": [
    "# playing with trained agent\n",
    "total_reward_a = []\n",
    "total_steps = 0\n",
    "# obs = env.reset()\n",
    "sm = nn.Softmax(dim=1)\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    total_reward = 0.0\n",
    "    total_steps = 0\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        env.render()\n",
    "        action = get_action(obs, net_trained)\n",
    "#         action = env.action_space.sample()\n",
    "        next_obs, rew, is_done, _ = env.step(action)\n",
    "        total_reward+=rew\n",
    "        total_steps+=1\n",
    "        if is_done:\n",
    "            print(\"iter\",i,\" Total Reward = \",total_reward,\" Total Steps = \", total_steps)            \n",
    "            total_reward_a.append(total_reward)\n",
    "            break\n",
    "        obs=next_obs\n",
    "\n",
    "print('avg rew = ',sum(total_reward_a)/BATCH_SIZE)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
