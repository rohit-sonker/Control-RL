{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,obs_size, hidden_size,n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(obs_size,hidden_size),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(hidden_size,n_actions))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy(net, obs):\n",
    "    logits = net(obs)\n",
    "    return Categorical(logits=logits)\n",
    "\n",
    "def get_action(net, obs):\n",
    "    policy = get_policy(net, obs)\n",
    "    act = policy.sample().item()\n",
    "    return act\n",
    "\n",
    "def reward_to_go(rews):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + (rtgs[i+1] if i+1 < n else 0)\n",
    "    return rtgs\n",
    "\n",
    "def reward_to_go_avg(rews, avg):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + (rtgs[i+1] if i+1 < n else 0) - avg/n\n",
    "    return rtgs\n",
    "\n",
    "def disc_rtg_avg(rews, avg):\n",
    "    rtgs = []\n",
    "    val = 0\n",
    "    for i in reversed(range(len(rews))):\n",
    "        val = val*GAMMA + rews[i] - avg/len(rews)\n",
    "        rtgs.append(val)\n",
    "    rtgs = rtgs[::-1]\n",
    "    return rtgs\n",
    "\n",
    "def disc_rtg(rews):\n",
    "    rtgs = []\n",
    "    val = 0\n",
    "    for i in reversed(range(len(rews))):\n",
    "        val = val*GAMMA + rews[i]\n",
    "        rtgs.append(val)\n",
    "    rtgs = rtgs[::-1]\n",
    "    return rtgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(obs, acts, wts, net):\n",
    "#     obs_v = torch.FloatTensor(obs)\n",
    "    policy = get_policy(net,obs)\n",
    "    log_p = policy.log_prob(acts)\n",
    "    \n",
    "    loss = -(log_p*wts).mean()\n",
    "    entropy_v = policy.entropy().mean()\n",
    "    return loss, entropy_v, policy\n",
    "\n",
    "def get_kl_div(obs, old_policy, net ):\n",
    "    new_policy = get_policy(net, obs)\n",
    "    kl_div = -((new_policy.probs/old_policy.probs).log() * old_policy.probs).sum(-1).mean()\n",
    "    return kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(env, net, batch_size=5000, render=False):\n",
    "    batch_obs = []\n",
    "    batch_wts = []\n",
    "    batch_acts = []\n",
    "    batch_rets = []\n",
    "    batch_len = []\n",
    "    eps_rew = []\n",
    "    batch_rew = []\n",
    "    obs = env.reset()\n",
    "    done=False\n",
    "    epoch_finished_rendering = False\n",
    "    \n",
    "    while True:\n",
    "        if not epoch_finished_rendering and render:\n",
    "            env.render()\n",
    "        \n",
    "        act = get_action(net, obs = torch.as_tensor(obs,dtype=torch.float32))\n",
    "        batch_obs.append(obs.copy())\n",
    "        batch_acts.append(act)\n",
    "        \n",
    "        obs,rew,done,_ = env.step(act)\n",
    "        \n",
    "        eps_rew.append(rew)\n",
    "        batch_rew.append(rew)\n",
    "#         obs= next_obs\n",
    "        \n",
    "        if done:\n",
    "            eps_ret = sum(eps_rew)\n",
    "            eps_len = len(eps_rew)\n",
    "            batch_rets.append(eps_ret)\n",
    "            batch_len.append(eps_len)\n",
    "            \n",
    "            #plain\n",
    "#             batch_wts = batch_wts + [eps_ret]*eps_len\n",
    "\n",
    "            #subtract avg reward\n",
    "#             batch_wts = batch_wts + [eps_ret- avg_rew]*eps_len\n",
    "            \n",
    "            # reward to-go\n",
    "#             batch_wts = batch_wts + list(reward_to_go(eps_rew))\n",
    "\n",
    "            # reward to-go with avg rew\n",
    "#             batch_wts = batch_wts + list(reward_to_go_avg(eps_rew, avg_rew))\n",
    "            \n",
    "            # disc rtg\n",
    "            batch_wts = batch_wts + list(disc_rtg(eps_rew))\n",
    "            \n",
    "            eps_rew = []\n",
    "            done = False\n",
    "            \n",
    "            obs = env.reset()\n",
    "            epoch_finished_rendering = True\n",
    "            \n",
    "            if len(batch_obs)>batch_size:\n",
    "                break\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    batch_loss, entropy_v, policy = compute_loss(obs = torch.as_tensor(batch_obs, dtype=torch.float32),\n",
    "                              acts = torch.as_tensor(batch_acts, dtype = torch.int32),\n",
    "                              wts = torch.as_tensor(batch_wts, dtype = torch.float32),\n",
    "                             net = net)\n",
    "    \n",
    "    \n",
    "    \n",
    "    entropy = entropy_v.item()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    kl_div = get_kl_div(obs = torch.as_tensor(batch_obs, dtype=torch.float32),\n",
    "                       old_policy = policy,\n",
    "                       net=net)\n",
    "    return batch_loss,batch_rets, batch_len, entropy, kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "obs_size, n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 32\n",
    "BATCH_SIZE = 500\n",
    "GAMMA = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(obs_size = obs_size, hidden_size = HIDDEN_SIZE, n_actions= n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "act = get_action(net, obs= torch.as_tensor(obs, dtype=torch.float32))\n",
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = env.action_space.sample()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "lr = 1e-2\n",
    "optimizer = Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(comment=\"-vanilla_policy_grad_cartpole_disc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 \t loss: 9.193 \t return: 25.400 \t ep_len: 25.400 \t entropy: 0.691 \t kl_div: 0.002\n",
      "epoch:   2 \t loss: 12.293 \t return: 33.062 \t ep_len: 33.062 \t entropy: 0.684 \t kl_div: 0.002\n",
      "epoch:   3 \t loss: 12.725 \t return: 33.800 \t ep_len: 33.800 \t entropy: 0.674 \t kl_div: 0.002\n",
      "epoch:   4 \t loss: 13.458 \t return: 37.286 \t ep_len: 37.286 \t entropy: 0.668 \t kl_div: 0.001\n",
      "epoch:   5 \t loss: 15.231 \t return: 45.500 \t ep_len: 45.500 \t entropy: 0.659 \t kl_div: 0.001\n",
      "epoch:   6 \t loss: 13.723 \t return: 43.333 \t ep_len: 43.333 \t entropy: 0.654 \t kl_div: 0.001\n",
      "epoch:   7 \t loss: 14.847 \t return: 42.500 \t ep_len: 42.500 \t entropy: 0.642 \t kl_div: 0.001\n",
      "epoch:   8 \t loss: 16.975 \t return: 51.000 \t ep_len: 51.000 \t entropy: 0.635 \t kl_div: 0.001\n",
      "epoch:   9 \t loss: 14.603 \t return: 48.182 \t ep_len: 48.182 \t entropy: 0.630 \t kl_div: 0.001\n",
      "epoch:  10 \t loss: 13.114 \t return: 43.417 \t ep_len: 43.417 \t entropy: 0.630 \t kl_div: 0.001\n",
      "epoch:  11 \t loss: 18.762 \t return: 66.875 \t ep_len: 66.875 \t entropy: 0.625 \t kl_div: 0.000\n",
      "epoch:  12 \t loss: 18.133 \t return: 67.750 \t ep_len: 67.750 \t entropy: 0.620 \t kl_div: 0.001\n",
      "epoch:  13 \t loss: 16.022 \t return: 59.300 \t ep_len: 59.300 \t entropy: 0.614 \t kl_div: 0.001\n",
      "epoch:  14 \t loss: 15.455 \t return: 56.111 \t ep_len: 56.111 \t entropy: 0.600 \t kl_div: 0.001\n",
      "epoch:  15 \t loss: 19.953 \t return: 81.429 \t ep_len: 81.429 \t entropy: 0.601 \t kl_div: 0.001\n",
      "epoch:  16 \t loss: 16.134 \t return: 63.556 \t ep_len: 63.556 \t entropy: 0.595 \t kl_div: 0.001\n",
      "epoch:  17 \t loss: 18.572 \t return: 70.000 \t ep_len: 70.000 \t entropy: 0.595 \t kl_div: 0.000\n",
      "epoch:  18 \t loss: 17.696 \t return: 73.857 \t ep_len: 73.857 \t entropy: 0.594 \t kl_div: 0.001\n",
      "epoch:  19 \t loss: 20.064 \t return: 73.286 \t ep_len: 73.286 \t entropy: 0.578 \t kl_div: 0.000\n",
      "epoch:  20 \t loss: 22.319 \t return: 103.600 \t ep_len: 103.600 \t entropy: 0.590 \t kl_div: 0.000\n",
      "epoch:  21 \t loss: 25.580 \t return: 98.667 \t ep_len: 98.667 \t entropy: 0.572 \t kl_div: 0.000\n",
      "epoch:  22 \t loss: 24.179 \t return: 100.400 \t ep_len: 100.400 \t entropy: 0.561 \t kl_div: 0.001\n",
      "epoch:  23 \t loss: 24.162 \t return: 109.167 \t ep_len: 109.167 \t entropy: 0.579 \t kl_div: 0.001\n",
      "epoch:  24 \t loss: 22.143 \t return: 97.167 \t ep_len: 97.167 \t entropy: 0.568 \t kl_div: 0.001\n",
      "epoch:  25 \t loss: 22.112 \t return: 102.400 \t ep_len: 102.400 \t entropy: 0.577 \t kl_div: 0.003\n",
      "epoch:  26 \t loss: 30.677 \t return: 169.333 \t ep_len: 169.333 \t entropy: 0.579 \t kl_div: 0.001\n",
      "epoch:  27 \t loss: 33.419 \t return: 200.667 \t ep_len: 200.667 \t entropy: 0.581 \t kl_div: 0.004\n",
      "epoch:  28 \t loss: 37.508 \t return: 254.500 \t ep_len: 254.500 \t entropy: 0.573 \t kl_div: 0.003\n",
      "epoch:  29 \t loss: 27.444 \t return: 141.250 \t ep_len: 141.250 \t entropy: 0.567 \t kl_div: 0.000\n",
      "epoch:  30 \t loss: 36.394 \t return: 234.333 \t ep_len: 234.333 \t entropy: 0.592 \t kl_div: 0.000\n",
      "epoch:  31 \t loss: 36.892 \t return: 263.000 \t ep_len: 263.000 \t entropy: 0.582 \t kl_div: 0.000\n",
      "epoch:  32 \t loss: 45.938 \t return: 497.500 \t ep_len: 497.500 \t entropy: 0.580 \t kl_div: 0.001\n",
      "epoch:  33 \t loss: 32.529 \t return: 201.667 \t ep_len: 201.667 \t entropy: 0.565 \t kl_div: 0.000\n",
      "epoch:  34 \t loss: 34.302 \t return: 232.667 \t ep_len: 232.667 \t entropy: 0.566 \t kl_div: 0.000\n",
      "epoch:  35 \t loss: 36.164 \t return: 275.000 \t ep_len: 275.000 \t entropy: 0.562 \t kl_div: 0.000\n",
      "epoch:  36 \t loss: 43.726 \t return: 451.500 \t ep_len: 451.500 \t entropy: 0.570 \t kl_div: 0.001\n",
      "epoch:  37 \t loss: 42.465 \t return: 386.000 \t ep_len: 386.000 \t entropy: 0.553 \t kl_div: 0.001\n",
      "epoch:  38 \t loss: 37.312 \t return: 277.000 \t ep_len: 277.000 \t entropy: 0.561 \t kl_div: 0.001\n",
      "epoch:  39 \t loss: 35.763 \t return: 255.000 \t ep_len: 255.000 \t entropy: 0.551 \t kl_div: 0.001\n",
      "epoch:  40 \t loss: 35.678 \t return: 258.000 \t ep_len: 258.000 \t entropy: 0.560 \t kl_div: 0.000\n",
      "epoch:  41 \t loss: 38.133 \t return: 305.500 \t ep_len: 305.500 \t entropy: 0.551 \t kl_div: 0.000\n",
      "epoch:  42 \t loss: 31.386 \t return: 201.000 \t ep_len: 201.000 \t entropy: 0.552 \t kl_div: 0.000\n",
      "epoch:  43 \t loss: 36.507 \t return: 288.000 \t ep_len: 288.000 \t entropy: 0.557 \t kl_div: 0.000\n",
      "epoch:  44 \t loss: 37.185 \t return: 279.000 \t ep_len: 279.000 \t entropy: 0.553 \t kl_div: 0.001\n",
      "epoch:  45 \t loss: 38.534 \t return: 304.000 \t ep_len: 304.000 \t entropy: 0.534 \t kl_div: 0.002\n",
      "epoch:  46 \t loss: 38.309 \t return: 319.000 \t ep_len: 319.000 \t entropy: 0.555 \t kl_div: 0.001\n",
      "epoch:  47 \t loss: 38.289 \t return: 361.000 \t ep_len: 361.000 \t entropy: 0.571 \t kl_div: 0.000\n",
      "epoch:  48 \t loss: 38.140 \t return: 345.000 \t ep_len: 345.000 \t entropy: 0.548 \t kl_div: 0.000\n",
      "epoch:  49 \t loss: 42.134 \t return: 439.500 \t ep_len: 439.500 \t entropy: 0.539 \t kl_div: 0.001\n",
      "epoch:  50 \t loss: 41.497 \t return: 434.500 \t ep_len: 434.500 \t entropy: 0.543 \t kl_div: 0.000\n",
      "epoch:  51 \t loss: 39.768 \t return: 336.500 \t ep_len: 336.500 \t entropy: 0.526 \t kl_div: 0.000\n",
      "epoch:  52 \t loss: 41.127 \t return: 441.000 \t ep_len: 441.000 \t entropy: 0.540 \t kl_div: 0.001\n",
      "epoch:  53 \t loss: 43.231 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.530 \t kl_div: 0.000\n",
      "epoch:  54 \t loss: 40.679 \t return: 403.000 \t ep_len: 403.000 \t entropy: 0.529 \t kl_div: 0.001\n",
      "epoch:  55 \t loss: 41.842 \t return: 471.000 \t ep_len: 471.000 \t entropy: 0.538 \t kl_div: 0.000\n",
      "epoch:  56 \t loss: 40.438 \t return: 408.500 \t ep_len: 408.500 \t entropy: 0.536 \t kl_div: 0.001\n",
      "epoch:  57 \t loss: 43.828 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.531 \t kl_div: 0.000\n",
      "epoch:  58 \t loss: 38.376 \t return: 349.000 \t ep_len: 349.000 \t entropy: 0.542 \t kl_div: 0.000\n",
      "epoch:  59 \t loss: 41.976 \t return: 462.500 \t ep_len: 462.500 \t entropy: 0.532 \t kl_div: 0.000\n",
      "epoch:  60 \t loss: 42.781 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.535 \t kl_div: 0.000\n",
      "epoch:  61 \t loss: 43.318 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.526 \t kl_div: 0.001\n",
      "epoch:  62 \t loss: 41.374 \t return: 470.000 \t ep_len: 470.000 \t entropy: 0.535 \t kl_div: 0.001\n",
      "epoch:  63 \t loss: 40.658 \t return: 442.000 \t ep_len: 442.000 \t entropy: 0.536 \t kl_div: 0.000\n",
      "epoch:  64 \t loss: 37.262 \t return: 304.500 \t ep_len: 304.500 \t entropy: 0.514 \t kl_div: 0.000\n",
      "epoch:  65 \t loss: 41.529 \t return: 449.500 \t ep_len: 449.500 \t entropy: 0.529 \t kl_div: 0.000\n",
      "epoch:  66 \t loss: 42.140 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.533 \t kl_div: 0.000\n",
      "epoch:  67 \t loss: 39.694 \t return: 393.000 \t ep_len: 393.000 \t entropy: 0.523 \t kl_div: 0.000\n",
      "epoch:  68 \t loss: 42.189 \t return: 487.500 \t ep_len: 487.500 \t entropy: 0.521 \t kl_div: 0.000\n",
      "epoch:  69 \t loss: 42.154 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.527 \t kl_div: 0.000\n",
      "epoch:  70 \t loss: 40.339 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.532 \t kl_div: 0.000\n",
      "epoch:  71 \t loss: 41.138 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.523 \t kl_div: 0.000\n",
      "epoch:  72 \t loss: 40.550 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.529 \t kl_div: 0.000\n",
      "epoch:  73 \t loss: 40.093 \t return: 447.000 \t ep_len: 447.000 \t entropy: 0.514 \t kl_div: 0.000\n",
      "epoch:  74 \t loss: 41.833 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.512 \t kl_div: 0.000\n",
      "epoch:  75 \t loss: 40.054 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.526 \t kl_div: 0.000\n",
      "epoch:  76 \t loss: 41.307 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.510 \t kl_div: 0.000\n",
      "epoch:  77 \t loss: 41.134 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.513 \t kl_div: 0.000\n",
      "epoch:  78 \t loss: 41.104 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.512 \t kl_div: 0.000\n",
      "epoch:  79 \t loss: 39.497 \t return: 490.000 \t ep_len: 490.000 \t entropy: 0.522 \t kl_div: 0.000\n",
      "epoch:  80 \t loss: 39.078 \t return: 444.000 \t ep_len: 444.000 \t entropy: 0.507 \t kl_div: 0.000\n",
      "epoch:  81 \t loss: 39.879 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.508 \t kl_div: 0.000\n",
      "epoch:  82 \t loss: 40.460 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.503 \t kl_div: 0.000\n",
      "epoch:  83 \t loss: 39.983 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.499 \t kl_div: 0.000\n",
      "epoch:  84 \t loss: 39.643 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.503 \t kl_div: 0.000\n",
      "epoch:  85 \t loss: 39.204 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.498 \t kl_div: 0.000\n",
      "epoch:  86 \t loss: 38.956 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.500 \t kl_div: 0.000\n",
      "epoch:  87 \t loss: 38.958 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.493 \t kl_div: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  88 \t loss: 40.968 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.486 \t kl_div: 0.000\n",
      "epoch:  89 \t loss: 40.631 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.494 \t kl_div: 0.001\n",
      "epoch:  90 \t loss: 38.515 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.500 \t kl_div: 0.004\n",
      "epoch:  91 \t loss: 38.996 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.492 \t kl_div: 0.001\n",
      "epoch:  92 \t loss: 36.137 \t return: 362.500 \t ep_len: 362.500 \t entropy: 0.500 \t kl_div: 0.001\n",
      "epoch:  93 \t loss: 33.755 \t return: 334.500 \t ep_len: 334.500 \t entropy: 0.508 \t kl_div: 0.001\n",
      "epoch:  94 \t loss: 35.277 \t return: 295.500 \t ep_len: 295.500 \t entropy: 0.487 \t kl_div: 0.001\n",
      "epoch:  95 \t loss: 33.373 \t return: 292.000 \t ep_len: 292.000 \t entropy: 0.491 \t kl_div: 0.002\n",
      "epoch:  96 \t loss: 31.532 \t return: 241.000 \t ep_len: 241.000 \t entropy: 0.489 \t kl_div: 0.003\n",
      "epoch:  97 \t loss: 31.877 \t return: 228.333 \t ep_len: 228.333 \t entropy: 0.476 \t kl_div: 0.002\n",
      "epoch:  98 \t loss: 32.724 \t return: 255.500 \t ep_len: 255.500 \t entropy: 0.483 \t kl_div: 0.002\n",
      "epoch:  99 \t loss: 28.044 \t return: 206.000 \t ep_len: 206.000 \t entropy: 0.499 \t kl_div: 0.001\n",
      "epoch: 100 \t loss: 26.778 \t return: 180.333 \t ep_len: 180.333 \t entropy: 0.493 \t kl_div: 0.001\n",
      "epoch: 101 \t loss: 26.726 \t return: 182.667 \t ep_len: 182.667 \t entropy: 0.502 \t kl_div: 0.000\n",
      "epoch: 102 \t loss: 25.930 \t return: 188.333 \t ep_len: 188.333 \t entropy: 0.511 \t kl_div: 0.000\n",
      "epoch: 103 \t loss: 26.624 \t return: 180.333 \t ep_len: 180.333 \t entropy: 0.501 \t kl_div: 0.000\n",
      "epoch: 104 \t loss: 26.010 \t return: 183.333 \t ep_len: 183.333 \t entropy: 0.507 \t kl_div: 0.000\n",
      "epoch: 105 \t loss: 25.194 \t return: 173.333 \t ep_len: 173.333 \t entropy: 0.514 \t kl_div: 0.000\n",
      "epoch: 106 \t loss: 26.789 \t return: 168.333 \t ep_len: 168.333 \t entropy: 0.491 \t kl_div: 0.000\n",
      "epoch: 107 \t loss: 26.427 \t return: 176.000 \t ep_len: 176.000 \t entropy: 0.492 \t kl_div: 0.000\n",
      "epoch: 108 \t loss: 27.126 \t return: 185.333 \t ep_len: 185.333 \t entropy: 0.499 \t kl_div: 0.001\n",
      "epoch: 109 \t loss: 26.238 \t return: 187.667 \t ep_len: 187.667 \t entropy: 0.502 \t kl_div: 0.003\n",
      "epoch: 110 \t loss: 28.775 \t return: 215.333 \t ep_len: 215.333 \t entropy: 0.493 \t kl_div: 0.003\n",
      "epoch: 111 \t loss: 29.745 \t return: 235.333 \t ep_len: 235.333 \t entropy: 0.496 \t kl_div: 0.004\n",
      "epoch: 112 \t loss: 32.247 \t return: 310.500 \t ep_len: 310.500 \t entropy: 0.500 \t kl_div: 0.009\n",
      "epoch: 113 \t loss: 34.422 \t return: 288.000 \t ep_len: 288.000 \t entropy: 0.487 \t kl_div: 0.006\n",
      "epoch: 114 \t loss: 37.877 \t return: 400.500 \t ep_len: 400.500 \t entropy: 0.481 \t kl_div: 0.004\n",
      "epoch: 115 \t loss: 39.308 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.496 \t kl_div: 0.006\n",
      "epoch: 116 \t loss: 39.619 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.482 \t kl_div: 0.003\n",
      "epoch: 117 \t loss: 39.293 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.484 \t kl_div: 0.001\n",
      "epoch: 118 \t loss: 39.329 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.486 \t kl_div: 0.001\n",
      "epoch: 119 \t loss: 39.027 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.492 \t kl_div: 0.000\n",
      "epoch: 120 \t loss: 37.790 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.498 \t kl_div: 0.000\n",
      "epoch: 121 \t loss: 39.412 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.488 \t kl_div: 0.000\n",
      "epoch: 122 \t loss: 39.429 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.492 \t kl_div: 0.000\n",
      "epoch: 123 \t loss: 38.348 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.498 \t kl_div: 0.000\n",
      "epoch: 124 \t loss: 41.346 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.479 \t kl_div: 0.001\n",
      "epoch: 125 \t loss: 40.565 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.487 \t kl_div: 0.003\n",
      "epoch: 126 \t loss: 40.622 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.489 \t kl_div: 0.003\n",
      "epoch: 127 \t loss: 41.240 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.494 \t kl_div: 0.001\n",
      "epoch: 128 \t loss: 40.839 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.500 \t kl_div: 0.003\n",
      "epoch: 129 \t loss: 41.095 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.499 \t kl_div: 0.003\n",
      "epoch: 130 \t loss: 41.208 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.510 \t kl_div: 0.002\n",
      "epoch: 131 \t loss: 40.826 \t return: 490.000 \t ep_len: 490.000 \t entropy: 0.519 \t kl_div: 0.000\n",
      "epoch: 132 \t loss: 40.761 \t return: 468.000 \t ep_len: 468.000 \t entropy: 0.509 \t kl_div: 0.001\n",
      "epoch: 133 \t loss: 41.617 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.525 \t kl_div: 0.003\n",
      "epoch: 134 \t loss: 40.903 \t return: 447.000 \t ep_len: 447.000 \t entropy: 0.511 \t kl_div: 0.006\n",
      "epoch: 135 \t loss: 41.331 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.528 \t kl_div: 0.007\n",
      "epoch: 136 \t loss: 40.755 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.537 \t kl_div: 0.006\n",
      "epoch: 137 \t loss: 41.932 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.531 \t kl_div: 0.005\n",
      "epoch: 138 \t loss: 42.404 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.524 \t kl_div: 0.003\n",
      "epoch: 139 \t loss: 40.671 \t return: 439.500 \t ep_len: 439.500 \t entropy: 0.524 \t kl_div: 0.003\n",
      "epoch: 140 \t loss: 41.956 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.533 \t kl_div: 0.003\n",
      "epoch: 141 \t loss: 42.007 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.540 \t kl_div: 0.003\n",
      "epoch: 142 \t loss: 39.088 \t return: 383.000 \t ep_len: 383.000 \t entropy: 0.537 \t kl_div: 0.001\n",
      "epoch: 143 \t loss: 43.059 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.537 \t kl_div: 0.001\n",
      "epoch: 144 \t loss: 40.386 \t return: 397.000 \t ep_len: 397.000 \t entropy: 0.529 \t kl_div: 0.000\n",
      "epoch: 145 \t loss: 42.884 \t return: 481.000 \t ep_len: 481.000 \t entropy: 0.524 \t kl_div: 0.000\n",
      "epoch: 146 \t loss: 44.536 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.521 \t kl_div: 0.000\n",
      "epoch: 147 \t loss: 29.799 \t return: 177.000 \t ep_len: 177.000 \t entropy: 0.499 \t kl_div: 0.000\n",
      "epoch: 148 \t loss: 40.255 \t return: 333.500 \t ep_len: 333.500 \t entropy: 0.526 \t kl_div: 0.000\n",
      "epoch: 149 \t loss: 37.391 \t return: 279.000 \t ep_len: 279.000 \t entropy: 0.514 \t kl_div: 0.000\n",
      "epoch: 150 \t loss: 40.337 \t return: 420.000 \t ep_len: 420.000 \t entropy: 0.535 \t kl_div: 0.001\n",
      "epoch: 151 \t loss: 42.098 \t return: 496.500 \t ep_len: 496.500 \t entropy: 0.549 \t kl_div: 0.001\n",
      "epoch: 152 \t loss: 41.373 \t return: 402.000 \t ep_len: 402.000 \t entropy: 0.528 \t kl_div: 0.001\n",
      "epoch: 153 \t loss: 41.164 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.544 \t kl_div: 0.000\n",
      "epoch: 154 \t loss: 41.476 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.535 \t kl_div: 0.000\n",
      "epoch: 155 \t loss: 42.034 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.526 \t kl_div: 0.000\n",
      "epoch: 156 \t loss: 41.977 \t return: 492.000 \t ep_len: 492.000 \t entropy: 0.520 \t kl_div: 0.000\n",
      "epoch: 157 \t loss: 40.154 \t return: 404.000 \t ep_len: 404.000 \t entropy: 0.512 \t kl_div: 0.000\n",
      "epoch: 158 \t loss: 42.124 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.522 \t kl_div: 0.000\n",
      "epoch: 159 \t loss: 37.142 \t return: 306.000 \t ep_len: 306.000 \t entropy: 0.509 \t kl_div: 0.000\n",
      "epoch: 160 \t loss: 42.065 \t return: 485.000 \t ep_len: 485.000 \t entropy: 0.523 \t kl_div: 0.000\n",
      "epoch: 161 \t loss: 41.972 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.530 \t kl_div: 0.000\n",
      "epoch: 162 \t loss: 39.366 \t return: 374.000 \t ep_len: 374.000 \t entropy: 0.522 \t kl_div: 0.000\n",
      "epoch: 163 \t loss: 42.209 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.530 \t kl_div: 0.000\n",
      "epoch: 164 \t loss: 40.880 \t return: 426.500 \t ep_len: 426.500 \t entropy: 0.515 \t kl_div: 0.000\n",
      "epoch: 165 \t loss: 41.670 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.536 \t kl_div: 0.000\n",
      "epoch: 166 \t loss: 38.765 \t return: 357.500 \t ep_len: 357.500 \t entropy: 0.522 \t kl_div: 0.000\n",
      "epoch: 167 \t loss: 43.448 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.526 \t kl_div: 0.000\n",
      "epoch: 168 \t loss: 43.073 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.534 \t kl_div: 0.000\n",
      "epoch: 169 \t loss: 39.808 \t return: 377.000 \t ep_len: 377.000 \t entropy: 0.524 \t kl_div: 0.000\n",
      "epoch: 170 \t loss: 42.169 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.527 \t kl_div: 0.000\n",
      "epoch: 171 \t loss: 42.045 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.525 \t kl_div: 0.001\n",
      "epoch: 172 \t loss: 41.632 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.519 \t kl_div: 0.001\n",
      "epoch: 173 \t loss: 42.094 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.516 \t kl_div: 0.001\n",
      "epoch: 174 \t loss: 41.227 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.523 \t kl_div: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 175 \t loss: 40.535 \t return: 417.500 \t ep_len: 417.500 \t entropy: 0.508 \t kl_div: 0.002\n",
      "epoch: 176 \t loss: 41.895 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.514 \t kl_div: 0.001\n",
      "epoch: 177 \t loss: 41.025 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.512 \t kl_div: 0.001\n",
      "epoch: 178 \t loss: 42.293 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.506 \t kl_div: 0.000\n",
      "epoch: 179 \t loss: 41.347 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.515 \t kl_div: 0.001\n",
      "epoch: 180 \t loss: 41.585 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.513 \t kl_div: 0.002\n",
      "epoch: 181 \t loss: 40.458 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.521 \t kl_div: 0.002\n",
      "epoch: 182 \t loss: 41.992 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.511 \t kl_div: 0.001\n",
      "epoch: 183 \t loss: 40.886 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.519 \t kl_div: 0.002\n",
      "epoch: 184 \t loss: 41.679 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.517 \t kl_div: 0.001\n",
      "epoch: 185 \t loss: 40.716 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.527 \t kl_div: 0.001\n",
      "epoch: 186 \t loss: 41.276 \t return: 433.000 \t ep_len: 433.000 \t entropy: 0.510 \t kl_div: 0.001\n",
      "epoch: 187 \t loss: 40.862 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.530 \t kl_div: 0.000\n",
      "epoch: 188 \t loss: 42.094 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.520 \t kl_div: 0.000\n",
      "epoch: 189 \t loss: 41.227 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.526 \t kl_div: 0.000\n",
      "epoch: 190 \t loss: 41.353 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.523 \t kl_div: 0.000\n",
      "epoch: 191 \t loss: 41.502 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.522 \t kl_div: 0.000\n",
      "epoch: 192 \t loss: 41.846 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.517 \t kl_div: 0.000\n",
      "epoch: 193 \t loss: 40.733 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.518 \t kl_div: 0.000\n",
      "epoch: 194 \t loss: 41.539 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.514 \t kl_div: 0.000\n",
      "epoch: 195 \t loss: 41.520 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.503 \t kl_div: 0.000\n",
      "epoch: 196 \t loss: 41.696 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.503 \t kl_div: 0.000\n",
      "epoch: 197 \t loss: 41.795 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.513 \t kl_div: 0.000\n",
      "epoch: 198 \t loss: 41.985 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.509 \t kl_div: 0.000\n",
      "epoch: 199 \t loss: 42.210 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.521 \t kl_div: 0.000\n",
      "epoch: 200 \t loss: 41.170 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.519 \t kl_div: 0.000\n",
      "epoch: 201 \t loss: 41.694 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.527 \t kl_div: 0.000\n",
      "epoch: 202 \t loss: 38.262 \t return: 330.500 \t ep_len: 330.500 \t entropy: 0.517 \t kl_div: 0.000\n",
      "epoch: 203 \t loss: 38.863 \t return: 331.000 \t ep_len: 331.000 \t entropy: 0.516 \t kl_div: 0.000\n",
      "epoch: 204 \t loss: 42.580 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.524 \t kl_div: 0.000\n",
      "epoch: 205 \t loss: 42.230 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.527 \t kl_div: 0.001\n",
      "epoch: 206 \t loss: 41.950 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.536 \t kl_div: 0.000\n",
      "epoch: 207 \t loss: 41.595 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.528 \t kl_div: 0.000\n",
      "epoch: 208 \t loss: 41.010 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.542 \t kl_div: 0.000\n",
      "epoch: 209 \t loss: 39.376 \t return: 332.000 \t ep_len: 332.000 \t entropy: 0.518 \t kl_div: 0.000\n",
      "epoch: 210 \t loss: 41.408 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.523 \t kl_div: 0.000\n",
      "epoch: 211 \t loss: 40.975 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.526 \t kl_div: 0.000\n",
      "epoch: 212 \t loss: 41.583 \t return: 478.500 \t ep_len: 478.500 \t entropy: 0.509 \t kl_div: 0.001\n",
      "epoch: 213 \t loss: 42.227 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.509 \t kl_div: 0.001\n",
      "epoch: 214 \t loss: 41.374 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.519 \t kl_div: 0.000\n",
      "epoch: 215 \t loss: 40.995 \t return: 422.000 \t ep_len: 422.000 \t entropy: 0.504 \t kl_div: 0.000\n",
      "epoch: 216 \t loss: 40.833 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.523 \t kl_div: 0.000\n",
      "epoch: 217 \t loss: 41.197 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.525 \t kl_div: 0.000\n",
      "epoch: 218 \t loss: 42.530 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.511 \t kl_div: 0.000\n",
      "epoch: 219 \t loss: 42.672 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.516 \t kl_div: 0.000\n",
      "epoch: 220 \t loss: 39.214 \t return: 380.000 \t ep_len: 380.000 \t entropy: 0.512 \t kl_div: 0.000\n",
      "epoch: 221 \t loss: 40.329 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.527 \t kl_div: 0.001\n",
      "epoch: 222 \t loss: 40.219 \t return: 280.000 \t ep_len: 280.000 \t entropy: 0.501 \t kl_div: 0.002\n",
      "epoch: 223 \t loss: 39.128 \t return: 404.000 \t ep_len: 404.000 \t entropy: 0.513 \t kl_div: 0.001\n",
      "epoch: 224 \t loss: 38.356 \t return: 286.000 \t ep_len: 286.000 \t entropy: 0.524 \t kl_div: 0.006\n",
      "epoch: 225 \t loss: 42.079 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.526 \t kl_div: 0.006\n",
      "epoch: 226 \t loss: 41.974 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.527 \t kl_div: 0.007\n",
      "epoch: 227 \t loss: 38.683 \t return: 281.000 \t ep_len: 281.000 \t entropy: 0.521 \t kl_div: 0.005\n",
      "epoch: 228 \t loss: 41.046 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.524 \t kl_div: 0.004\n",
      "epoch: 229 \t loss: 42.506 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.516 \t kl_div: 0.004\n",
      "epoch: 230 \t loss: 40.810 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.525 \t kl_div: 0.001\n",
      "epoch: 231 \t loss: 41.110 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.515 \t kl_div: 0.000\n",
      "epoch: 232 \t loss: 37.214 \t return: 283.000 \t ep_len: 283.000 \t entropy: 0.509 \t kl_div: 0.001\n",
      "epoch: 233 \t loss: 39.931 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.510 \t kl_div: 0.002\n",
      "epoch: 234 \t loss: 36.923 \t return: 291.000 \t ep_len: 291.000 \t entropy: 0.499 \t kl_div: 0.003\n",
      "epoch: 235 \t loss: 38.194 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.509 \t kl_div: 0.003\n",
      "epoch: 236 \t loss: 39.028 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.502 \t kl_div: 0.003\n",
      "epoch: 237 \t loss: 39.570 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.491 \t kl_div: 0.000\n",
      "epoch: 238 \t loss: 38.433 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.496 \t kl_div: 0.002\n",
      "epoch: 239 \t loss: 39.047 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.484 \t kl_div: 0.001\n",
      "epoch: 240 \t loss: 38.363 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.487 \t kl_div: 0.002\n",
      "epoch: 241 \t loss: 39.182 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.482 \t kl_div: 0.004\n",
      "epoch: 242 \t loss: 37.943 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.491 \t kl_div: 0.000\n",
      "epoch: 243 \t loss: 34.898 \t return: 318.000 \t ep_len: 318.000 \t entropy: 0.469 \t kl_div: 0.000\n",
      "epoch: 244 \t loss: 34.615 \t return: 370.000 \t ep_len: 370.000 \t entropy: 0.479 \t kl_div: 0.002\n",
      "epoch: 245 \t loss: 30.111 \t return: 255.500 \t ep_len: 255.500 \t entropy: 0.473 \t kl_div: 0.002\n",
      "epoch: 246 \t loss: 33.671 \t return: 232.000 \t ep_len: 232.000 \t entropy: 0.460 \t kl_div: 0.002\n",
      "epoch: 247 \t loss: 31.804 \t return: 293.000 \t ep_len: 293.000 \t entropy: 0.462 \t kl_div: 0.002\n",
      "epoch: 248 \t loss: 27.383 \t return: 202.333 \t ep_len: 202.333 \t entropy: 0.458 \t kl_div: 0.005\n",
      "epoch: 249 \t loss: 30.915 \t return: 264.500 \t ep_len: 264.500 \t entropy: 0.461 \t kl_div: 0.004\n",
      "epoch: 250 \t loss: 22.689 \t return: 147.400 \t ep_len: 147.400 \t entropy: 0.457 \t kl_div: 0.005\n",
      "epoch: 251 \t loss: 17.962 \t return: 118.600 \t ep_len: 118.600 \t entropy: 0.462 \t kl_div: 0.004\n",
      "epoch: 252 \t loss: 21.337 \t return: 143.600 \t ep_len: 143.600 \t entropy: 0.461 \t kl_div: 0.000\n",
      "epoch: 253 \t loss: 20.183 \t return: 110.000 \t ep_len: 110.000 \t entropy: 0.444 \t kl_div: 0.000\n",
      "epoch: 254 \t loss: 19.758 \t return: 121.000 \t ep_len: 121.000 \t entropy: 0.449 \t kl_div: 0.001\n",
      "epoch: 255 \t loss: 16.960 \t return: 92.667 \t ep_len: 92.667 \t entropy: 0.442 \t kl_div: 0.001\n",
      "epoch: 256 \t loss: 24.710 \t return: 168.000 \t ep_len: 168.000 \t entropy: 0.451 \t kl_div: 0.002\n",
      "epoch: 257 \t loss: 24.320 \t return: 174.750 \t ep_len: 174.750 \t entropy: 0.456 \t kl_div: 0.002\n",
      "epoch: 258 \t loss: 24.138 \t return: 167.667 \t ep_len: 167.667 \t entropy: 0.457 \t kl_div: 0.002\n",
      "epoch: 259 \t loss: 33.413 \t return: 336.000 \t ep_len: 336.000 \t entropy: 0.452 \t kl_div: 0.005\n",
      "epoch: 260 \t loss: 30.245 \t return: 279.500 \t ep_len: 279.500 \t entropy: 0.455 \t kl_div: 0.001\n",
      "epoch: 261 \t loss: 32.742 \t return: 266.500 \t ep_len: 266.500 \t entropy: 0.461 \t kl_div: 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 262 \t loss: 37.207 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.448 \t kl_div: 0.007\n",
      "epoch: 263 \t loss: 35.779 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.453 \t kl_div: 0.005\n",
      "epoch: 264 \t loss: 29.463 \t return: 306.000 \t ep_len: 306.000 \t entropy: 0.458 \t kl_div: 0.007\n",
      "epoch: 265 \t loss: 34.307 \t return: 345.500 \t ep_len: 345.500 \t entropy: 0.433 \t kl_div: 0.002\n",
      "epoch: 266 \t loss: 31.463 \t return: 300.000 \t ep_len: 300.000 \t entropy: 0.441 \t kl_div: 0.005\n",
      "epoch: 267 \t loss: 35.440 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.442 \t kl_div: 0.004\n",
      "epoch: 268 \t loss: 31.599 \t return: 300.500 \t ep_len: 300.500 \t entropy: 0.438 \t kl_div: 0.003\n",
      "epoch: 269 \t loss: 33.095 \t return: 308.000 \t ep_len: 308.000 \t entropy: 0.433 \t kl_div: 0.002\n",
      "epoch: 270 \t loss: 30.987 \t return: 302.500 \t ep_len: 302.500 \t entropy: 0.437 \t kl_div: 0.001\n",
      "epoch: 271 \t loss: 33.377 \t return: 344.500 \t ep_len: 344.500 \t entropy: 0.429 \t kl_div: 0.001\n",
      "epoch: 272 \t loss: 31.507 \t return: 304.500 \t ep_len: 304.500 \t entropy: 0.433 \t kl_div: 0.000\n",
      "epoch: 273 \t loss: 35.842 \t return: 500.000 \t ep_len: 500.000 \t entropy: 0.425 \t kl_div: 0.000\n",
      "epoch: 274 \t loss: 33.055 \t return: 384.500 \t ep_len: 384.500 \t entropy: 0.425 \t kl_div: 0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-b6a4b46b4362>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mrender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#     render = False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mbatch_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkl_div\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mmean_rew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmean_rew_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmean_rew\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-119-c16d7a119ac8>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(env, net, batch_size, render)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mbatch_obs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mbatch_acts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-e0cdb5366ba9>\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(net, obs)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\distributions\\categorical.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, sample_shape)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0msample_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mparam_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_events\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mprobs_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_events\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\distributions\\utils.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, instance, obj_type)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\distributions\\categorical.py\u001b[0m in \u001b[0;36mprobs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mlazy_property\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlogits_to_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\distributions\\utils.py\u001b[0m in \u001b[0;36mlogits_to_probs\u001b[1;34m(logits, is_binary)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_binary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "rew_req = 200\n",
    "i=0\n",
    "mean_rew = 0\n",
    "mean_rew_sum = 0\n",
    "avg_rew = 0\n",
    "\n",
    "while i<500:\n",
    "    i+=1\n",
    "    render = True if i%20==0 else False\n",
    "#     render = False\n",
    "    batch_loss,batch_ret, batch_len, entropy, kl_div = train_one_epoch(env, net,batch_size=BATCH_SIZE, render=render)\n",
    "    mean_rew = np.mean(batch_ret)\n",
    "    mean_rew_sum += mean_rew\n",
    "    avg_rew = mean_rew_sum/i\n",
    "    if render:\n",
    "        env.close()\n",
    "    print('epoch: %3d \\t loss: %.3f \\t return: %.3f \\t ep_len: %.3f \\t entropy: %.3f \\t kl_div: %.3f'%\n",
    "                (i, batch_loss, np.mean(batch_ret), np.mean(batch_len), entropy,kl_div))\n",
    "    writer.add_scalar(\"loss\", batch_loss, i)\n",
    "    writer.add_scalar(\"reward_mean\", mean_rew, i)\n",
    "    writer.add_scalar(\"kl_div\", kl_div, i)\n",
    "    writer.add_scalar(\"entropy\", entropy,i)\n",
    "#     writer.add_scalar(\"rew_baseline\", baseline,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Categorical(logits = torch.FloatTensor([[1,0,1],[1,1,1],[1,0,0]]))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0174, -1.0986, -0.9753])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c.probs * torch.log(c.probs)).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0174, 1.0986, 0.9753])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 16, 49]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [0,0,0]\n",
    "for i in range(0,100):\n",
    "    x = c.sample().item()\n",
    "    count[x]+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8620)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.log_prob(torch.as_tensor(0, dtype=torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =([2]*8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ([1]*3 + [2]*5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2500)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.FloatTensor(x)*torch.FloatTensor(y)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_to_go([1,0,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.930499, 2.9601, 2.99, 1.0, 0.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_rtg([1,0,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36119184, -0.36119184, -0.36651629])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.3,0.3,0.4] * np.log([0.3,0.3,0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3]\n",
    "y = []\n",
    "y.append(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[4,2,3]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.append(x.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 2, 3]]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 2, 3], [4, 2, 3]]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.3292841e-01,  1.3936392e+38,  2.2844117e-02,  8.5078421e+37],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([79045296309277814133001641918405279744.,\n",
       "         8074543887068950992878338433657864192.], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.FloatTensor(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = Categorical(net(torch.FloatTensor(obs)))\n",
    "c2.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3786, grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.log_prob(torch.as_tensor(1, dtype = torch.int32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
