{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,obs_size, hidden_size,n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(obs_size,hidden_size),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(hidden_size,n_actions))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions.normal import Normal\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Categorical(logits = torch.FloatTensor([1,0,1]))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47, 18, 35]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [0,0,0]\n",
    "for i in range(0,100):\n",
    "    x = c.sample().item()\n",
    "    count[x]+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8620)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.log_prob(torch.as_tensor(0, dtype=torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =([2]*8)\n",
    "x = torch.FloatTensor(x)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = ([1]*3 + [2]*5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2500)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.FloatTensor(x)*torch.FloatTensor(y)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 1, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_to_go([1,0,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.7483314773547883)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,0,2,1,0]),np.std([1,0,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy(net, obs):\n",
    "    logits = net(obs)\n",
    "    return Categorical(logits=logits)\n",
    "\n",
    "def get_policy_cont(net, obs):\n",
    "    mu = net(obs)\n",
    "    mu = torch.tanh(mu)*1.8\n",
    "    return Normal(loc=mu, scale=STD)\n",
    "\n",
    "def get_action(net, obs, cont=False):\n",
    "    if cont:\n",
    "        policy = get_policy_cont(net, obs)\n",
    "    else:\n",
    "        policy = get_policy(net, obs)\n",
    "    act = policy.sample().item()\n",
    "    if cont:\n",
    "        act = np.array([act])\n",
    "    return act\n",
    "\n",
    "def reward_to_go(rews):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + (rtgs[i+1] if i+1 < n else 0)\n",
    "    return rtgs\n",
    "\n",
    "def reward_to_go_avg(rews, avg):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + (rtgs[i+1] if i+1 < n else 0) - avg/n\n",
    "    return rtgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(obs, acts, wts, net, cont=False):\n",
    "#     obs_v = torch.FloatTensor(obs)\n",
    "    if cont:\n",
    "        policy = get_policy_cont(net, obs)\n",
    "    else:\n",
    "        policy = get_policy(net,obs)\n",
    "#     print(policy)\n",
    "#     pdb.set_trace()\n",
    "    log_p = policy.log_prob(acts)\n",
    "    return -(log_p*wts).mean(), policy.entropy().mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic_targets(eps_rews):\n",
    "    targets = []\n",
    "    val = 0\n",
    "    for i in reversed(range(len(eps_rews))):\n",
    "        val = val*GAMMA + eps_rews[i]\n",
    "        targets.append(val)\n",
    "    targets = targets[::-1]\n",
    "    return targets\n",
    "\n",
    "def get_critic_targets_biased(eps_rews, eps_obs, critic):\n",
    "    targets = []\n",
    "\n",
    "    eps_rews = torch.as_tensor(eps_rews,dtype=torch.float32)\n",
    "        \n",
    "#     pdb.set_trace()\n",
    "    \n",
    "#     eps_rews = (eps_rews - torch.mean(eps_rews))/(torch.std(eps_rews))\n",
    "    eps_rews = eps_rews / torch.sum(eps_rews)\n",
    "    \n",
    "    \n",
    "    for i in range(len(eps_obs)):\n",
    "        if (i==len(eps_obs)-1):\n",
    "            val = eps_rews[i]\n",
    "        else:\n",
    "            next_obs = eps_obs[i+1]\n",
    "            val = eps_rews[i] + GAMMA*critic(torch.as_tensor(next_obs, dtype=torch.float32))\n",
    "        targets.append(val)\n",
    "        \n",
    "    \n",
    "    return targets\n",
    "\n",
    "def get_advantage(batch_obs, batch_rews, critic):\n",
    "#     batch_obs = torch.as_tensor(batch_obs, dtype = torch.float32)\n",
    "    targets = []\n",
    "    \n",
    "    batch_rews = torch.as_tensor(batch_rews,dtype=torch.float32)\n",
    "    \n",
    "#     batch_rews = (batch_rews - torch.mean(batch_rews))/(torch.std(batch_rews))\n",
    "    batch_rews = batch_rews/torch.sum(batch_rews)\n",
    "    \n",
    "    for i in range(len(batch_obs)):\n",
    "        obs = batch_obs[i]\n",
    "        obs = torch.as_tensor(obs, dtype = torch.float32)\n",
    "        \n",
    "        if (i==len(batch_obs)-1):\n",
    "            target = batch_rews[i] - critic(obs).item() \n",
    "        else:\n",
    "            next_obs = batch_obs[i+1]\n",
    "            next_obs = torch.as_tensor(next_obs, dtype = torch.float32)\n",
    "            target = batch_rews[i] + GAMMA*(critic(next_obs).item()) - critic(obs).item()\n",
    "        \n",
    "        targets.append(target.item())\n",
    "    \n",
    "    # last advantage should just be the rew\n",
    "#     targets.append(batch_rews[-1])\n",
    "    \n",
    "    return targets\n",
    "\n",
    "\n",
    "def get_batch_advantage(batch_obs, batch_rew, critic):\n",
    "    advantage = []\n",
    "    for i in range(len(batch_obs)):\n",
    "        eps_obs = batch_obs[i]\n",
    "        eps_rew = batch_rew[i]\n",
    "        adv = []\n",
    "#         eps_obs = torch.as_tensor(batch_obs, dtype = torch.float32)\n",
    "        for j in range(len(eps_obs)):\n",
    "            obs = eps_obs[j]\n",
    "            obs = torch.as_tensor(obs, dtype = torch.float32)\n",
    "            \n",
    "            if (j==len(eps_obs)-1):\n",
    "                val = eps_rew[j] - critic(obs).item()\n",
    "            else:\n",
    "                next_obs = eps_obs[j+1]\n",
    "                next_obs = torch.as_tensor(next_obs, dtype = torch.float32)\n",
    "                val = eps_rew[j] + GAMMA*critic(next_obs).item() - critic(obs).item()\n",
    "            adv.append(val)\n",
    "            \n",
    "        advantage.extend(adv)\n",
    "    \n",
    "    return advantage\n",
    "\n",
    "def get_normalised_adv_targets(ep_obs, ep_rews, critic):\n",
    "    rewards = []\n",
    "    disc_rew = 0\n",
    "    for rew in ep_rews[::-1]:\n",
    "        disc_rew = GAMMA*disc_rew + rew\n",
    "        rewards.append(disc_rew)\n",
    "        \n",
    "    returns = rewards[::-1]\n",
    "    eps = 1e-6\n",
    "\n",
    "    returns = torch.tensor(returns)\n",
    "    returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "    \n",
    "#     targets=rewards\n",
    "    targets = returns\n",
    "    advantage = []\n",
    "    \n",
    "    ep_obs = torch.as_tensor(ep_obs, dtype = torch.float32)\n",
    "    \n",
    "#     for obs, rew in zip(ep_obs, returns):\n",
    "#         adv = rew - critic(obs)\n",
    "#         advantage.append(adv.item())\n",
    "    \n",
    "    for i in range(len(ep_obs)):\n",
    "        a = returns[i] - critic(ep_obs[i])\n",
    "#         if (i==len(ep_obs)-1):\n",
    "#             a = rewards[i] - critic(ep_obs[i])\n",
    "#         else:\n",
    "#             a = rewards[i] + critic(ep_obs[i+1]) - critic(ep_obs[i])\n",
    "        \n",
    "        advantage.append(a.item())\n",
    "    \n",
    "    return advantage, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0, 1, 5, 4]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,1,0,0,0,1]\n",
    "get_critic_targets(x)\n",
    "y = [5,4]\n",
    "x.extend(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(env, net,critic, cont, batch_size=5000, render=False):\n",
    "    batch_obs = []\n",
    "    batch_wts = []\n",
    "    batch_acts = []\n",
    "    batch_rets = []\n",
    "    batch_len = []\n",
    "    eps_rew = []\n",
    "    batch_rews = []\n",
    "    targets = []\n",
    "    advantage = []\n",
    "    eps_obs = []\n",
    "    obs = env.reset()\n",
    "    done=False\n",
    "    epoch_finished_rendering = False\n",
    "    \n",
    "    batch_pack_obs = []\n",
    "    batch_pack_rew = []\n",
    "    \n",
    "    while True:\n",
    "        if not epoch_finished_rendering and render:\n",
    "            env.render()\n",
    "        \n",
    "        act = get_action(net, obs = torch.as_tensor(obs,dtype=torch.float32), cont=cont)\n",
    "        batch_obs.append(obs.copy())\n",
    "        batch_acts.append(act)\n",
    "        \n",
    "        eps_obs.append(obs)\n",
    "        \n",
    "        obs,rew,done,_ = env.step(act)\n",
    "        \n",
    "        eps_rew.append(rew)\n",
    "        \n",
    "        batch_rews.append(rew)\n",
    "#         obs= next_obs\n",
    "        \n",
    "        if done:\n",
    "            eps_ret = sum(eps_rew)\n",
    "            eps_len = len(eps_rew)\n",
    "            batch_rets.append(eps_ret)\n",
    "            batch_len.append(eps_len)\n",
    "            \n",
    "#             eps_target = get_critic_targets(eps_rew)\n",
    "#             eps_target = get_critic_targets_biased(eps_rew,eps_obs, critic)\n",
    "#             targets.extend(eps_target)\n",
    "            \n",
    "#             # get advantage estimate\n",
    "#             adv = get_advantage(eps_obs, eps_rew, critic)\n",
    "#             advantage.extend(adv)\n",
    "\n",
    "\n",
    "            batch_pack_obs.append(eps_obs)\n",
    "            batch_pack_rew.append(eps_rew)\n",
    "        \n",
    "            ep_adv, ep_targ = get_normalised_adv_targets(eps_obs, eps_rew, critic)\n",
    "            advantage.extend(ep_adv)\n",
    "            targets.extend(ep_targ)\n",
    "            \n",
    "            #plain\n",
    "#             batch_wts = batch_wts + [eps_ret]*eps_len\n",
    "\n",
    "            #subtract avg reward\n",
    "#             batch_wts = batch_wts + [eps_ret- avg_rew]*eps_len\n",
    "            \n",
    "            # reward to-go\n",
    "#             batch_wts = batch_wts + list(reward_to_go(eps_rew))\n",
    "\n",
    "            # reward to-go with avg rew\n",
    "#             batch_wts = batch_wts + list(reward_to_go_avg(eps_rew, avg_rew))\n",
    "            \n",
    "            eps_rew = []\n",
    "            eps_obs = []\n",
    "            done = False\n",
    "            \n",
    "            obs = env.reset()\n",
    "            epoch_finished_rendering = True\n",
    "            \n",
    "            if len(batch_obs)>batch_size:\n",
    "                break\n",
    "    \n",
    "    # critic update\n",
    "    pred_values = critic(torch.as_tensor(batch_obs, dtype = torch.float32))\n",
    "#     actual_values = get_critic_targets(batch_rews)\n",
    "    \n",
    "    optimizer_critic.zero_grad()\n",
    "    batch_loss_critic = loss_mae(pred_values.reshape(-1),\n",
    "                                 torch.as_tensor(targets, dtype = torch.float32))\n",
    "    batch_loss_critic.backward()\n",
    "    optimizer_critic.step()\n",
    "    \n",
    "#     # get advantage estimate\n",
    "#     advantage = get_advantage(batch_obs, batch_rews, critic)\n",
    "#     advantage = get_batch_advantage(batch_pack_obs, batch_pack_rew, critic)\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    # policy network update\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if cont:\n",
    "        batch_act_v = torch.as_tensor(batch_acts, dtype=torch.float32)\n",
    "    else:\n",
    "        batch_act_v = torch.as_tensor(batch_acts, dtype = torch.int32)\n",
    "    \n",
    "    batch_loss, entropy_v = compute_loss(obs = torch.as_tensor(batch_obs, dtype=torch.float32),\n",
    "                              acts = batch_act_v,\n",
    "                              wts = torch.as_tensor(advantage, dtype = torch.float32),\n",
    "                             net = net,cont=cont)\n",
    "    \n",
    "    entropy = entropy_v.item()\n",
    "    \n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    return batch_loss,batch_rets, batch_len, batch_loss_critic, advantage, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "env = gym.make('LunarLander-v2')\n",
    "cont = False\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "\n",
    "if cont:\n",
    "    n_actions = env.action_space.shape[0]\n",
    "else:\n",
    "    n_actions = env.action_space.n\n",
    "obs_size, n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(8,), Discrete(4))"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 32\n",
    "BATCH_SIZE = 500\n",
    "GAMMA = 0.99\n",
    "STD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(obs_size = obs_size, hidden_size = HIDDEN_SIZE, n_actions= n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "act = get_action(net, obs= torch.as_tensor(obs, dtype=torch.float32), cont=cont)\n",
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical()"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "pol = get_policy(net, obs= torch.as_tensor(obs, dtype=torch.float32))\n",
    "# pol = get_policy_cont(net,obs= torch.as_tensor(obs, dtype=torch.float32))\n",
    "pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Categorical' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-467-b52a2c8e9a0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Categorical' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "pol.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.6612, grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol.log_prob(torch.as_tensor(act, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = env.action_space.sample()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "lr = 1e-2\n",
    "optimizer = Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic\n",
    "critic = Net(obs_size = obs_size, hidden_size = HIDDEN_SIZE, n_actions=1)\n",
    "lr_c = 1e-2\n",
    "optimizer_critic = Adam(critic.parameters(), lr=lr_c)\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "loss_mae = MSELoss(reduction='sum')\n",
    "# loss_mae = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0424], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "value = critic(torch.as_tensor(obs, dtype=torch.float32))\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(comment=\"-actor_critic_mntcar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 \t loss: 0.011 \t return: -166.005 \t ep_len: 86.667 \t critic_loss: 557.426 \t adv: 0.005\n",
      "epoch:   2 \t loss: -0.011 \t return: -304.225 \t ep_len: 113.200 \t critic_loss: 558.280 \t adv: -0.019\n",
      "epoch:   3 \t loss: 0.012 \t return: -133.544 \t ep_len: 93.500 \t critic_loss: 586.948 \t adv: 0.007\n",
      "epoch:   4 \t loss: -0.083 \t return: -349.428 \t ep_len: 99.833 \t critic_loss: 536.006 \t adv: -0.068\n",
      "epoch:   5 \t loss: 0.049 \t return: -167.461 \t ep_len: 87.500 \t critic_loss: 517.839 \t adv: 0.033\n",
      "epoch:   6 \t loss: 0.010 \t return: -269.968 \t ep_len: 105.200 \t critic_loss: 502.290 \t adv: 0.011\n",
      "epoch:   7 \t loss: -0.012 \t return: -173.752 \t ep_len: 90.667 \t critic_loss: 521.423 \t adv: 0.010\n",
      "epoch:   8 \t loss: 0.320 \t return: -192.112 \t ep_len: 104.400 \t critic_loss: 602.143 \t adv: 0.234\n",
      "epoch:   9 \t loss: 0.150 \t return: -162.837 \t ep_len: 80.286 \t critic_loss: 566.544 \t adv: 0.111\n",
      "epoch:  10 \t loss: 0.239 \t return: -190.630 \t ep_len: 107.600 \t critic_loss: 617.755 \t adv: 0.152\n",
      "epoch:  11 \t loss: 0.005 \t return: -126.285 \t ep_len: 99.833 \t critic_loss: 616.612 \t adv: -0.003\n",
      "epoch:  12 \t loss: 0.089 \t return: -245.283 \t ep_len: 120.000 \t critic_loss: 539.541 \t adv: 0.076\n",
      "epoch:  13 \t loss: -0.019 \t return: -187.306 \t ep_len: 99.500 \t critic_loss: 609.337 \t adv: -0.029\n",
      "epoch:  14 \t loss: -0.248 \t return: -155.976 \t ep_len: 110.800 \t critic_loss: 566.974 \t adv: -0.164\n",
      "epoch:  15 \t loss: -0.225 \t return: -151.581 \t ep_len: 132.000 \t critic_loss: 479.921 \t adv: -0.168\n",
      "epoch:  16 \t loss: -0.333 \t return: -172.905 \t ep_len: 151.750 \t critic_loss: 598.046 \t adv: -0.240\n",
      "epoch:  17 \t loss: -0.268 \t return: -87.127 \t ep_len: 95.167 \t critic_loss: 517.626 \t adv: -0.179\n",
      "epoch:  18 \t loss: -0.188 \t return: -226.681 \t ep_len: 150.250 \t critic_loss: 558.513 \t adv: -0.138\n",
      "epoch:  19 \t loss: -0.091 \t return: -81.548 \t ep_len: 96.000 \t critic_loss: 493.834 \t adv: -0.058\n",
      "epoch:  20 \t loss: -0.047 \t return: -215.839 \t ep_len: 131.750 \t critic_loss: 444.681 \t adv: -0.030\n",
      "epoch:  21 \t loss: -0.051 \t return: -181.510 \t ep_len: 136.250 \t critic_loss: 482.656 \t adv: -0.047\n",
      "epoch:  22 \t loss: -0.212 \t return: -168.714 \t ep_len: 159.250 \t critic_loss: 733.332 \t adv: -0.179\n",
      "epoch:  23 \t loss: 0.094 \t return: -157.119 \t ep_len: 108.200 \t critic_loss: 434.424 \t adv: 0.065\n",
      "epoch:  24 \t loss: -0.040 \t return: -148.801 \t ep_len: 127.750 \t critic_loss: 455.984 \t adv: 0.002\n",
      "epoch:  25 \t loss: 0.101 \t return: -247.842 \t ep_len: 149.250 \t critic_loss: 472.195 \t adv: 0.085\n",
      "epoch:  26 \t loss: 0.043 \t return: -137.566 \t ep_len: 130.000 \t critic_loss: 482.378 \t adv: 0.061\n",
      "epoch:  27 \t loss: 0.065 \t return: -169.328 \t ep_len: 126.000 \t critic_loss: 578.350 \t adv: 0.046\n",
      "epoch:  28 \t loss: -0.064 \t return: -159.319 \t ep_len: 124.800 \t critic_loss: 566.653 \t adv: -0.024\n",
      "epoch:  29 \t loss: -0.049 \t return: -137.717 \t ep_len: 159.250 \t critic_loss: 429.362 \t adv: -0.017\n",
      "epoch:  30 \t loss: 0.080 \t return: -146.947 \t ep_len: 124.200 \t critic_loss: 704.864 \t adv: 0.105\n",
      "epoch:  31 \t loss: -0.138 \t return: -162.094 \t ep_len: 156.000 \t critic_loss: 549.486 \t adv: -0.098\n",
      "epoch:  32 \t loss: -0.079 \t return: -147.515 \t ep_len: 170.250 \t critic_loss: 626.880 \t adv: -0.057\n",
      "epoch:  33 \t loss: -0.232 \t return: -200.369 \t ep_len: 129.500 \t critic_loss: 642.654 \t adv: -0.134\n",
      "epoch:  34 \t loss: 0.064 \t return: -164.878 \t ep_len: 141.250 \t critic_loss: 424.893 \t adv: 0.081\n",
      "epoch:  35 \t loss: 0.032 \t return: -134.654 \t ep_len: 132.400 \t critic_loss: 465.994 \t adv: 0.058\n",
      "epoch:  36 \t loss: -0.119 \t return: -191.208 \t ep_len: 135.750 \t critic_loss: 697.545 \t adv: -0.012\n",
      "epoch:  37 \t loss: -0.031 \t return: -142.256 \t ep_len: 147.500 \t critic_loss: 465.654 \t adv: 0.002\n",
      "epoch:  38 \t loss: -0.292 \t return: -178.823 \t ep_len: 190.500 \t critic_loss: 761.797 \t adv: -0.213\n",
      "epoch:  39 \t loss: -0.170 \t return: -159.617 \t ep_len: 170.000 \t critic_loss: 459.825 \t adv: -0.153\n",
      "epoch:  40 \t loss: -0.291 \t return: -172.416 \t ep_len: 209.333 \t critic_loss: 561.138 \t adv: -0.219\n",
      "epoch:  41 \t loss: -0.178 \t return: -156.045 \t ep_len: 134.250 \t critic_loss: 485.479 \t adv: -0.168\n",
      "epoch:  42 \t loss: -0.156 \t return: -196.239 \t ep_len: 193.667 \t critic_loss: 650.305 \t adv: -0.144\n",
      "epoch:  43 \t loss: 0.160 \t return: -154.773 \t ep_len: 179.667 \t critic_loss: 365.006 \t adv: 0.107\n",
      "epoch:  44 \t loss: 0.158 \t return: -183.235 \t ep_len: 196.667 \t critic_loss: 461.444 \t adv: 0.162\n",
      "epoch:  45 \t loss: -0.113 \t return: -207.417 \t ep_len: 245.000 \t critic_loss: 609.208 \t adv: -0.053\n",
      "epoch:  46 \t loss: 0.330 \t return: -122.968 \t ep_len: 152.000 \t critic_loss: 477.864 \t adv: 0.296\n",
      "epoch:  47 \t loss: 0.386 \t return: -80.562 \t ep_len: 152.000 \t critic_loss: 475.030 \t adv: 0.334\n",
      "epoch:  48 \t loss: 0.258 \t return: -22.658 \t ep_len: 222.000 \t critic_loss: 610.390 \t adv: 0.244\n",
      "epoch:  49 \t loss: 0.240 \t return: -77.015 \t ep_len: 134.500 \t critic_loss: 423.558 \t adv: 0.214\n",
      "epoch:  50 \t loss: 0.078 \t return: -141.130 \t ep_len: 125.250 \t critic_loss: 389.289 \t adv: 0.120\n",
      "epoch:  51 \t loss: 0.061 \t return: -75.959 \t ep_len: 184.333 \t critic_loss: 348.630 \t adv: 0.083\n",
      "epoch:  52 \t loss: 0.048 \t return: -29.964 \t ep_len: 158.750 \t critic_loss: 341.043 \t adv: 0.035\n",
      "epoch:  53 \t loss: -0.177 \t return: -61.568 \t ep_len: 162.750 \t critic_loss: 395.921 \t adv: -0.124\n",
      "epoch:  54 \t loss: -0.001 \t return: -74.077 \t ep_len: 167.000 \t critic_loss: 227.405 \t adv: 0.004\n",
      "epoch:  55 \t loss: -0.160 \t return: -19.670 \t ep_len: 166.500 \t critic_loss: 329.280 \t adv: -0.135\n",
      "epoch:  56 \t loss: -0.290 \t return: -32.112 \t ep_len: 179.750 \t critic_loss: 377.963 \t adv: -0.247\n",
      "epoch:  57 \t loss: -0.351 \t return: -90.380 \t ep_len: 178.667 \t critic_loss: 259.133 \t adv: -0.292\n",
      "epoch:  58 \t loss: -0.217 \t return: -18.651 \t ep_len: 137.500 \t critic_loss: 260.493 \t adv: -0.203\n",
      "epoch:  59 \t loss: -0.374 \t return: -36.616 \t ep_len: 187.000 \t critic_loss: 280.920 \t adv: -0.291\n",
      "epoch:  60 \t loss: -0.306 \t return: -62.600 \t ep_len: 144.500 \t critic_loss: 245.346 \t adv: -0.214\n",
      "epoch:  61 \t loss: 0.589 \t return: -135.031 \t ep_len: 342.000 \t critic_loss: 1323.045 \t adv: 0.490\n",
      "epoch:  62 \t loss: 0.812 \t return: -28.188 \t ep_len: 593.500 \t critic_loss: 1345.992 \t adv: 0.681\n",
      "epoch:  63 \t loss: 0.738 \t return: -9.968 \t ep_len: 618.000 \t critic_loss: 1384.028 \t adv: 0.632\n",
      "epoch:  64 \t loss: -0.173 \t return: 22.656 \t ep_len: 198.000 \t critic_loss: 166.354 \t adv: -0.123\n",
      "epoch:  65 \t loss: 0.808 \t return: 4.923 \t ep_len: 1000.000 \t critic_loss: 1012.262 \t adv: 0.732\n",
      "epoch:  66 \t loss: -0.045 \t return: -58.983 \t ep_len: 289.000 \t critic_loss: 275.834 \t adv: -0.052\n",
      "epoch:  67 \t loss: 0.150 \t return: -60.347 \t ep_len: 482.000 \t critic_loss: 1233.938 \t adv: 0.142\n",
      "epoch:  68 \t loss: 0.131 \t return: -130.813 \t ep_len: 624.000 \t critic_loss: 810.815 \t adv: 0.123\n",
      "epoch:  69 \t loss: 0.205 \t return: -11.819 \t ep_len: 1000.000 \t critic_loss: 568.168 \t adv: 0.200\n",
      "epoch:  70 \t loss: -0.162 \t return: -203.947 \t ep_len: 892.000 \t critic_loss: 367.981 \t adv: -0.108\n",
      "epoch:  71 \t loss: -0.049 \t return: -79.673 \t ep_len: 1000.000 \t critic_loss: 558.018 \t adv: -0.015\n",
      "epoch:  72 \t loss: -0.891 \t return: -9.737 \t ep_len: 211.667 \t critic_loss: 658.613 \t adv: -0.789\n",
      "epoch:  73 \t loss: -0.340 \t return: -88.561 \t ep_len: 458.667 \t critic_loss: 1068.897 \t adv: -0.292\n",
      "epoch:  74 \t loss: -0.092 \t return: 6.021 \t ep_len: 600.500 \t critic_loss: 895.908 \t adv: -0.078\n",
      "epoch:  75 \t loss: -0.795 \t return: -61.040 \t ep_len: 320.500 \t critic_loss: 642.251 \t adv: -0.686\n",
      "epoch:  76 \t loss: -0.170 \t return: -4.259 \t ep_len: 1000.000 \t critic_loss: 563.353 \t adv: -0.108\n",
      "epoch:  77 \t loss: 0.009 \t return: -7.286 \t ep_len: 1000.000 \t critic_loss: 751.422 \t adv: 0.047\n",
      "epoch:  78 \t loss: -0.575 \t return: -17.146 \t ep_len: 275.500 \t critic_loss: 460.235 \t adv: -0.512\n",
      "epoch:  79 \t loss: -0.243 \t return: -86.968 \t ep_len: 415.500 \t critic_loss: 488.365 \t adv: -0.188\n",
      "epoch:  80 \t loss: -0.526 \t return: -113.186 \t ep_len: 441.000 \t critic_loss: 1370.355 \t adv: -0.494\n",
      "epoch:  81 \t loss: 0.109 \t return: 14.814 \t ep_len: 1000.000 \t critic_loss: 631.328 \t adv: 0.150\n",
      "epoch:  82 \t loss: -0.244 \t return: -93.956 \t ep_len: 310.000 \t critic_loss: 526.712 \t adv: -0.199\n",
      "epoch:  83 \t loss: 0.285 \t return: -19.587 \t ep_len: 1000.000 \t critic_loss: 824.969 \t adv: 0.253\n",
      "epoch:  84 \t loss: -0.259 \t return: -17.180 \t ep_len: 238.333 \t critic_loss: 424.121 \t adv: -0.207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  85 \t loss: 0.004 \t return: -28.831 \t ep_len: 1000.000 \t critic_loss: 727.586 \t adv: 0.033\n",
      "epoch:  86 \t loss: 0.141 \t return: -17.105 \t ep_len: 477.667 \t critic_loss: 958.885 \t adv: 0.135\n",
      "epoch:  87 \t loss: 0.023 \t return: -6.371 \t ep_len: 630.500 \t critic_loss: 761.966 \t adv: 0.035\n",
      "epoch:  88 \t loss: -0.334 \t return: 6.738 \t ep_len: 189.333 \t critic_loss: 360.573 \t adv: -0.260\n",
      "epoch:  89 \t loss: -0.140 \t return: -0.523 \t ep_len: 170.333 \t critic_loss: 272.319 \t adv: -0.130\n",
      "epoch:  90 \t loss: -0.103 \t return: 0.648 \t ep_len: 254.667 \t critic_loss: 472.829 \t adv: -0.028\n",
      "epoch:  91 \t loss: 0.545 \t return: 17.662 \t ep_len: 1000.000 \t critic_loss: 590.868 \t adv: 0.489\n",
      "epoch:  92 \t loss: 0.472 \t return: 5.478 \t ep_len: 1000.000 \t critic_loss: 593.758 \t adv: 0.413\n",
      "epoch:  93 \t loss: 0.253 \t return: 40.837 \t ep_len: 490.667 \t critic_loss: 955.575 \t adv: 0.220\n",
      "epoch:  94 \t loss: 0.192 \t return: -16.071 \t ep_len: 394.333 \t critic_loss: 806.967 \t adv: 0.172\n",
      "epoch:  95 \t loss: -0.419 \t return: -7.839 \t ep_len: 217.000 \t critic_loss: 389.874 \t adv: -0.423\n",
      "epoch:  96 \t loss: 0.334 \t return: 41.561 \t ep_len: 1000.000 \t critic_loss: 375.184 \t adv: 0.294\n",
      "epoch:  97 \t loss: 0.512 \t return: -5.029 \t ep_len: 1000.000 \t critic_loss: 688.009 \t adv: 0.478\n",
      "epoch:  98 \t loss: -0.524 \t return: 8.544 \t ep_len: 202.333 \t critic_loss: 385.317 \t adv: -0.505\n",
      "epoch:  99 \t loss: 0.090 \t return: 13.943 \t ep_len: 594.500 \t critic_loss: 499.916 \t adv: 0.079\n",
      "epoch: 100 \t loss: -0.747 \t return: -24.889 \t ep_len: 270.000 \t critic_loss: 580.910 \t adv: -0.651\n",
      "epoch: 101 \t loss: 0.223 \t return: -3.275 \t ep_len: 643.500 \t critic_loss: 675.790 \t adv: 0.214\n",
      "epoch: 102 \t loss: -0.361 \t return: -167.735 \t ep_len: 588.000 \t critic_loss: 386.589 \t adv: -0.276\n",
      "epoch: 103 \t loss: -0.085 \t return: 20.832 \t ep_len: 1000.000 \t critic_loss: 863.344 \t adv: -0.021\n",
      "epoch: 104 \t loss: -0.766 \t return: 6.049 \t ep_len: 253.000 \t critic_loss: 500.536 \t adv: -0.703\n",
      "epoch: 105 \t loss: -0.603 \t return: -64.082 \t ep_len: 285.000 \t critic_loss: 388.245 \t adv: -0.545\n",
      "epoch: 106 \t loss: -0.464 \t return: -108.346 \t ep_len: 388.500 \t critic_loss: 505.090 \t adv: -0.436\n",
      "epoch: 107 \t loss: 0.193 \t return: -21.068 \t ep_len: 601.000 \t critic_loss: 768.365 \t adv: 0.172\n",
      "epoch: 108 \t loss: 0.330 \t return: -27.490 \t ep_len: 1000.000 \t critic_loss: 752.695 \t adv: 0.318\n",
      "epoch: 109 \t loss: 0.275 \t return: -6.163 \t ep_len: 1000.000 \t critic_loss: 402.435 \t adv: 0.255\n",
      "epoch: 110 \t loss: -0.608 \t return: 14.280 \t ep_len: 226.000 \t critic_loss: 568.650 \t adv: -0.546\n",
      "epoch: 111 \t loss: -0.112 \t return: -53.088 \t ep_len: 264.000 \t critic_loss: 327.308 \t adv: -0.104\n",
      "epoch: 112 \t loss: -0.565 \t return: -41.380 \t ep_len: 197.667 \t critic_loss: 448.620 \t adv: -0.505\n",
      "epoch: 113 \t loss: -0.338 \t return: -64.429 \t ep_len: 267.333 \t critic_loss: 407.004 \t adv: -0.284\n",
      "epoch: 114 \t loss: 0.280 \t return: -19.312 \t ep_len: 609.500 \t critic_loss: 874.826 \t adv: 0.250\n",
      "epoch: 115 \t loss: 0.496 \t return: -3.451 \t ep_len: 1000.000 \t critic_loss: 522.806 \t adv: 0.458\n",
      "epoch: 116 \t loss: -0.317 \t return: 36.427 \t ep_len: 173.333 \t critic_loss: 287.437 \t adv: -0.286\n",
      "epoch: 117 \t loss: -0.535 \t return: -44.143 \t ep_len: 282.000 \t critic_loss: 399.308 \t adv: -0.473\n",
      "epoch: 118 \t loss: 0.229 \t return: 94.051 \t ep_len: 1000.000 \t critic_loss: 396.888 \t adv: 0.226\n",
      "epoch: 119 \t loss: 0.244 \t return: 39.994 \t ep_len: 1000.000 \t critic_loss: 886.794 \t adv: 0.239\n",
      "epoch: 120 \t loss: 0.061 \t return: 23.634 \t ep_len: 630.000 \t critic_loss: 693.519 \t adv: 0.093\n",
      "epoch: 121 \t loss: 0.170 \t return: 12.845 \t ep_len: 625.000 \t critic_loss: 697.370 \t adv: 0.185\n",
      "epoch: 122 \t loss: 0.274 \t return: 2.015 \t ep_len: 622.000 \t critic_loss: 415.666 \t adv: 0.266\n",
      "epoch: 123 \t loss: 0.041 \t return: 40.153 \t ep_len: 1000.000 \t critic_loss: 490.472 \t adv: 0.078\n",
      "epoch: 124 \t loss: 0.176 \t return: 26.902 \t ep_len: 1000.000 \t critic_loss: 518.738 \t adv: 0.198\n",
      "epoch: 125 \t loss: 0.322 \t return: 21.318 \t ep_len: 1000.000 \t critic_loss: 491.786 \t adv: 0.332\n",
      "epoch: 126 \t loss: 0.172 \t return: -1.086 \t ep_len: 673.000 \t critic_loss: 356.208 \t adv: 0.187\n",
      "epoch: 127 \t loss: 0.222 \t return: 94.419 \t ep_len: 1000.000 \t critic_loss: 510.329 \t adv: 0.226\n",
      "epoch: 128 \t loss: -0.685 \t return: 33.198 \t ep_len: 273.500 \t critic_loss: 482.505 \t adv: -0.628\n",
      "epoch: 129 \t loss: 0.027 \t return: 70.754 \t ep_len: 1000.000 \t critic_loss: 414.688 \t adv: 0.058\n",
      "epoch: 130 \t loss: 0.124 \t return: 43.924 \t ep_len: 573.500 \t critic_loss: 394.751 \t adv: 0.113\n",
      "epoch: 131 \t loss: -0.679 \t return: -11.727 \t ep_len: 261.000 \t critic_loss: 429.053 \t adv: -0.665\n",
      "epoch: 132 \t loss: 0.148 \t return: 44.616 \t ep_len: 603.000 \t critic_loss: 605.259 \t adv: 0.149\n",
      "epoch: 133 \t loss: 0.371 \t return: 62.673 \t ep_len: 1000.000 \t critic_loss: 342.341 \t adv: 0.337\n",
      "epoch: 134 \t loss: 0.392 \t return: 71.308 \t ep_len: 1000.000 \t critic_loss: 340.342 \t adv: 0.365\n",
      "epoch: 135 \t loss: -0.886 \t return: -6.359 \t ep_len: 250.000 \t critic_loss: 810.352 \t adv: -0.829\n",
      "epoch: 136 \t loss: -0.851 \t return: 4.878 \t ep_len: 170.500 \t critic_loss: 729.733 \t adv: -0.815\n",
      "epoch: 137 \t loss: 0.493 \t return: 116.797 \t ep_len: 1000.000 \t critic_loss: 440.520 \t adv: 0.440\n",
      "epoch: 138 \t loss: 0.090 \t return: 59.575 \t ep_len: 591.000 \t critic_loss: 507.285 \t adv: 0.082\n",
      "epoch: 139 \t loss: 0.229 \t return: 119.635 \t ep_len: 1000.000 \t critic_loss: 226.065 \t adv: 0.210\n",
      "epoch: 140 \t loss: -0.916 \t return: 10.448 \t ep_len: 197.000 \t critic_loss: 677.949 \t adv: -0.855\n",
      "epoch: 141 \t loss: -0.874 \t return: 24.126 \t ep_len: 194.000 \t critic_loss: 603.430 \t adv: -0.807\n",
      "epoch: 142 \t loss: -0.903 \t return: 36.647 \t ep_len: 187.667 \t critic_loss: 600.561 \t adv: -0.804\n",
      "epoch: 143 \t loss: 0.288 \t return: 129.210 \t ep_len: 1000.000 \t critic_loss: 360.349 \t adv: 0.260\n",
      "epoch: 144 \t loss: -0.685 \t return: 31.362 \t ep_len: 189.000 \t critic_loss: 485.405 \t adv: -0.666\n",
      "epoch: 145 \t loss: 0.089 \t return: 64.504 \t ep_len: 459.333 \t critic_loss: 833.105 \t adv: 0.076\n",
      "epoch: 146 \t loss: -0.656 \t return: 15.466 \t ep_len: 135.250 \t critic_loss: 472.437 \t adv: -0.616\n",
      "epoch: 147 \t loss: -0.627 \t return: 18.599 \t ep_len: 156.750 \t critic_loss: 523.631 \t adv: -0.579\n",
      "epoch: 148 \t loss: -0.541 \t return: 11.522 \t ep_len: 178.333 \t critic_loss: 423.475 \t adv: -0.544\n",
      "epoch: 149 \t loss: 0.110 \t return: 16.455 \t ep_len: 424.667 \t critic_loss: 682.211 \t adv: 0.136\n",
      "epoch: 150 \t loss: 0.273 \t return: 66.761 \t ep_len: 583.000 \t critic_loss: 653.592 \t adv: 0.255\n",
      "epoch: 151 \t loss: -0.347 \t return: 22.092 \t ep_len: 156.000 \t critic_loss: 404.090 \t adv: -0.345\n",
      "epoch: 152 \t loss: 0.177 \t return: 44.423 \t ep_len: 479.667 \t critic_loss: 784.577 \t adv: 0.161\n",
      "epoch: 153 \t loss: 0.115 \t return: 56.801 \t ep_len: 467.000 \t critic_loss: 795.216 \t adv: 0.115\n",
      "epoch: 154 \t loss: 0.247 \t return: 59.769 \t ep_len: 642.000 \t critic_loss: 765.783 \t adv: 0.228\n",
      "epoch: 155 \t loss: 0.370 \t return: 115.412 \t ep_len: 1000.000 \t critic_loss: 499.182 \t adv: 0.362\n",
      "epoch: 156 \t loss: 0.354 \t return: 145.926 \t ep_len: 1000.000 \t critic_loss: 500.147 \t adv: 0.335\n",
      "epoch: 157 \t loss: 0.176 \t return: 78.057 \t ep_len: 596.500 \t critic_loss: 497.594 \t adv: 0.165\n",
      "epoch: 158 \t loss: 0.362 \t return: 131.473 \t ep_len: 1000.000 \t critic_loss: 470.179 \t adv: 0.346\n",
      "epoch: 159 \t loss: 0.117 \t return: 56.932 \t ep_len: 474.667 \t critic_loss: 644.583 \t adv: 0.100\n",
      "epoch: 160 \t loss: 0.303 \t return: 133.486 \t ep_len: 1000.000 \t critic_loss: 465.756 \t adv: 0.298\n",
      "epoch: 161 \t loss: 0.175 \t return: 101.369 \t ep_len: 1000.000 \t critic_loss: 453.359 \t adv: 0.181\n",
      "epoch: 162 \t loss: -0.663 \t return: 2.457 \t ep_len: 198.667 \t critic_loss: 499.174 \t adv: -0.641\n",
      "epoch: 163 \t loss: 0.334 \t return: 140.545 \t ep_len: 1000.000 \t critic_loss: 362.795 \t adv: 0.317\n",
      "epoch: 164 \t loss: 0.249 \t return: 102.528 \t ep_len: 1000.000 \t critic_loss: 292.997 \t adv: 0.243\n",
      "epoch: 165 \t loss: 0.253 \t return: 134.709 \t ep_len: 1000.000 \t critic_loss: 324.816 \t adv: 0.268\n",
      "epoch: 166 \t loss: -0.098 \t return: 20.663 \t ep_len: 705.000 \t critic_loss: 653.272 \t adv: -0.084\n",
      "epoch: 167 \t loss: 0.169 \t return: 128.647 \t ep_len: 1000.000 \t critic_loss: 251.217 \t adv: 0.185\n",
      "epoch: 168 \t loss: 0.063 \t return: 119.621 \t ep_len: 1000.000 \t critic_loss: 252.902 \t adv: 0.090\n",
      "epoch: 169 \t loss: -0.005 \t return: 111.152 \t ep_len: 1000.000 \t critic_loss: 525.908 \t adv: 0.014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 170 \t loss: 0.143 \t return: 85.775 \t ep_len: 1000.000 \t critic_loss: 339.012 \t adv: 0.139\n",
      "epoch: 171 \t loss: 0.069 \t return: 121.004 \t ep_len: 1000.000 \t critic_loss: 311.087 \t adv: 0.100\n",
      "epoch: 172 \t loss: -0.111 \t return: 79.270 \t ep_len: 1000.000 \t critic_loss: 524.976 \t adv: -0.066\n",
      "epoch: 173 \t loss: 0.162 \t return: 80.466 \t ep_len: 1000.000 \t critic_loss: 387.373 \t adv: 0.164\n",
      "epoch: 174 \t loss: 0.086 \t return: 83.525 \t ep_len: 1000.000 \t critic_loss: 314.518 \t adv: 0.107\n",
      "epoch: 175 \t loss: -0.040 \t return: 91.543 \t ep_len: 1000.000 \t critic_loss: 365.868 \t adv: -0.026\n",
      "epoch: 176 \t loss: 0.116 \t return: 131.488 \t ep_len: 1000.000 \t critic_loss: 197.807 \t adv: 0.116\n",
      "epoch: 177 \t loss: -0.091 \t return: 127.400 \t ep_len: 1000.000 \t critic_loss: 274.162 \t adv: -0.062\n",
      "epoch: 178 \t loss: 0.164 \t return: 136.121 \t ep_len: 1000.000 \t critic_loss: 172.262 \t adv: 0.153\n",
      "epoch: 179 \t loss: -1.079 \t return: 5.083 \t ep_len: 304.500 \t critic_loss: 740.333 \t adv: -1.008\n",
      "epoch: 180 \t loss: -1.160 \t return: -1.264 \t ep_len: 282.000 \t critic_loss: 819.852 \t adv: -1.085\n",
      "epoch: 181 \t loss: -0.101 \t return: 64.290 \t ep_len: 619.000 \t critic_loss: 632.756 \t adv: -0.078\n",
      "epoch: 182 \t loss: -0.223 \t return: 46.518 \t ep_len: 632.000 \t critic_loss: 833.396 \t adv: -0.148\n",
      "epoch: 183 \t loss: 0.089 \t return: 154.804 \t ep_len: 1000.000 \t critic_loss: 189.277 \t adv: 0.097\n",
      "epoch: 184 \t loss: -0.985 \t return: -7.175 \t ep_len: 286.000 \t critic_loss: 669.626 \t adv: -0.933\n",
      "epoch: 185 \t loss: -0.070 \t return: 84.775 \t ep_len: 623.000 \t critic_loss: 414.315 \t adv: -0.049\n",
      "epoch: 186 \t loss: 0.017 \t return: 82.130 \t ep_len: 634.500 \t critic_loss: 534.055 \t adv: 0.012\n",
      "epoch: 187 \t loss: 0.038 \t return: 61.657 \t ep_len: 604.500 \t critic_loss: 417.389 \t adv: 0.038\n",
      "epoch: 188 \t loss: 0.311 \t return: 185.142 \t ep_len: 1000.000 \t critic_loss: 318.119 \t adv: 0.314\n",
      "epoch: 189 \t loss: 0.206 \t return: 108.457 \t ep_len: 1000.000 \t critic_loss: 279.342 \t adv: 0.207\n",
      "epoch: 190 \t loss: 0.187 \t return: 168.214 \t ep_len: 1000.000 \t critic_loss: 279.024 \t adv: 0.214\n",
      "epoch: 191 \t loss: 0.180 \t return: 133.889 \t ep_len: 1000.000 \t critic_loss: 274.337 \t adv: 0.192\n",
      "epoch: 192 \t loss: -0.076 \t return: 32.818 \t ep_len: 640.500 \t critic_loss: 634.747 \t adv: -0.054\n",
      "epoch: 193 \t loss: 0.196 \t return: 143.815 \t ep_len: 1000.000 \t critic_loss: 307.764 \t adv: 0.206\n",
      "epoch: 194 \t loss: 0.114 \t return: 148.363 \t ep_len: 1000.000 \t critic_loss: 242.756 \t adv: 0.115\n",
      "epoch: 195 \t loss: 0.035 \t return: 171.757 \t ep_len: 1000.000 \t critic_loss: 192.444 \t adv: 0.048\n",
      "epoch: 196 \t loss: 0.123 \t return: 81.063 \t ep_len: 1000.000 \t critic_loss: 378.927 \t adv: 0.159\n",
      "epoch: 197 \t loss: 0.125 \t return: 116.390 \t ep_len: 1000.000 \t critic_loss: 284.885 \t adv: 0.117\n",
      "epoch: 198 \t loss: 0.113 \t return: 120.930 \t ep_len: 1000.000 \t critic_loss: 231.692 \t adv: 0.119\n",
      "epoch: 199 \t loss: 0.115 \t return: 85.853 \t ep_len: 1000.000 \t critic_loss: 264.361 \t adv: 0.121\n",
      "epoch: 200 \t loss: -0.056 \t return: 76.189 \t ep_len: 630.500 \t critic_loss: 510.393 \t adv: -0.028\n",
      "epoch: 201 \t loss: 0.209 \t return: 143.527 \t ep_len: 1000.000 \t critic_loss: 177.107 \t adv: 0.198\n",
      "epoch: 202 \t loss: 0.181 \t return: 154.051 \t ep_len: 1000.000 \t critic_loss: 162.093 \t adv: 0.174\n",
      "epoch: 203 \t loss: -0.031 \t return: 75.594 \t ep_len: 630.000 \t critic_loss: 503.812 \t adv: -0.024\n",
      "epoch: 204 \t loss: 0.200 \t return: 97.187 \t ep_len: 1000.000 \t critic_loss: 185.026 \t adv: 0.213\n",
      "epoch: 205 \t loss: -0.159 \t return: 114.754 \t ep_len: 640.500 \t critic_loss: 587.237 \t adv: -0.127\n",
      "epoch: 206 \t loss: -0.316 \t return: 58.482 \t ep_len: 487.333 \t critic_loss: 958.647 \t adv: -0.297\n",
      "epoch: 207 \t loss: -1.221 \t return: 24.942 \t ep_len: 180.000 \t critic_loss: 880.019 \t adv: -1.148\n",
      "epoch: 208 \t loss: -0.424 \t return: 71.366 \t ep_len: 476.667 \t critic_loss: 848.216 \t adv: -0.390\n",
      "epoch: 209 \t loss: 0.044 \t return: 103.525 \t ep_len: 1000.000 \t critic_loss: 176.672 \t adv: 0.056\n",
      "epoch: 210 \t loss: 0.150 \t return: 148.000 \t ep_len: 1000.000 \t critic_loss: 203.218 \t adv: 0.150\n",
      "epoch: 211 \t loss: 0.087 \t return: 99.928 \t ep_len: 1000.000 \t critic_loss: 162.166 \t adv: 0.098\n",
      "epoch: 212 \t loss: 0.184 \t return: 60.789 \t ep_len: 1000.000 \t critic_loss: 372.221 \t adv: 0.229\n",
      "epoch: 213 \t loss: 0.049 \t return: 87.521 \t ep_len: 1000.000 \t critic_loss: 243.365 \t adv: 0.062\n",
      "epoch: 214 \t loss: -0.294 \t return: 36.357 \t ep_len: 640.500 \t critic_loss: 996.129 \t adv: -0.245\n",
      "epoch: 215 \t loss: -0.114 \t return: 104.698 \t ep_len: 1000.000 \t critic_loss: 856.416 \t adv: -0.030\n",
      "epoch: 216 \t loss: -0.256 \t return: 123.089 \t ep_len: 1000.000 \t critic_loss: 544.711 \t adv: -0.208\n",
      "epoch: 217 \t loss: -0.076 \t return: 69.911 \t ep_len: 1000.000 \t critic_loss: 451.294 \t adv: -0.047\n",
      "epoch: 218 \t loss: -0.103 \t return: 47.796 \t ep_len: 665.500 \t critic_loss: 603.142 \t adv: -0.096\n",
      "epoch: 219 \t loss: 0.196 \t return: 108.688 \t ep_len: 1000.000 \t critic_loss: 246.567 \t adv: 0.190\n",
      "epoch: 220 \t loss: 0.082 \t return: 128.100 \t ep_len: 1000.000 \t critic_loss: 176.815 \t adv: 0.095\n",
      "epoch: 221 \t loss: 0.106 \t return: 146.905 \t ep_len: 1000.000 \t critic_loss: 239.416 \t adv: 0.127\n",
      "epoch: 222 \t loss: -0.683 \t return: -17.403 \t ep_len: 387.500 \t critic_loss: 601.812 \t adv: -0.608\n",
      "epoch: 223 \t loss: 0.314 \t return: 105.602 \t ep_len: 1000.000 \t critic_loss: 513.450 \t adv: 0.345\n",
      "epoch: 224 \t loss: -0.019 \t return: 45.749 \t ep_len: 631.000 \t critic_loss: 522.615 \t adv: -0.022\n",
      "epoch: 225 \t loss: 0.185 \t return: 107.284 \t ep_len: 1000.000 \t critic_loss: 275.645 \t adv: 0.183\n",
      "epoch: 226 \t loss: 0.273 \t return: 123.050 \t ep_len: 1000.000 \t critic_loss: 286.933 \t adv: 0.270\n",
      "epoch: 227 \t loss: -0.149 \t return: 79.573 \t ep_len: 658.500 \t critic_loss: 559.669 \t adv: -0.108\n",
      "epoch: 228 \t loss: 0.043 \t return: 72.284 \t ep_len: 658.500 \t critic_loss: 521.949 \t adv: 0.049\n",
      "epoch: 229 \t loss: 0.346 \t return: 165.380 \t ep_len: 1000.000 \t critic_loss: 378.033 \t adv: 0.346\n",
      "epoch: 230 \t loss: 0.342 \t return: 142.716 \t ep_len: 1000.000 \t critic_loss: 352.778 \t adv: 0.335\n",
      "epoch: 231 \t loss: 0.325 \t return: 148.029 \t ep_len: 1000.000 \t critic_loss: 286.940 \t adv: 0.337\n",
      "epoch: 232 \t loss: 0.140 \t return: 156.646 \t ep_len: 1000.000 \t critic_loss: 178.443 \t adv: 0.149\n",
      "epoch: 233 \t loss: 0.262 \t return: 135.937 \t ep_len: 1000.000 \t critic_loss: 259.155 \t adv: 0.258\n",
      "epoch: 234 \t loss: 0.122 \t return: 136.404 \t ep_len: 1000.000 \t critic_loss: 210.587 \t adv: 0.135\n",
      "epoch: 235 \t loss: -0.006 \t return: 126.608 \t ep_len: 1000.000 \t critic_loss: 174.853 \t adv: 0.014\n",
      "epoch: 236 \t loss: -0.019 \t return: 85.358 \t ep_len: 1000.000 \t critic_loss: 241.849 \t adv: -0.002\n",
      "epoch: 237 \t loss: 0.004 \t return: 143.353 \t ep_len: 1000.000 \t critic_loss: 135.102 \t adv: 0.012\n",
      "epoch: 238 \t loss: -0.296 \t return: 84.950 \t ep_len: 635.500 \t critic_loss: 665.382 \t adv: -0.278\n",
      "epoch: 239 \t loss: 0.241 \t return: 152.901 \t ep_len: 1000.000 \t critic_loss: 169.996 \t adv: 0.242\n",
      "epoch: 240 \t loss: 0.218 \t return: 166.376 \t ep_len: 1000.000 \t critic_loss: 233.145 \t adv: 0.228\n",
      "epoch: 241 \t loss: 0.249 \t return: 154.530 \t ep_len: 1000.000 \t critic_loss: 201.275 \t adv: 0.258\n",
      "epoch: 242 \t loss: -0.016 \t return: 135.650 \t ep_len: 1000.000 \t critic_loss: 127.044 \t adv: -0.005\n",
      "epoch: 243 \t loss: 0.171 \t return: 133.781 \t ep_len: 1000.000 \t critic_loss: 115.892 \t adv: 0.177\n",
      "epoch: 244 \t loss: -0.102 \t return: 150.900 \t ep_len: 1000.000 \t critic_loss: 148.822 \t adv: -0.112\n",
      "epoch: 245 \t loss: -0.301 \t return: 53.551 \t ep_len: 471.333 \t critic_loss: 890.628 \t adv: -0.300\n",
      "epoch: 246 \t loss: 0.167 \t return: 156.217 \t ep_len: 1000.000 \t critic_loss: 162.150 \t adv: 0.170\n",
      "epoch: 247 \t loss: -0.088 \t return: 105.360 \t ep_len: 588.500 \t critic_loss: 370.028 \t adv: -0.099\n",
      "epoch: 248 \t loss: -0.003 \t return: 166.023 \t ep_len: 1000.000 \t critic_loss: 99.800 \t adv: -0.000\n",
      "epoch: 249 \t loss: -0.363 \t return: 44.891 \t ep_len: 459.000 \t critic_loss: 1003.483 \t adv: -0.346\n",
      "epoch: 250 \t loss: -0.011 \t return: 165.615 \t ep_len: 1000.000 \t critic_loss: 73.137 \t adv: -0.004\n",
      "epoch: 251 \t loss: -1.377 \t return: 20.348 \t ep_len: 191.667 \t critic_loss: 1144.174 \t adv: -1.349\n",
      "epoch: 252 \t loss: -0.177 \t return: 89.530 \t ep_len: 615.000 \t critic_loss: 535.181 \t adv: -0.146\n",
      "epoch: 253 \t loss: -0.226 \t return: 78.056 \t ep_len: 615.000 \t critic_loss: 453.941 \t adv: -0.222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 254 \t loss: 0.132 \t return: 129.559 \t ep_len: 1000.000 \t critic_loss: 101.435 \t adv: 0.136\n",
      "epoch: 255 \t loss: -0.156 \t return: 58.749 \t ep_len: 597.500 \t critic_loss: 606.106 \t adv: -0.124\n",
      "epoch: 256 \t loss: -0.096 \t return: 61.199 \t ep_len: 598.000 \t critic_loss: 426.891 \t adv: -0.077\n",
      "epoch: 257 \t loss: -0.018 \t return: 84.989 \t ep_len: 634.500 \t critic_loss: 475.096 \t adv: 0.001\n",
      "epoch: 258 \t loss: 0.098 \t return: 113.681 \t ep_len: 1000.000 \t critic_loss: 120.185 \t adv: 0.103\n",
      "epoch: 259 \t loss: -0.187 \t return: 58.780 \t ep_len: 655.500 \t critic_loss: 624.643 \t adv: -0.148\n",
      "epoch: 260 \t loss: 0.044 \t return: 145.845 \t ep_len: 1000.000 \t critic_loss: 283.381 \t adv: 0.063\n",
      "epoch: 261 \t loss: 0.047 \t return: 81.327 \t ep_len: 1000.000 \t critic_loss: 744.172 \t adv: 0.208\n",
      "epoch: 262 \t loss: -0.071 \t return: 135.917 \t ep_len: 1000.000 \t critic_loss: 417.585 \t adv: -0.045\n",
      "epoch: 263 \t loss: -0.039 \t return: 130.253 \t ep_len: 1000.000 \t critic_loss: 329.543 \t adv: -0.009\n",
      "epoch: 264 \t loss: -0.177 \t return: 78.427 \t ep_len: 1000.000 \t critic_loss: 541.436 \t adv: -0.153\n",
      "epoch: 265 \t loss: -0.059 \t return: 113.296 \t ep_len: 1000.000 \t critic_loss: 600.731 \t adv: -0.003\n",
      "epoch: 266 \t loss: -0.028 \t return: 44.099 \t ep_len: 1000.000 \t critic_loss: 306.504 \t adv: 0.003\n",
      "epoch: 267 \t loss: 0.078 \t return: 124.297 \t ep_len: 1000.000 \t critic_loss: 312.295 \t adv: 0.109\n",
      "epoch: 268 \t loss: -0.120 \t return: 90.319 \t ep_len: 1000.000 \t critic_loss: 660.059 \t adv: -0.094\n",
      "epoch: 269 \t loss: -0.049 \t return: 80.406 \t ep_len: 1000.000 \t critic_loss: 520.142 \t adv: 0.014\n",
      "epoch: 270 \t loss: -0.106 \t return: 94.911 \t ep_len: 1000.000 \t critic_loss: 342.679 \t adv: -0.092\n",
      "epoch: 271 \t loss: -0.156 \t return: 75.606 \t ep_len: 1000.000 \t critic_loss: 597.054 \t adv: -0.117\n",
      "epoch: 272 \t loss: 0.047 \t return: 70.930 \t ep_len: 1000.000 \t critic_loss: 806.827 \t adv: 0.069\n",
      "epoch: 273 \t loss: 0.069 \t return: 40.013 \t ep_len: 639.500 \t critic_loss: 459.800 \t adv: 0.071\n",
      "epoch: 274 \t loss: 0.155 \t return: 162.455 \t ep_len: 1000.000 \t critic_loss: 203.461 \t adv: 0.169\n",
      "epoch: 275 \t loss: 0.216 \t return: 85.394 \t ep_len: 1000.000 \t critic_loss: 321.437 \t adv: 0.236\n",
      "epoch: 276 \t loss: 0.237 \t return: 117.200 \t ep_len: 1000.000 \t critic_loss: 324.666 \t adv: 0.216\n",
      "epoch: 277 \t loss: 0.223 \t return: 72.816 \t ep_len: 1000.000 \t critic_loss: 338.061 \t adv: 0.294\n",
      "epoch: 278 \t loss: 0.199 \t return: 140.854 \t ep_len: 1000.000 \t critic_loss: 216.103 \t adv: 0.207\n",
      "epoch: 279 \t loss: -0.056 \t return: 85.848 \t ep_len: 459.000 \t critic_loss: 599.782 \t adv: -0.090\n",
      "epoch: 280 \t loss: -0.046 \t return: 101.881 \t ep_len: 580.500 \t critic_loss: 437.288 \t adv: -0.063\n",
      "epoch: 281 \t loss: 0.129 \t return: 138.656 \t ep_len: 568.500 \t critic_loss: 496.272 \t adv: 0.108\n",
      "epoch: 282 \t loss: 0.208 \t return: 144.541 \t ep_len: 1000.000 \t critic_loss: 273.689 \t adv: 0.219\n",
      "epoch: 283 \t loss: 0.062 \t return: 152.321 \t ep_len: 1000.000 \t critic_loss: 169.383 \t adv: 0.069\n",
      "epoch: 284 \t loss: -0.015 \t return: 195.451 \t ep_len: 656.500 \t critic_loss: 682.089 \t adv: 0.024\n",
      "epoch: 285 \t loss: 0.147 \t return: 174.463 \t ep_len: 1000.000 \t critic_loss: 387.411 \t adv: 0.166\n",
      "epoch: 286 \t loss: 0.150 \t return: 165.413 \t ep_len: 1000.000 \t critic_loss: 274.605 \t adv: 0.135\n",
      "epoch: 287 \t loss: 0.110 \t return: 186.284 \t ep_len: 1000.000 \t critic_loss: 247.849 \t adv: 0.117\n",
      "epoch: 288 \t loss: 0.046 \t return: 147.438 \t ep_len: 1000.000 \t critic_loss: 162.503 \t adv: 0.041\n",
      "epoch: 289 \t loss: -1.329 \t return: 30.616 \t ep_len: 158.500 \t critic_loss: 1243.444 \t adv: -1.343\n",
      "epoch: 290 \t loss: -1.231 \t return: 36.727 \t ep_len: 141.000 \t critic_loss: 1130.498 \t adv: -1.346\n",
      "epoch: 291 \t loss: -0.170 \t return: 27.712 \t ep_len: 445.333 \t critic_loss: 708.169 \t adv: -0.174\n",
      "epoch: 292 \t loss: -0.092 \t return: 76.256 \t ep_len: 587.500 \t critic_loss: 495.515 \t adv: -0.086\n",
      "epoch: 293 \t loss: -0.034 \t return: 157.234 \t ep_len: 1000.000 \t critic_loss: 134.079 \t adv: -0.040\n",
      "epoch: 294 \t loss: 0.035 \t return: 78.541 \t ep_len: 586.000 \t critic_loss: 506.897 \t adv: 0.055\n",
      "epoch: 295 \t loss: 0.032 \t return: 63.357 \t ep_len: 579.000 \t critic_loss: 424.731 \t adv: 0.040\n",
      "epoch: 296 \t loss: 0.081 \t return: 83.996 \t ep_len: 590.000 \t critic_loss: 537.249 \t adv: 0.125\n",
      "epoch: 297 \t loss: 0.084 \t return: 62.134 \t ep_len: 615.000 \t critic_loss: 544.464 \t adv: 0.093\n",
      "epoch: 298 \t loss: 0.129 \t return: 120.298 \t ep_len: 1000.000 \t critic_loss: 181.208 \t adv: 0.148\n",
      "epoch: 299 \t loss: -0.186 \t return: 164.123 \t ep_len: 513.000 \t critic_loss: 775.724 \t adv: -0.018\n",
      "epoch: 300 \t loss: -0.126 \t return: 56.635 \t ep_len: 462.333 \t critic_loss: 681.603 \t adv: -0.112\n",
      "epoch: 301 \t loss: -0.036 \t return: 80.462 \t ep_len: 605.500 \t critic_loss: 503.596 \t adv: -0.013\n",
      "epoch: 302 \t loss: 0.129 \t return: 102.721 \t ep_len: 1000.000 \t critic_loss: 452.615 \t adv: 0.142\n",
      "epoch: 303 \t loss: -0.196 \t return: 35.266 \t ep_len: 601.500 \t critic_loss: 558.304 \t adv: -0.213\n",
      "epoch: 304 \t loss: 0.039 \t return: 108.562 \t ep_len: 1000.000 \t critic_loss: 380.306 \t adv: -0.002\n",
      "epoch: 305 \t loss: 0.036 \t return: 125.844 \t ep_len: 1000.000 \t critic_loss: 250.489 \t adv: 0.002\n",
      "epoch: 306 \t loss: 0.090 \t return: 109.562 \t ep_len: 1000.000 \t critic_loss: 328.212 \t adv: 0.080\n",
      "epoch: 307 \t loss: -0.005 \t return: 208.185 \t ep_len: 928.000 \t critic_loss: 753.585 \t adv: 0.075\n",
      "epoch: 308 \t loss: 0.188 \t return: 91.701 \t ep_len: 1000.000 \t critic_loss: 254.317 \t adv: 0.188\n",
      "epoch: 309 \t loss: 0.155 \t return: 131.975 \t ep_len: 1000.000 \t critic_loss: 324.715 \t adv: 0.178\n",
      "epoch: 310 \t loss: 0.089 \t return: 125.897 \t ep_len: 1000.000 \t critic_loss: 316.711 \t adv: 0.078\n",
      "epoch: 311 \t loss: 0.052 \t return: 110.369 \t ep_len: 1000.000 \t critic_loss: 197.948 \t adv: 0.047\n",
      "epoch: 312 \t loss: 0.231 \t return: 150.142 \t ep_len: 1000.000 \t critic_loss: 282.941 \t adv: 0.298\n",
      "epoch: 313 \t loss: 0.032 \t return: 70.183 \t ep_len: 1000.000 \t critic_loss: 395.702 \t adv: 0.096\n",
      "epoch: 314 \t loss: -0.191 \t return: 40.230 \t ep_len: 675.000 \t critic_loss: 612.295 \t adv: -0.169\n",
      "epoch: 315 \t loss: -0.093 \t return: 49.958 \t ep_len: 654.000 \t critic_loss: 443.696 \t adv: -0.091\n",
      "epoch: 316 \t loss: -0.724 \t return: 150.891 \t ep_len: 373.500 \t critic_loss: 1183.122 \t adv: -0.547\n",
      "epoch: 317 \t loss: -0.568 \t return: 104.387 \t ep_len: 360.667 \t critic_loss: 1288.106 \t adv: -0.484\n",
      "epoch: 318 \t loss: -0.683 \t return: 117.619 \t ep_len: 408.500 \t critic_loss: 1081.627 \t adv: -0.510\n",
      "epoch: 319 \t loss: -0.323 \t return: 193.368 \t ep_len: 495.500 \t critic_loss: 1325.535 \t adv: -0.248\n",
      "epoch: 320 \t loss: -0.718 \t return: -12.298 \t ep_len: 332.000 \t critic_loss: 425.118 \t adv: -0.662\n",
      "epoch: 321 \t loss: -0.744 \t return: 241.793 \t ep_len: 394.000 \t critic_loss: 1637.414 \t adv: -0.440\n",
      "epoch: 322 \t loss: -0.549 \t return: 242.632 \t ep_len: 427.000 \t critic_loss: 1231.186 \t adv: -0.330\n",
      "epoch: 323 \t loss: -0.498 \t return: 263.543 \t ep_len: 347.500 \t critic_loss: 1205.286 \t adv: -0.396\n",
      "epoch: 324 \t loss: -0.347 \t return: 230.307 \t ep_len: 505.000 \t critic_loss: 585.658 \t adv: -0.128\n",
      "epoch: 325 \t loss: -0.346 \t return: 244.564 \t ep_len: 401.500 \t critic_loss: 848.339 \t adv: -0.192\n",
      "epoch: 326 \t loss: -0.342 \t return: 111.473 \t ep_len: 300.500 \t critic_loss: 523.191 \t adv: -0.225\n",
      "epoch: 327 \t loss: -0.193 \t return: 107.779 \t ep_len: 303.500 \t critic_loss: 412.943 \t adv: -0.158\n",
      "epoch: 328 \t loss: -0.239 \t return: 254.288 \t ep_len: 312.500 \t critic_loss: 602.433 \t adv: -0.145\n",
      "epoch: 329 \t loss: -0.187 \t return: 239.279 \t ep_len: 380.500 \t critic_loss: 655.275 \t adv: -0.114\n",
      "epoch: 330 \t loss: -0.042 \t return: 258.035 \t ep_len: 336.500 \t critic_loss: 603.316 \t adv: -0.080\n",
      "epoch: 331 \t loss: 0.021 \t return: 238.671 \t ep_len: 359.000 \t critic_loss: 754.297 \t adv: -0.179\n",
      "epoch: 332 \t loss: -0.043 \t return: 240.246 \t ep_len: 297.500 \t critic_loss: 492.117 \t adv: -0.013\n",
      "epoch: 333 \t loss: 0.117 \t return: 99.894 \t ep_len: 223.667 \t critic_loss: 608.750 \t adv: 0.062\n",
      "epoch: 334 \t loss: 0.114 \t return: 261.203 \t ep_len: 282.500 \t critic_loss: 602.505 \t adv: -0.099\n",
      "epoch: 335 \t loss: 0.151 \t return: 43.860 \t ep_len: 174.333 \t critic_loss: 513.858 \t adv: 0.182\n",
      "epoch: 336 \t loss: 0.232 \t return: 129.888 \t ep_len: 201.333 \t critic_loss: 684.269 \t adv: 0.082\n",
      "epoch: 337 \t loss: 0.173 \t return: 112.334 \t ep_len: 213.667 \t critic_loss: 664.214 \t adv: -0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 338 \t loss: 0.195 \t return: 24.372 \t ep_len: 153.500 \t critic_loss: 534.163 \t adv: 0.130\n",
      "epoch: 339 \t loss: 0.118 \t return: 243.646 \t ep_len: 251.000 \t critic_loss: 501.503 \t adv: -0.060\n",
      "epoch: 340 \t loss: 0.166 \t return: 25.685 \t ep_len: 142.000 \t critic_loss: 468.167 \t adv: 0.080\n",
      "epoch: 341 \t loss: 0.230 \t return: 271.258 \t ep_len: 231.333 \t critic_loss: 733.293 \t adv: 0.049\n",
      "epoch: 342 \t loss: 0.130 \t return: 85.960 \t ep_len: 166.000 \t critic_loss: 503.446 \t adv: 0.021\n",
      "epoch: 343 \t loss: 0.084 \t return: 26.961 \t ep_len: 148.750 \t critic_loss: 399.438 \t adv: 0.016\n",
      "epoch: 344 \t loss: 0.068 \t return: 272.068 \t ep_len: 256.500 \t critic_loss: 509.327 \t adv: 0.052\n",
      "epoch: 345 \t loss: 0.101 \t return: 155.654 \t ep_len: 219.750 \t critic_loss: 660.905 \t adv: 0.079\n",
      "epoch: 346 \t loss: 0.248 \t return: 250.988 \t ep_len: 709.000 \t critic_loss: 617.509 \t adv: 0.285\n",
      "epoch: 347 \t loss: 0.041 \t return: 108.745 \t ep_len: 202.667 \t critic_loss: 360.432 \t adv: 0.031\n",
      "epoch: 348 \t loss: 0.040 \t return: 124.280 \t ep_len: 173.333 \t critic_loss: 282.426 \t adv: -0.062\n",
      "epoch: 349 \t loss: 0.005 \t return: 113.687 \t ep_len: 198.000 \t critic_loss: 376.253 \t adv: -0.029\n",
      "epoch: 350 \t loss: -0.029 \t return: 76.340 \t ep_len: 196.750 \t critic_loss: 395.980 \t adv: -0.042\n",
      "epoch: 351 \t loss: -0.077 \t return: 89.558 \t ep_len: 191.000 \t critic_loss: 342.339 \t adv: -0.055\n",
      "epoch: 352 \t loss: -0.094 \t return: 16.985 \t ep_len: 181.000 \t critic_loss: 210.649 \t adv: -0.142\n",
      "epoch: 353 \t loss: -0.161 \t return: 262.519 \t ep_len: 252.500 \t critic_loss: 517.331 \t adv: -0.004\n",
      "epoch: 354 \t loss: -0.160 \t return: 31.578 \t ep_len: 201.333 \t critic_loss: 215.984 \t adv: -0.177\n",
      "epoch: 355 \t loss: -0.266 \t return: 12.824 \t ep_len: 163.000 \t critic_loss: 272.469 \t adv: -0.277\n",
      "epoch: 356 \t loss: 0.042 \t return: 182.476 \t ep_len: 295.000 \t critic_loss: 598.521 \t adv: 0.186\n",
      "epoch: 357 \t loss: -0.036 \t return: 287.714 \t ep_len: 373.000 \t critic_loss: 855.071 \t adv: 0.275\n",
      "epoch: 358 \t loss: -0.118 \t return: 173.066 \t ep_len: 253.333 \t critic_loss: 748.559 \t adv: 0.100\n",
      "epoch: 359 \t loss: -0.165 \t return: 175.170 \t ep_len: 230.000 \t critic_loss: 538.339 \t adv: 0.001\n",
      "epoch: 360 \t loss: -0.074 \t return: 152.582 \t ep_len: 274.500 \t critic_loss: 472.168 \t adv: 0.092\n",
      "epoch: 361 \t loss: 0.134 \t return: 219.584 \t ep_len: 704.500 \t critic_loss: 1464.988 \t adv: 0.437\n",
      "epoch: 362 \t loss: -0.159 \t return: 250.038 \t ep_len: 321.500 \t critic_loss: 908.369 \t adv: 0.066\n",
      "epoch: 363 \t loss: -0.179 \t return: 236.693 \t ep_len: 507.000 \t critic_loss: 1129.960 \t adv: 0.075\n",
      "epoch: 364 \t loss: -0.322 \t return: 241.738 \t ep_len: 603.000 \t critic_loss: 603.461 \t adv: 0.027\n",
      "epoch: 365 \t loss: 0.302 \t return: 6.603 \t ep_len: 1000.000 \t critic_loss: 677.856 \t adv: 0.206\n",
      "epoch: 366 \t loss: -0.098 \t return: 229.296 \t ep_len: 540.000 \t critic_loss: 539.825 \t adv: 0.029\n",
      "epoch: 367 \t loss: -0.212 \t return: 259.262 \t ep_len: 367.000 \t critic_loss: 733.793 \t adv: -0.122\n",
      "epoch: 368 \t loss: -0.462 \t return: 210.295 \t ep_len: 612.000 \t critic_loss: 461.316 \t adv: -0.223\n",
      "epoch: 369 \t loss: -0.258 \t return: 238.437 \t ep_len: 333.500 \t critic_loss: 571.594 \t adv: -0.145\n",
      "epoch: 370 \t loss: -0.285 \t return: 224.998 \t ep_len: 534.500 \t critic_loss: 643.939 \t adv: -0.172\n",
      "epoch: 371 \t loss: -0.268 \t return: 206.196 \t ep_len: 440.500 \t critic_loss: 535.155 \t adv: -0.139\n",
      "epoch: 372 \t loss: -0.052 \t return: 30.538 \t ep_len: 538.000 \t critic_loss: 765.670 \t adv: -0.031\n",
      "epoch: 373 \t loss: -0.161 \t return: 215.387 \t ep_len: 538.000 \t critic_loss: 321.032 \t adv: -0.076\n",
      "epoch: 374 \t loss: -0.150 \t return: 118.922 \t ep_len: 912.000 \t critic_loss: 566.866 \t adv: -0.136\n",
      "epoch: 375 \t loss: -0.299 \t return: 238.256 \t ep_len: 421.500 \t critic_loss: 708.081 \t adv: -0.313\n",
      "epoch: 376 \t loss: -0.101 \t return: 229.593 \t ep_len: 412.500 \t critic_loss: 977.494 \t adv: -0.383\n",
      "epoch: 377 \t loss: -0.068 \t return: 163.528 \t ep_len: 639.000 \t critic_loss: 346.315 \t adv: 0.027\n",
      "epoch: 378 \t loss: -0.143 \t return: 266.417 \t ep_len: 364.500 \t critic_loss: 445.389 \t adv: -0.119\n",
      "epoch: 379 \t loss: -0.062 \t return: 111.676 \t ep_len: 384.500 \t critic_loss: 669.127 \t adv: -0.028\n",
      "epoch: 380 \t loss: -0.203 \t return: 259.523 \t ep_len: 309.000 \t critic_loss: 430.356 \t adv: -0.202\n",
      "epoch: 381 \t loss: 0.178 \t return: 70.099 \t ep_len: 417.500 \t critic_loss: 631.868 \t adv: 0.203\n",
      "epoch: 382 \t loss: 0.031 \t return: 252.232 \t ep_len: 299.500 \t critic_loss: 460.493 \t adv: 0.003\n",
      "epoch: 383 \t loss: -0.018 \t return: 259.355 \t ep_len: 294.000 \t critic_loss: 430.918 \t adv: -0.026\n",
      "epoch: 384 \t loss: -0.176 \t return: 243.304 \t ep_len: 379.500 \t critic_loss: 549.886 \t adv: -0.189\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-474-754ca5714067>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mrender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#     render = False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mbatch_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcritic_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madvantage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mmean_rew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ret\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# mean return per episode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmean_rew_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmean_rew\u001b[0m  \u001b[1;31m# sum of returns of episodes from start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-411-e1b596a0310d>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(env, net, critic, cont, batch_size, render)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mbatch_obs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mbatch_acts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-282-f691ad4080a2>\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(net, obs, cont)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_policy_cont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcont\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-282-f691ad4080a2>\u001b[0m in \u001b[0;36mget_policy\u001b[1;34m(net, obs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_policy_cont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-d3958f0758aa>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "rew_req = 200\n",
    "i=0\n",
    "mean_rew = 0\n",
    "mean_rew_sum = 0\n",
    "avg_rew = 0\n",
    "\n",
    "while i<500:\n",
    "    i+=1\n",
    "    render = True if i%20==0 else False\n",
    "#     render = False\n",
    "    batch_loss,batch_ret, batch_len, critic_loss,advantage, entropy = train_one_epoch(env, net, critic, cont,batch_size=BATCH_SIZE, render=render)\n",
    "    mean_rew = np.mean(batch_ret) # mean return per episode\n",
    "    mean_rew_sum += mean_rew  # sum of returns of episodes from start\n",
    "    avg_rew = mean_rew_sum/i  # avg reward per episode from start\n",
    "    if render:\n",
    "        env.close()\n",
    "    print('epoch: %3d \\t loss: %.3f \\t return: %.3f \\t ep_len: %.3f \\t critic_loss: %.3f \\t adv: %.3f'%\n",
    "                (i, batch_loss, np.mean(batch_ret), np.mean(batch_len), critic_loss, np.mean(advantage)))\n",
    "    writer.add_scalar(\"loss\", batch_loss, i)\n",
    "    writer.add_scalar(\"reward_mean\", mean_rew, i)\n",
    "    writer.add_scalar('entropy', entropy,i)\n",
    "    writer.add_scalar('advantage',np.mean(advantage),i)\n",
    "    writer.add_scalar('critc_loss',critic_loss,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3]\n",
    "y = []\n",
    "y.append(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[4,2,3]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.append(x.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 2, 3]]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 2, 3], [4, 2, 3]]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.3292841e-01,  1.3936392e+38,  2.2844117e-02,  8.5078421e+37],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([79045296309277814133001641918405279744.,\n",
       "         8074543887068950992878338433657864192.], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.FloatTensor(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = Categorical(net(torch.FloatTensor(obs)))\n",
    "c2.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3786, grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.log_prob(torch.as_tensor(1, dtype = torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rew1(ep_rews):\n",
    "    rewards = []\n",
    "    disc_rew = 0\n",
    "    for rew in ep_rews[::-1]:\n",
    "        disc_rew = GAMMA*disc_rew + rew\n",
    "        rewards.append(disc_rew)\n",
    "    rewards = rewards[::-1]\n",
    "    return rewards\n",
    "        \n",
    "def test_rew2(ep_rews):\n",
    "    R = 0\n",
    "    returns = []\n",
    "    eps = 1e-6\n",
    "    for r in ep_rews[::-1]:\n",
    "        # calculate the discounted value\n",
    "        R = r + GAMMA * R\n",
    "        returns.insert(0, R)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.8519850599, 4.90099501, 3.9403989999999998, 2.9701, 1.99, 1.0]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,1,1,1,1,1]\n",
    "test_rew1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.8519850599, 4.90099501, 3.9403989999999998, 2.9701, 1.99, 1.0]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rew2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
