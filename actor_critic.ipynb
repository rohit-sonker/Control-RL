{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,obs_size, hidden_size,n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(obs_size,hidden_size),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(hidden_size,n_actions))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions.normal import Normal\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy(net, obs):\n",
    "    logits = net(obs)\n",
    "    return Categorical(logits=logits)\n",
    "\n",
    "def get_policy_cont(net, obs):\n",
    "    mu = net(obs)\n",
    "    mu = torch.tanh(mu)*1.8\n",
    "    return Normal(loc=mu, scale=STD)\n",
    "\n",
    "def get_action(net, obs, cont=False):\n",
    "    if cont:\n",
    "        policy = get_policy_cont(net, obs)\n",
    "    else:\n",
    "        policy = get_policy(net, obs)\n",
    "    act = policy.sample().item()\n",
    "    if cont:\n",
    "        act = np.array([act])\n",
    "    return act\n",
    "\n",
    "def reward_to_go(rews):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + (rtgs[i+1] if i+1 < n else 0)\n",
    "    return rtgs\n",
    "\n",
    "def reward_to_go_avg(rews, avg):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + (rtgs[i+1] if i+1 < n else 0) - avg/n\n",
    "    return rtgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(obs, acts, wts, net, cont=False):\n",
    "#     obs_v = torch.FloatTensor(obs)\n",
    "    if cont:\n",
    "        policy = get_policy_cont(net, obs)\n",
    "    else:\n",
    "        policy = get_policy(net,obs)\n",
    "#     print(policy)\n",
    "#     pdb.set_trace()\n",
    "    log_p = policy.log_prob(acts)\n",
    "    return -(log_p*wts).mean(), policy.entropy().mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic_targets(eps_rews):\n",
    "    targets = []\n",
    "    val = 0\n",
    "    for i in reversed(range(len(eps_rews))):\n",
    "        val = val*GAMMA + eps_rews[i]\n",
    "        targets.append(val)\n",
    "    targets = targets[::-1]\n",
    "    return targets\n",
    "\n",
    "def get_critic_targets_biased(eps_rews, eps_obs, critic):\n",
    "    targets = []\n",
    "\n",
    "    eps_rews = torch.as_tensor(eps_rews,dtype=torch.float32)\n",
    "        \n",
    "#     pdb.set_trace()\n",
    "    \n",
    "#     eps_rews = (eps_rews - torch.mean(eps_rews))/(torch.std(eps_rews))\n",
    "    eps_rews = eps_rews / torch.sum(eps_rews)\n",
    "    \n",
    "    \n",
    "    for i in range(len(eps_obs)):\n",
    "        if (i==len(eps_obs)-1):\n",
    "            val = eps_rews[i]\n",
    "        else:\n",
    "            next_obs = eps_obs[i+1]\n",
    "            val = eps_rews[i] + GAMMA*critic(torch.as_tensor(next_obs, dtype=torch.float32))\n",
    "        targets.append(val)\n",
    "        \n",
    "    \n",
    "    return targets\n",
    "\n",
    "def get_advantage(batch_obs, batch_rews, critic):\n",
    "#     batch_obs = torch.as_tensor(batch_obs, dtype = torch.float32)\n",
    "    targets = []\n",
    "    \n",
    "    batch_rews = torch.as_tensor(batch_rews,dtype=torch.float32)\n",
    "    \n",
    "#     batch_rews = (batch_rews - torch.mean(batch_rews))/(torch.std(batch_rews))\n",
    "    batch_rews = batch_rews/torch.sum(batch_rews)\n",
    "    \n",
    "    for i in range(len(batch_obs)):\n",
    "        obs = batch_obs[i]\n",
    "        obs = torch.as_tensor(obs, dtype = torch.float32)\n",
    "        \n",
    "        if (i==len(batch_obs)-1):\n",
    "            target = batch_rews[i] - critic(obs).item() \n",
    "        else:\n",
    "            next_obs = batch_obs[i+1]\n",
    "            next_obs = torch.as_tensor(next_obs, dtype = torch.float32)\n",
    "            target = batch_rews[i] + GAMMA*(critic(next_obs).item()) - critic(obs).item()\n",
    "        \n",
    "        targets.append(target.item())\n",
    "    \n",
    "    # last advantage should just be the rew\n",
    "#     targets.append(batch_rews[-1])\n",
    "    \n",
    "    return targets\n",
    "\n",
    "\n",
    "def get_batch_advantage(batch_obs, batch_rew, critic):\n",
    "    advantage = []\n",
    "    for i in range(len(batch_obs)):\n",
    "        eps_obs = batch_obs[i]\n",
    "        eps_rew = batch_rew[i]\n",
    "        adv = []\n",
    "#         eps_obs = torch.as_tensor(batch_obs, dtype = torch.float32)\n",
    "        for j in range(len(eps_obs)):\n",
    "            obs = eps_obs[j]\n",
    "            obs = torch.as_tensor(obs, dtype = torch.float32)\n",
    "            \n",
    "            if (j==len(eps_obs)-1):\n",
    "                val = eps_rew[j] - critic(obs).item()\n",
    "            else:\n",
    "                next_obs = eps_obs[j+1]\n",
    "                next_obs = torch.as_tensor(next_obs, dtype = torch.float32)\n",
    "                val = eps_rew[j] + GAMMA*critic(next_obs).item() - critic(obs).item()\n",
    "            adv.append(val)\n",
    "            \n",
    "        advantage.extend(adv)\n",
    "    \n",
    "    return advantage\n",
    "\n",
    "def get_normalised_adv_targets(ep_obs, ep_rews, critic):\n",
    "    rewards = []\n",
    "    disc_rew = 0\n",
    "    for rew in ep_rews[::-1]:\n",
    "        disc_rew = GAMMA*disc_rew + rew\n",
    "        rewards.append(disc_rew)\n",
    "        \n",
    "    returns = rewards[::-1]\n",
    "    eps = 1e-6\n",
    "\n",
    "    returns = torch.tensor(returns)\n",
    "    returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "    \n",
    "#     targets=rewards\n",
    "    targets = returns\n",
    "    advantage = []\n",
    "    \n",
    "    ep_obs = torch.as_tensor(ep_obs, dtype = torch.float32)\n",
    "    \n",
    "#     for obs, rew in zip(ep_obs, returns):\n",
    "#         adv = rew - critic(obs)\n",
    "#         advantage.append(adv.item())\n",
    "    \n",
    "    for i in range(len(ep_obs)):\n",
    "        a = returns[i] - critic(ep_obs[i])\n",
    "#         if (i==len(ep_obs)-1):\n",
    "#             a = rewards[i] - critic(ep_obs[i])\n",
    "#         else:\n",
    "#             a = rewards[i] + critic(ep_obs[i+1]) - critic(ep_obs[i])\n",
    "        \n",
    "        advantage.append(a.item())\n",
    "    \n",
    "    return advantage, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(env, net,critic, cont, batch_size=5000, render=False):\n",
    "    batch_obs = []\n",
    "    batch_wts = []\n",
    "    batch_acts = []\n",
    "    batch_rets = []\n",
    "    batch_len = []\n",
    "    eps_rew = []\n",
    "    batch_rews = []\n",
    "    targets = []\n",
    "    advantage = []\n",
    "    eps_obs = []\n",
    "    obs = env.reset()\n",
    "    done=False\n",
    "    epoch_finished_rendering = False\n",
    "    \n",
    "    batch_pack_obs = []\n",
    "    batch_pack_rew = []\n",
    "    \n",
    "    while True:\n",
    "        if not epoch_finished_rendering and render:\n",
    "            env.render()\n",
    "        \n",
    "        act = get_action(net, obs = torch.as_tensor(obs,dtype=torch.float32), cont=cont)\n",
    "        batch_obs.append(obs.copy())\n",
    "        batch_acts.append(act)\n",
    "        \n",
    "        eps_obs.append(obs)\n",
    "        \n",
    "        obs,rew,done,_ = env.step(act)\n",
    "        \n",
    "        eps_rew.append(rew)\n",
    "        \n",
    "        batch_rews.append(rew)\n",
    "#         obs= next_obs\n",
    "        \n",
    "        if done:\n",
    "            eps_ret = sum(eps_rew)\n",
    "            eps_len = len(eps_rew)\n",
    "            batch_rets.append(eps_ret)\n",
    "            batch_len.append(eps_len)\n",
    "            \n",
    "#             eps_target = get_critic_targets(eps_rew)\n",
    "#             eps_target = get_critic_targets_biased(eps_rew,eps_obs, critic)\n",
    "#             targets.extend(eps_target)\n",
    "            \n",
    "#             # get advantage estimate\n",
    "#             adv = get_advantage(eps_obs, eps_rew, critic)\n",
    "#             advantage.extend(adv)\n",
    "\n",
    "\n",
    "            batch_pack_obs.append(eps_obs)\n",
    "            batch_pack_rew.append(eps_rew)\n",
    "        \n",
    "            ep_adv, ep_targ = get_normalised_adv_targets(eps_obs, eps_rew, critic)\n",
    "            advantage.extend(ep_adv)\n",
    "            targets.extend(ep_targ)\n",
    "            \n",
    "            #plain\n",
    "#             batch_wts = batch_wts + [eps_ret]*eps_len\n",
    "\n",
    "            #subtract avg reward\n",
    "#             batch_wts = batch_wts + [eps_ret- avg_rew]*eps_len\n",
    "            \n",
    "            # reward to-go\n",
    "#             batch_wts = batch_wts + list(reward_to_go(eps_rew))\n",
    "\n",
    "            # reward to-go with avg rew\n",
    "#             batch_wts = batch_wts + list(reward_to_go_avg(eps_rew, avg_rew))\n",
    "            \n",
    "            eps_rew = []\n",
    "            eps_obs = []\n",
    "            done = False\n",
    "            \n",
    "            obs = env.reset()\n",
    "            epoch_finished_rendering = True\n",
    "            \n",
    "            if len(batch_obs)>batch_size:\n",
    "                break\n",
    "    \n",
    "    # critic update\n",
    "    pred_values = critic(torch.as_tensor(batch_obs, dtype = torch.float32))\n",
    "#     actual_values = get_critic_targets(batch_rews)\n",
    "    \n",
    "    optimizer_critic.zero_grad()\n",
    "    batch_loss_critic = loss_mae(pred_values.reshape(-1),\n",
    "                                 torch.as_tensor(targets, dtype = torch.float32))\n",
    "    batch_loss_critic.backward()\n",
    "    optimizer_critic.step()\n",
    "    \n",
    "#     # get advantage estimate\n",
    "#     advantage = get_advantage(batch_obs, batch_rews, critic)\n",
    "#     advantage = get_batch_advantage(batch_pack_obs, batch_pack_rew, critic)\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    # policy network update\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if cont:\n",
    "        batch_act_v = torch.as_tensor(batch_acts, dtype=torch.float32)\n",
    "    else:\n",
    "        batch_act_v = torch.as_tensor(batch_acts, dtype = torch.int32)\n",
    "    \n",
    "    batch_loss, entropy_v = compute_loss(obs = torch.as_tensor(batch_obs, dtype=torch.float32),\n",
    "                              acts = batch_act_v,\n",
    "                              wts = torch.as_tensor(advantage, dtype = torch.float32),\n",
    "                             net = net,cont=cont)\n",
    "    \n",
    "    entropy = entropy_v.item()\n",
    "    \n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    return batch_loss,batch_rets, batch_len, batch_loss_critic, advantage, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsonker001\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "env = gym.make('LunarLander-v2')\n",
    "cont = False\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "\n",
    "if cont:\n",
    "    n_actions = env.action_space.shape[0]\n",
    "else:\n",
    "    n_actions = env.action_space.n\n",
    "obs_size, n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(8,), Discrete(4))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 32\n",
    "BATCH_SIZE = 500\n",
    "GAMMA = 0.99\n",
    "STD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(obs_size = obs_size, hidden_size = HIDDEN_SIZE, n_actions= n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "act = get_action(net, obs= torch.as_tensor(obs, dtype=torch.float32), cont=cont)\n",
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "pol = get_policy(net, obs= torch.as_tensor(obs, dtype=torch.float32))\n",
    "# pol = get_policy_cont(net,obs= torch.as_tensor(obs, dtype=torch.float32))\n",
    "pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.2531, grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol.log_prob(torch.as_tensor(act, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = env.action_space.sample()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "lr = 1e-2\n",
    "optimizer = Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic\n",
    "critic = Net(obs_size = obs_size, hidden_size = HIDDEN_SIZE, n_actions=1)\n",
    "lr_c = 1e-2\n",
    "optimizer_critic = Adam(critic.parameters(), lr=lr_c)\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "loss_mae = MSELoss(reduction='sum')\n",
    "# loss_mae = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1364], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "value = critic(torch.as_tensor(obs, dtype=torch.float32))\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(comment=\"-actor_critic_mntcar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 \t loss: 0.141 \t return: -301.001 \t ep_len: 86.500 \t critic_loss: 456.352 \t adv: 0.084\n",
      "epoch:   2 \t loss: 0.039 \t return: -260.674 \t ep_len: 88.333 \t critic_loss: 518.926 \t adv: 0.030\n",
      "epoch:   3 \t loss: -0.059 \t return: -247.123 \t ep_len: 91.833 \t critic_loss: 582.611 \t adv: -0.035\n",
      "epoch:   4 \t loss: 0.049 \t return: -189.375 \t ep_len: 90.667 \t critic_loss: 536.127 \t adv: 0.031\n",
      "epoch:   5 \t loss: 0.023 \t return: -186.485 \t ep_len: 95.500 \t critic_loss: 553.543 \t adv: 0.027\n",
      "epoch:   6 \t loss: -0.008 \t return: -166.354 \t ep_len: 103.600 \t critic_loss: 610.368 \t adv: 0.007\n",
      "epoch:   7 \t loss: -0.128 \t return: -152.780 \t ep_len: 81.857 \t critic_loss: 612.724 \t adv: -0.100\n",
      "epoch:   8 \t loss: -0.095 \t return: -180.444 \t ep_len: 90.667 \t critic_loss: 589.227 \t adv: -0.074\n",
      "epoch:   9 \t loss: -0.184 \t return: -169.805 \t ep_len: 97.833 \t critic_loss: 651.115 \t adv: -0.117\n",
      "epoch:  10 \t loss: -0.087 \t return: -124.913 \t ep_len: 102.400 \t critic_loss: 490.891 \t adv: -0.073\n",
      "epoch:  11 \t loss: -0.049 \t return: -123.941 \t ep_len: 94.333 \t critic_loss: 544.721 \t adv: -0.016\n",
      "epoch:  12 \t loss: -0.027 \t return: -116.458 \t ep_len: 99.500 \t critic_loss: 563.828 \t adv: -0.000\n",
      "epoch:  13 \t loss: 0.008 \t return: -209.438 \t ep_len: 102.800 \t critic_loss: 523.206 \t adv: 0.004\n",
      "epoch:  14 \t loss: 0.038 \t return: -142.122 \t ep_len: 94.833 \t critic_loss: 528.182 \t adv: 0.027\n",
      "epoch:  15 \t loss: 0.004 \t return: -157.297 \t ep_len: 95.167 \t critic_loss: 501.137 \t adv: 0.016\n",
      "epoch:  16 \t loss: -0.053 \t return: -123.528 \t ep_len: 101.800 \t critic_loss: 429.886 \t adv: -0.035\n",
      "epoch:  17 \t loss: -0.090 \t return: -253.613 \t ep_len: 110.800 \t critic_loss: 558.285 \t adv: -0.094\n",
      "epoch:  18 \t loss: -0.023 \t return: -92.398 \t ep_len: 95.333 \t critic_loss: 458.164 \t adv: -0.009\n",
      "epoch:  19 \t loss: -0.089 \t return: -147.528 \t ep_len: 108.200 \t critic_loss: 463.948 \t adv: -0.067\n",
      "epoch:  20 \t loss: -0.000 \t return: -158.129 \t ep_len: 91.167 \t critic_loss: 444.883 \t adv: 0.000\n",
      "epoch:  21 \t loss: -0.033 \t return: -84.678 \t ep_len: 106.400 \t critic_loss: 445.138 \t adv: -0.014\n",
      "epoch:  22 \t loss: 0.075 \t return: -110.606 \t ep_len: 83.714 \t critic_loss: 406.990 \t adv: 0.072\n",
      "epoch:  23 \t loss: -0.029 \t return: -91.944 \t ep_len: 109.400 \t critic_loss: 424.874 \t adv: -0.007\n",
      "epoch:  24 \t loss: -0.038 \t return: -103.829 \t ep_len: 99.833 \t critic_loss: 451.944 \t adv: -0.013\n",
      "epoch:  25 \t loss: -0.077 \t return: -109.741 \t ep_len: 104.000 \t critic_loss: 399.264 \t adv: -0.083\n",
      "epoch:  26 \t loss: -0.071 \t return: -179.588 \t ep_len: 113.400 \t critic_loss: 580.516 \t adv: 0.002\n",
      "epoch:  27 \t loss: -0.062 \t return: -107.474 \t ep_len: 104.800 \t critic_loss: 386.551 \t adv: -0.070\n",
      "epoch:  28 \t loss: -0.180 \t return: -232.877 \t ep_len: 118.400 \t critic_loss: 714.884 \t adv: -0.115\n",
      "epoch:  29 \t loss: -0.065 \t return: -163.921 \t ep_len: 107.167 \t critic_loss: 777.114 \t adv: -0.026\n",
      "epoch:  30 \t loss: 0.124 \t return: -146.617 \t ep_len: 103.600 \t critic_loss: 311.409 \t adv: 0.112\n",
      "epoch:  31 \t loss: 0.131 \t return: -164.635 \t ep_len: 94.333 \t critic_loss: 629.382 \t adv: 0.133\n",
      "epoch:  32 \t loss: 0.056 \t return: -74.354 \t ep_len: 115.200 \t critic_loss: 436.263 \t adv: 0.086\n",
      "epoch:  33 \t loss: 0.112 \t return: -75.089 \t ep_len: 89.500 \t critic_loss: 317.450 \t adv: 0.101\n",
      "epoch:  34 \t loss: -0.021 \t return: -129.940 \t ep_len: 111.800 \t critic_loss: 316.446 \t adv: -0.059\n",
      "epoch:  35 \t loss: 0.027 \t return: -150.933 \t ep_len: 129.500 \t critic_loss: 339.942 \t adv: 0.018\n",
      "epoch:  36 \t loss: -0.198 \t return: -176.226 \t ep_len: 119.600 \t critic_loss: 421.972 \t adv: -0.182\n",
      "epoch:  37 \t loss: -0.060 \t return: -146.727 \t ep_len: 128.500 \t critic_loss: 556.895 \t adv: -0.017\n",
      "epoch:  38 \t loss: -0.221 \t return: -77.832 \t ep_len: 135.000 \t critic_loss: 335.797 \t adv: -0.163\n",
      "epoch:  39 \t loss: 0.007 \t return: -117.833 \t ep_len: 116.200 \t critic_loss: 317.605 \t adv: -0.011\n",
      "epoch:  40 \t loss: 1.533 \t return: -36.803 \t ep_len: 1000.000 \t critic_loss: 2235.534 \t adv: 1.240\n",
      "epoch:  41 \t loss: 0.916 \t return: -109.904 \t ep_len: 569.500 \t critic_loss: 1385.452 \t adv: 0.714\n",
      "epoch:  42 \t loss: -0.286 \t return: -147.410 \t ep_len: 138.250 \t critic_loss: 525.232 \t adv: -0.230\n",
      "epoch:  43 \t loss: -0.458 \t return: -144.849 \t ep_len: 133.000 \t critic_loss: 650.085 \t adv: -0.336\n",
      "epoch:  44 \t loss: -0.355 \t return: -152.918 \t ep_len: 126.800 \t critic_loss: 574.555 \t adv: -0.315\n",
      "epoch:  45 \t loss: -0.290 \t return: -167.425 \t ep_len: 118.800 \t critic_loss: 613.786 \t adv: -0.241\n",
      "epoch:  46 \t loss: -0.274 \t return: -148.287 \t ep_len: 110.800 \t critic_loss: 427.906 \t adv: -0.216\n",
      "epoch:  47 \t loss: -0.320 \t return: -124.821 \t ep_len: 115.800 \t critic_loss: 386.310 \t adv: -0.249\n",
      "epoch:  48 \t loss: -0.422 \t return: -135.952 \t ep_len: 134.750 \t critic_loss: 463.872 \t adv: -0.315\n",
      "epoch:  49 \t loss: -0.253 \t return: -202.594 \t ep_len: 134.750 \t critic_loss: 504.573 \t adv: -0.204\n",
      "epoch:  50 \t loss: -0.284 \t return: -88.662 \t ep_len: 121.400 \t critic_loss: 567.103 \t adv: -0.167\n",
      "epoch:  51 \t loss: 0.166 \t return: -157.227 \t ep_len: 355.750 \t critic_loss: 1393.786 \t adv: 0.138\n",
      "epoch:  52 \t loss: -0.170 \t return: -81.982 \t ep_len: 121.600 \t critic_loss: 445.853 \t adv: -0.122\n",
      "epoch:  53 \t loss: -0.131 \t return: -139.606 \t ep_len: 135.250 \t critic_loss: 513.006 \t adv: -0.090\n",
      "epoch:  54 \t loss: -0.089 \t return: -122.480 \t ep_len: 152.750 \t critic_loss: 501.995 \t adv: -0.088\n",
      "epoch:  55 \t loss: -0.081 \t return: -61.433 \t ep_len: 136.250 \t critic_loss: 534.265 \t adv: -0.045\n",
      "epoch:  56 \t loss: 0.015 \t return: -199.481 \t ep_len: 131.750 \t critic_loss: 395.304 \t adv: -0.059\n",
      "epoch:  57 \t loss: -0.028 \t return: -73.500 \t ep_len: 123.000 \t critic_loss: 452.818 \t adv: -0.006\n",
      "epoch:  58 \t loss: -0.057 \t return: -112.911 \t ep_len: 128.500 \t critic_loss: 425.213 \t adv: -0.022\n",
      "epoch:  59 \t loss: -0.031 \t return: -253.174 \t ep_len: 128.000 \t critic_loss: 526.677 \t adv: -0.052\n",
      "epoch:  60 \t loss: 0.030 \t return: -226.480 \t ep_len: 153.000 \t critic_loss: 465.566 \t adv: 0.016\n",
      "epoch:  61 \t loss: 0.026 \t return: -54.259 \t ep_len: 121.600 \t critic_loss: 522.552 \t adv: 0.030\n",
      "epoch:  62 \t loss: 0.007 \t return: -154.730 \t ep_len: 152.250 \t critic_loss: 668.039 \t adv: -0.008\n",
      "epoch:  63 \t loss: -0.055 \t return: -183.637 \t ep_len: 119.600 \t critic_loss: 491.755 \t adv: -0.024\n",
      "epoch:  64 \t loss: 0.004 \t return: -157.745 \t ep_len: 129.250 \t critic_loss: 375.703 \t adv: 0.007\n",
      "epoch:  65 \t loss: -0.044 \t return: -83.133 \t ep_len: 123.800 \t critic_loss: 514.793 \t adv: -0.004\n",
      "epoch:  66 \t loss: -0.036 \t return: -57.202 \t ep_len: 134.750 \t critic_loss: 459.034 \t adv: -0.001\n",
      "epoch:  67 \t loss: -0.028 \t return: -76.274 \t ep_len: 136.500 \t critic_loss: 363.662 \t adv: -0.012\n",
      "epoch:  68 \t loss: -0.040 \t return: -77.226 \t ep_len: 127.000 \t critic_loss: 389.356 \t adv: -0.049\n",
      "epoch:  69 \t loss: 0.016 \t return: -102.668 \t ep_len: 114.400 \t critic_loss: 371.755 \t adv: 0.016\n",
      "epoch:  70 \t loss: -0.042 \t return: -9.586 \t ep_len: 133.750 \t critic_loss: 356.585 \t adv: -0.031\n",
      "epoch:  71 \t loss: -0.090 \t return: -118.901 \t ep_len: 138.000 \t critic_loss: 391.327 \t adv: -0.115\n",
      "epoch:  72 \t loss: -0.189 \t return: -12.465 \t ep_len: 175.250 \t critic_loss: 477.857 \t adv: -0.125\n",
      "epoch:  73 \t loss: -0.052 \t return: -93.390 \t ep_len: 207.667 \t critic_loss: 404.981 \t adv: -0.035\n",
      "epoch:  74 \t loss: -0.157 \t return: -68.275 \t ep_len: 153.000 \t critic_loss: 399.518 \t adv: -0.134\n",
      "epoch:  75 \t loss: -0.165 \t return: -140.246 \t ep_len: 199.333 \t critic_loss: 357.179 \t adv: -0.194\n",
      "epoch:  76 \t loss: 0.157 \t return: -117.018 \t ep_len: 458.000 \t critic_loss: 1105.166 \t adv: 0.164\n",
      "epoch:  77 \t loss: -0.219 \t return: -113.941 \t ep_len: 179.333 \t critic_loss: 330.816 \t adv: -0.215\n",
      "epoch:  78 \t loss: 0.299 \t return: -222.312 \t ep_len: 565.000 \t critic_loss: 506.533 \t adv: 0.273\n",
      "epoch:  79 \t loss: 0.360 \t return: -12.730 \t ep_len: 1000.000 \t critic_loss: 823.993 \t adv: 0.311\n",
      "epoch:  80 \t loss: -0.138 \t return: -31.785 \t ep_len: 182.667 \t critic_loss: 278.931 \t adv: -0.154\n",
      "epoch:  81 \t loss: -0.329 \t return: -170.624 \t ep_len: 224.000 \t critic_loss: 537.038 \t adv: -0.316\n",
      "epoch:  82 \t loss: 0.155 \t return: -97.503 \t ep_len: 632.500 \t critic_loss: 960.453 \t adv: 0.142\n",
      "epoch:  83 \t loss: -0.071 \t return: -122.275 \t ep_len: 296.333 \t critic_loss: 435.618 \t adv: -0.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  84 \t loss: -0.538 \t return: -112.007 \t ep_len: 184.333 \t critic_loss: 534.094 \t adv: -0.438\n",
      "epoch:  85 \t loss: 0.180 \t return: -87.032 \t ep_len: 449.000 \t critic_loss: 1020.179 \t adv: 0.147\n",
      "epoch:  86 \t loss: -0.013 \t return: -121.580 \t ep_len: 258.000 \t critic_loss: 456.497 \t adv: 0.007\n",
      "epoch:  87 \t loss: 0.457 \t return: -29.532 \t ep_len: 1000.000 \t critic_loss: 692.234 \t adv: 0.391\n",
      "epoch:  88 \t loss: 0.342 \t return: -37.794 \t ep_len: 557.500 \t critic_loss: 987.093 \t adv: 0.307\n",
      "epoch:  89 \t loss: -0.651 \t return: -23.108 \t ep_len: 167.000 \t critic_loss: 491.758 \t adv: -0.581\n",
      "epoch:  90 \t loss: 0.107 \t return: -43.139 \t ep_len: 366.250 \t critic_loss: 1130.261 \t adv: 0.099\n",
      "epoch:  91 \t loss: -0.515 \t return: -82.644 \t ep_len: 147.000 \t critic_loss: 662.374 \t adv: -0.458\n",
      "epoch:  92 \t loss: 0.234 \t return: -32.221 \t ep_len: 369.750 \t critic_loss: 1215.390 \t adv: 0.193\n",
      "epoch:  93 \t loss: -0.517 \t return: -27.152 \t ep_len: 136.000 \t critic_loss: 369.531 \t adv: -0.447\n",
      "epoch:  94 \t loss: -0.268 \t return: -102.707 \t ep_len: 178.667 \t critic_loss: 422.050 \t adv: -0.189\n",
      "epoch:  95 \t loss: 0.238 \t return: -12.475 \t ep_len: 566.500 \t critic_loss: 739.761 \t adv: 0.247\n",
      "epoch:  96 \t loss: -0.352 \t return: -17.815 \t ep_len: 139.750 \t critic_loss: 359.518 \t adv: -0.345\n",
      "epoch:  97 \t loss: 0.352 \t return: 7.749 \t ep_len: 1000.000 \t critic_loss: 635.447 \t adv: 0.311\n",
      "epoch:  98 \t loss: -0.503 \t return: 18.683 \t ep_len: 177.333 \t critic_loss: 426.615 \t adv: -0.439\n",
      "epoch:  99 \t loss: -0.559 \t return: -19.409 \t ep_len: 141.250 \t critic_loss: 470.338 \t adv: -0.468\n",
      "epoch: 100 \t loss: -0.446 \t return: -16.580 \t ep_len: 156.750 \t critic_loss: 435.877 \t adv: -0.394\n",
      "epoch: 101 \t loss: -0.384 \t return: -21.386 \t ep_len: 115.200 \t critic_loss: 387.819 \t adv: -0.333\n",
      "epoch: 102 \t loss: -0.274 \t return: -3.448 \t ep_len: 125.500 \t critic_loss: 293.908 \t adv: -0.264\n",
      "epoch: 103 \t loss: 0.177 \t return: 2.492 \t ep_len: 433.000 \t critic_loss: 763.426 \t adv: 0.148\n",
      "epoch: 104 \t loss: 0.229 \t return: -7.186 \t ep_len: 432.333 \t critic_loss: 878.868 \t adv: 0.205\n",
      "epoch: 105 \t loss: -0.235 \t return: 22.113 \t ep_len: 166.500 \t critic_loss: 384.440 \t adv: -0.218\n",
      "epoch: 106 \t loss: -0.094 \t return: -51.474 \t ep_len: 128.750 \t critic_loss: 245.882 \t adv: -0.111\n",
      "epoch: 107 \t loss: -0.222 \t return: -25.798 \t ep_len: 161.500 \t critic_loss: 369.541 \t adv: -0.191\n",
      "epoch: 108 \t loss: 0.320 \t return: -61.333 \t ep_len: 561.000 \t critic_loss: 872.572 \t adv: 0.297\n",
      "epoch: 109 \t loss: 0.327 \t return: 41.448 \t ep_len: 1000.000 \t critic_loss: 641.496 \t adv: 0.311\n",
      "epoch: 110 \t loss: -0.261 \t return: -150.503 \t ep_len: 207.667 \t critic_loss: 354.547 \t adv: -0.227\n",
      "epoch: 111 \t loss: 0.301 \t return: -73.800 \t ep_len: 1000.000 \t critic_loss: 840.938 \t adv: 0.270\n",
      "epoch: 112 \t loss: 0.159 \t return: -20.692 \t ep_len: 582.500 \t critic_loss: 617.156 \t adv: 0.156\n",
      "epoch: 113 \t loss: 0.241 \t return: -152.161 \t ep_len: 518.000 \t critic_loss: 352.024 \t adv: 0.252\n",
      "epoch: 114 \t loss: 0.156 \t return: 14.787 \t ep_len: 1000.000 \t critic_loss: 642.620 \t adv: 0.164\n",
      "epoch: 115 \t loss: 0.021 \t return: -113.069 \t ep_len: 613.000 \t critic_loss: 571.968 \t adv: 0.023\n",
      "epoch: 116 \t loss: -0.048 \t return: -60.297 \t ep_len: 704.500 \t critic_loss: 624.044 \t adv: -0.020\n",
      "epoch: 117 \t loss: 0.122 \t return: -35.430 \t ep_len: 1000.000 \t critic_loss: 537.279 \t adv: 0.124\n",
      "epoch: 118 \t loss: 0.047 \t return: -40.489 \t ep_len: 1000.000 \t critic_loss: 500.561 \t adv: 0.054\n",
      "epoch: 119 \t loss: -0.047 \t return: 9.834 \t ep_len: 1000.000 \t critic_loss: 659.179 \t adv: -0.006\n",
      "epoch: 120 \t loss: -0.130 \t return: -132.290 \t ep_len: 507.000 \t critic_loss: 529.729 \t adv: -0.146\n",
      "epoch: 121 \t loss: -0.013 \t return: -185.425 \t ep_len: 886.000 \t critic_loss: 705.161 \t adv: 0.007\n",
      "epoch: 122 \t loss: -0.258 \t return: -136.646 \t ep_len: 650.500 \t critic_loss: 1211.814 \t adv: -0.249\n",
      "epoch: 123 \t loss: -0.749 \t return: -27.431 \t ep_len: 292.500 \t critic_loss: 773.763 \t adv: -0.634\n",
      "epoch: 124 \t loss: -0.453 \t return: -85.004 \t ep_len: 309.000 \t critic_loss: 317.843 \t adv: -0.406\n",
      "epoch: 125 \t loss: -0.104 \t return: 4.994 \t ep_len: 1000.000 \t critic_loss: 715.178 \t adv: -0.060\n",
      "epoch: 126 \t loss: -1.003 \t return: -22.259 \t ep_len: 297.500 \t critic_loss: 946.833 \t adv: -0.835\n",
      "epoch: 127 \t loss: 0.110 \t return: -138.159 \t ep_len: 616.000 \t critic_loss: 695.749 \t adv: 0.083\n",
      "epoch: 128 \t loss: -0.032 \t return: 52.448 \t ep_len: 624.000 \t critic_loss: 868.568 \t adv: -0.012\n",
      "epoch: 129 \t loss: 0.401 \t return: 31.086 \t ep_len: 1000.000 \t critic_loss: 485.331 \t adv: 0.356\n",
      "epoch: 130 \t loss: -0.513 \t return: 4.963 \t ep_len: 170.667 \t critic_loss: 336.861 \t adv: -0.496\n",
      "epoch: 131 \t loss: 0.188 \t return: 20.260 \t ep_len: 459.667 \t critic_loss: 773.229 \t adv: 0.144\n",
      "epoch: 132 \t loss: -0.503 \t return: 20.194 \t ep_len: 188.333 \t critic_loss: 367.363 \t adv: -0.446\n",
      "epoch: 133 \t loss: -0.394 \t return: 21.134 \t ep_len: 173.000 \t critic_loss: 259.530 \t adv: -0.367\n",
      "epoch: 134 \t loss: -0.250 \t return: -31.737 \t ep_len: 223.000 \t critic_loss: 328.341 \t adv: -0.188\n",
      "epoch: 135 \t loss: 0.598 \t return: -24.433 \t ep_len: 574.000 \t critic_loss: 1199.262 \t adv: 0.500\n",
      "epoch: 136 \t loss: 0.521 \t return: 24.312 \t ep_len: 1000.000 \t critic_loss: 691.020 \t adv: 0.458\n",
      "epoch: 137 \t loss: -0.298 \t return: -9.536 \t ep_len: 180.333 \t critic_loss: 315.029 \t adv: -0.274\n",
      "epoch: 138 \t loss: 0.247 \t return: -1.689 \t ep_len: 450.667 \t critic_loss: 766.225 \t adv: 0.212\n",
      "epoch: 139 \t loss: 0.341 \t return: 14.090 \t ep_len: 473.333 \t critic_loss: 1125.135 \t adv: 0.297\n",
      "epoch: 140 \t loss: -0.356 \t return: 2.467 \t ep_len: 190.667 \t critic_loss: 377.000 \t adv: -0.357\n",
      "epoch: 141 \t loss: 0.205 \t return: 34.156 \t ep_len: 458.000 \t critic_loss: 747.505 \t adv: 0.190\n",
      "epoch: 142 \t loss: 0.406 \t return: 52.291 \t ep_len: 1000.000 \t critic_loss: 544.605 \t adv: 0.364\n",
      "epoch: 143 \t loss: -0.387 \t return: 18.218 \t ep_len: 203.333 \t critic_loss: 400.454 \t adv: -0.342\n",
      "epoch: 144 \t loss: 0.092 \t return: 40.754 \t ep_len: 479.000 \t critic_loss: 812.100 \t adv: 0.069\n",
      "epoch: 145 \t loss: -0.317 \t return: 11.950 \t ep_len: 182.333 \t critic_loss: 328.693 \t adv: -0.334\n",
      "epoch: 146 \t loss: 0.005 \t return: 50.003 \t ep_len: 546.000 \t critic_loss: 1171.786 \t adv: 0.157\n",
      "epoch: 147 \t loss: -0.472 \t return: 21.485 \t ep_len: 208.000 \t critic_loss: 442.895 \t adv: -0.446\n",
      "epoch: 148 \t loss: 0.238 \t return: 9.524 \t ep_len: 1000.000 \t critic_loss: 615.404 \t adv: 0.256\n",
      "epoch: 149 \t loss: -0.418 \t return: -31.597 \t ep_len: 209.000 \t critic_loss: 442.312 \t adv: -0.391\n",
      "epoch: 150 \t loss: 0.177 \t return: 26.502 \t ep_len: 656.500 \t critic_loss: 1033.923 \t adv: 0.134\n",
      "epoch: 151 \t loss: 0.103 \t return: 31.397 \t ep_len: 590.500 \t critic_loss: 844.221 \t adv: 0.099\n",
      "epoch: 152 \t loss: -0.530 \t return: -6.907 \t ep_len: 238.000 \t critic_loss: 524.336 \t adv: -0.449\n",
      "epoch: 153 \t loss: -0.076 \t return: 37.474 \t ep_len: 632.500 \t critic_loss: 563.554 \t adv: -0.053\n",
      "epoch: 154 \t loss: -0.009 \t return: 18.111 \t ep_len: 590.000 \t critic_loss: 606.873 \t adv: 0.009\n",
      "epoch: 155 \t loss: 0.033 \t return: 21.331 \t ep_len: 593.000 \t critic_loss: 553.819 \t adv: 0.061\n",
      "epoch: 156 \t loss: 0.158 \t return: 84.571 \t ep_len: 1000.000 \t critic_loss: 407.370 \t adv: 0.186\n",
      "epoch: 157 \t loss: 0.200 \t return: 12.330 \t ep_len: 1000.000 \t critic_loss: 776.277 \t adv: 0.189\n",
      "epoch: 158 \t loss: 0.221 \t return: 86.601 \t ep_len: 608.500 \t critic_loss: 674.756 \t adv: 0.212\n",
      "epoch: 159 \t loss: -0.583 \t return: -17.377 \t ep_len: 252.500 \t critic_loss: 367.947 \t adv: -0.554\n",
      "epoch: 160 \t loss: 0.055 \t return: 62.543 \t ep_len: 602.500 \t critic_loss: 493.112 \t adv: 0.075\n",
      "epoch: 161 \t loss: 0.093 \t return: 33.178 \t ep_len: 656.500 \t critic_loss: 578.468 \t adv: 0.113\n",
      "epoch: 162 \t loss: 0.319 \t return: 116.852 \t ep_len: 1000.000 \t critic_loss: 393.084 \t adv: 0.304\n",
      "epoch: 163 \t loss: 0.364 \t return: 100.269 \t ep_len: 1000.000 \t critic_loss: 355.191 \t adv: 0.331\n",
      "epoch: 164 \t loss: 0.322 \t return: 134.049 \t ep_len: 1000.000 \t critic_loss: 410.726 \t adv: 0.319\n",
      "epoch: 165 \t loss: -0.046 \t return: 68.915 \t ep_len: 647.500 \t critic_loss: 861.719 \t adv: -0.038\n",
      "epoch: 166 \t loss: -0.287 \t return: 29.538 \t ep_len: 662.000 \t critic_loss: 668.136 \t adv: -0.228\n",
      "epoch: 167 \t loss: 0.150 \t return: 90.818 \t ep_len: 1000.000 \t critic_loss: 241.803 \t adv: 0.164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 168 \t loss: -0.346 \t return: 32.468 \t ep_len: 662.500 \t critic_loss: 640.004 \t adv: -0.285\n",
      "epoch: 169 \t loss: 0.214 \t return: 110.256 \t ep_len: 1000.000 \t critic_loss: 234.916 \t adv: 0.214\n",
      "epoch: 170 \t loss: -0.252 \t return: 35.185 \t ep_len: 476.000 \t critic_loss: 627.342 \t adv: -0.235\n",
      "epoch: 171 \t loss: -0.089 \t return: 41.257 \t ep_len: 634.500 \t critic_loss: 579.761 \t adv: -0.083\n",
      "epoch: 172 \t loss: -0.073 \t return: 34.723 \t ep_len: 633.500 \t critic_loss: 504.072 \t adv: -0.061\n",
      "epoch: 173 \t loss: -0.039 \t return: 17.368 \t ep_len: 624.000 \t critic_loss: 760.825 \t adv: -0.017\n",
      "epoch: 174 \t loss: -0.151 \t return: 80.557 \t ep_len: 653.000 \t critic_loss: 621.848 \t adv: -0.127\n",
      "epoch: 175 \t loss: -0.973 \t return: -7.131 \t ep_len: 316.500 \t critic_loss: 676.367 \t adv: -0.846\n",
      "epoch: 176 \t loss: 0.223 \t return: 41.957 \t ep_len: 1000.000 \t critic_loss: 248.954 \t adv: 0.250\n",
      "epoch: 177 \t loss: 0.002 \t return: 48.186 \t ep_len: 622.500 \t critic_loss: 608.890 \t adv: 0.000\n",
      "epoch: 178 \t loss: 0.321 \t return: 77.442 \t ep_len: 1000.000 \t critic_loss: 509.975 \t adv: 0.293\n",
      "epoch: 179 \t loss: 0.095 \t return: 115.468 \t ep_len: 1000.000 \t critic_loss: 202.833 \t adv: 0.102\n",
      "epoch: 180 \t loss: 0.265 \t return: 120.743 \t ep_len: 1000.000 \t critic_loss: 310.498 \t adv: 0.268\n",
      "epoch: 181 \t loss: -0.707 \t return: -7.915 \t ep_len: 282.000 \t critic_loss: 499.830 \t adv: -0.667\n",
      "epoch: 182 \t loss: 0.007 \t return: 12.333 \t ep_len: 622.500 \t critic_loss: 782.448 \t adv: 0.008\n",
      "epoch: 183 \t loss: 0.170 \t return: 89.417 \t ep_len: 1000.000 \t critic_loss: 341.884 \t adv: 0.169\n",
      "epoch: 184 \t loss: 0.032 \t return: 90.408 \t ep_len: 1000.000 \t critic_loss: 381.144 \t adv: 0.047\n",
      "epoch: 185 \t loss: 0.061 \t return: 77.191 \t ep_len: 1000.000 \t critic_loss: 277.390 \t adv: 0.066\n",
      "epoch: 186 \t loss: 0.282 \t return: 165.722 \t ep_len: 1000.000 \t critic_loss: 366.487 \t adv: 0.283\n",
      "epoch: 187 \t loss: 0.241 \t return: 122.824 \t ep_len: 1000.000 \t critic_loss: 412.428 \t adv: 0.269\n",
      "epoch: 188 \t loss: 0.299 \t return: 168.602 \t ep_len: 1000.000 \t critic_loss: 319.465 \t adv: 0.306\n",
      "epoch: 189 \t loss: -0.083 \t return: 33.635 \t ep_len: 616.000 \t critic_loss: 617.813 \t adv: -0.073\n",
      "epoch: 190 \t loss: -0.003 \t return: 71.153 \t ep_len: 1000.000 \t critic_loss: 449.407 \t adv: 0.021\n",
      "epoch: 191 \t loss: -0.215 \t return: 187.066 \t ep_len: 625.000 \t critic_loss: 1003.237 \t adv: -0.014\n",
      "epoch: 192 \t loss: -1.027 \t return: 7.869 \t ep_len: 314.000 \t critic_loss: 801.737 \t adv: -0.923\n",
      "epoch: 193 \t loss: -0.087 \t return: 69.073 \t ep_len: 637.500 \t critic_loss: 459.105 \t adv: -0.082\n",
      "epoch: 194 \t loss: 0.062 \t return: 76.003 \t ep_len: 1000.000 \t critic_loss: 307.081 \t adv: 0.067\n",
      "epoch: 195 \t loss: 0.034 \t return: 69.227 \t ep_len: 591.500 \t critic_loss: 523.702 \t adv: 0.032\n",
      "epoch: 196 \t loss: -0.096 \t return: 69.150 \t ep_len: 648.500 \t critic_loss: 653.017 \t adv: -0.079\n",
      "epoch: 197 \t loss: -0.223 \t return: 25.402 \t ep_len: 500.000 \t critic_loss: 942.236 \t adv: -0.192\n",
      "epoch: 198 \t loss: 0.290 \t return: 100.209 \t ep_len: 1000.000 \t critic_loss: 272.949 \t adv: 0.272\n",
      "epoch: 199 \t loss: -0.792 \t return: 11.729 \t ep_len: 207.000 \t critic_loss: 643.113 \t adv: -0.789\n",
      "epoch: 200 \t loss: -0.034 \t return: 93.081 \t ep_len: 444.000 \t critic_loss: 1043.126 \t adv: 0.018\n",
      "epoch: 201 \t loss: -0.757 \t return: 20.485 \t ep_len: 189.000 \t critic_loss: 540.248 \t adv: -0.705\n",
      "epoch: 202 \t loss: -0.800 \t return: 8.623 \t ep_len: 229.000 \t critic_loss: 676.007 \t adv: -0.722\n",
      "epoch: 203 \t loss: -0.256 \t return: 127.281 \t ep_len: 282.000 \t critic_loss: 465.699 \t adv: -0.177\n",
      "epoch: 204 \t loss: -0.530 \t return: 33.994 \t ep_len: 195.667 \t critic_loss: 423.772 \t adv: -0.519\n",
      "epoch: 205 \t loss: 0.163 \t return: 54.755 \t ep_len: 474.667 \t critic_loss: 814.253 \t adv: 0.151\n",
      "epoch: 206 \t loss: 0.406 \t return: 83.766 \t ep_len: 1000.000 \t critic_loss: 694.963 \t adv: 0.425\n",
      "epoch: 207 \t loss: 0.191 \t return: 54.821 \t ep_len: 448.000 \t critic_loss: 743.659 \t adv: 0.182\n",
      "epoch: 208 \t loss: 0.090 \t return: 26.145 \t ep_len: 600.000 \t critic_loss: 682.594 \t adv: 0.130\n",
      "epoch: 209 \t loss: 0.049 \t return: -48.276 \t ep_len: 531.000 \t critic_loss: 177.157 \t adv: 0.034\n",
      "epoch: 210 \t loss: 0.289 \t return: 112.331 \t ep_len: 1000.000 \t critic_loss: 480.013 \t adv: 0.284\n",
      "epoch: 211 \t loss: -0.379 \t return: 3.962 \t ep_len: 239.667 \t critic_loss: 474.063 \t adv: -0.367\n",
      "epoch: 212 \t loss: 0.364 \t return: 55.847 \t ep_len: 1000.000 \t critic_loss: 582.944 \t adv: 0.353\n",
      "epoch: 213 \t loss: -0.477 \t return: 13.164 \t ep_len: 304.000 \t critic_loss: 439.745 \t adv: -0.426\n",
      "epoch: 214 \t loss: 0.222 \t return: 84.084 \t ep_len: 1000.000 \t critic_loss: 470.628 \t adv: 0.245\n",
      "epoch: 215 \t loss: 0.227 \t return: 110.395 \t ep_len: 1000.000 \t critic_loss: 491.076 \t adv: 0.203\n",
      "epoch: 216 \t loss: 0.290 \t return: 92.341 \t ep_len: 1000.000 \t critic_loss: 507.487 \t adv: 0.323\n",
      "epoch: 217 \t loss: 0.200 \t return: 71.216 \t ep_len: 1000.000 \t critic_loss: 395.783 \t adv: 0.198\n",
      "epoch: 218 \t loss: 0.222 \t return: 133.992 \t ep_len: 1000.000 \t critic_loss: 313.938 \t adv: 0.194\n",
      "epoch: 219 \t loss: 0.197 \t return: 95.954 \t ep_len: 1000.000 \t critic_loss: 362.210 \t adv: 0.222\n",
      "epoch: 220 \t loss: 0.210 \t return: 110.701 \t ep_len: 1000.000 \t critic_loss: 374.949 \t adv: 0.204\n",
      "epoch: 221 \t loss: 0.016 \t return: 14.269 \t ep_len: 667.000 \t critic_loss: 583.149 \t adv: 0.029\n",
      "epoch: 222 \t loss: 0.025 \t return: 78.398 \t ep_len: 614.000 \t critic_loss: 530.439 \t adv: 0.014\n",
      "epoch: 223 \t loss: 0.180 \t return: 63.097 \t ep_len: 1000.000 \t critic_loss: 406.824 \t adv: 0.227\n",
      "epoch: 224 \t loss: -0.153 \t return: 130.839 \t ep_len: 477.000 \t critic_loss: 725.547 \t adv: -0.024\n",
      "epoch: 225 \t loss: 0.275 \t return: 108.842 \t ep_len: 1000.000 \t critic_loss: 224.468 \t adv: 0.264\n",
      "epoch: 226 \t loss: 0.102 \t return: 122.808 \t ep_len: 1000.000 \t critic_loss: 159.108 \t adv: 0.102\n",
      "epoch: 227 \t loss: 0.137 \t return: 126.084 \t ep_len: 1000.000 \t critic_loss: 230.254 \t adv: 0.125\n",
      "epoch: 228 \t loss: 0.138 \t return: 63.321 \t ep_len: 1000.000 \t critic_loss: 327.877 \t adv: 0.191\n",
      "epoch: 229 \t loss: 0.043 \t return: 189.913 \t ep_len: 1000.000 \t critic_loss: 391.402 \t adv: 0.156\n",
      "epoch: 230 \t loss: -0.318 \t return: 73.249 \t ep_len: 465.000 \t critic_loss: 904.250 \t adv: -0.352\n",
      "epoch: 231 \t loss: -1.375 \t return: 8.181 \t ep_len: 206.333 \t critic_loss: 1154.852 \t adv: -1.289\n",
      "epoch: 232 \t loss: 0.042 \t return: 127.660 \t ep_len: 1000.000 \t critic_loss: 213.575 \t adv: 0.041\n",
      "epoch: 233 \t loss: -1.280 \t return: 74.235 \t ep_len: 245.000 \t critic_loss: 1473.529 \t adv: -1.042\n",
      "epoch: 234 \t loss: 0.194 \t return: 132.933 \t ep_len: 1000.000 \t critic_loss: 188.367 \t adv: 0.205\n",
      "epoch: 235 \t loss: -0.068 \t return: 50.759 \t ep_len: 607.500 \t critic_loss: 524.685 \t adv: -0.074\n",
      "epoch: 236 \t loss: -0.838 \t return: -20.191 \t ep_len: 277.500 \t critic_loss: 534.788 \t adv: -0.861\n",
      "epoch: 237 \t loss: 0.154 \t return: 111.119 \t ep_len: 1000.000 \t critic_loss: 171.537 \t adv: 0.146\n",
      "epoch: 238 \t loss: -0.134 \t return: 62.430 \t ep_len: 474.000 \t critic_loss: 726.251 \t adv: -0.126\n",
      "epoch: 239 \t loss: 0.233 \t return: 125.880 \t ep_len: 1000.000 \t critic_loss: 243.177 \t adv: 0.219\n",
      "epoch: 240 \t loss: -0.005 \t return: 70.162 \t ep_len: 607.000 \t critic_loss: 502.880 \t adv: 0.014\n",
      "epoch: 241 \t loss: 0.221 \t return: 155.051 \t ep_len: 1000.000 \t critic_loss: 248.265 \t adv: 0.222\n",
      "epoch: 242 \t loss: 0.072 \t return: 94.832 \t ep_len: 589.500 \t critic_loss: 518.408 \t adv: 0.092\n",
      "epoch: 243 \t loss: 0.203 \t return: 127.928 \t ep_len: 1000.000 \t critic_loss: 264.156 \t adv: 0.220\n",
      "epoch: 244 \t loss: 0.126 \t return: 123.627 \t ep_len: 1000.000 \t critic_loss: 229.323 \t adv: 0.128\n",
      "epoch: 245 \t loss: -0.045 \t return: 49.033 \t ep_len: 462.667 \t critic_loss: 677.552 \t adv: -0.053\n",
      "epoch: 246 \t loss: -0.880 \t return: 70.972 \t ep_len: 352.500 \t critic_loss: 1137.864 \t adv: -0.631\n",
      "epoch: 247 \t loss: 0.284 \t return: 180.979 \t ep_len: 1000.000 \t critic_loss: 354.863 \t adv: 0.306\n",
      "epoch: 248 \t loss: -0.096 \t return: 71.976 \t ep_len: 483.000 \t critic_loss: 721.212 \t adv: -0.087\n",
      "epoch: 249 \t loss: 0.124 \t return: 148.194 \t ep_len: 1000.000 \t critic_loss: 202.635 \t adv: 0.121\n",
      "epoch: 250 \t loss: -0.126 \t return: 54.338 \t ep_len: 630.500 \t critic_loss: 590.112 \t adv: -0.111\n",
      "epoch: 251 \t loss: 0.080 \t return: 106.718 \t ep_len: 1000.000 \t critic_loss: 229.350 \t adv: 0.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 252 \t loss: -0.012 \t return: 79.851 \t ep_len: 619.000 \t critic_loss: 539.122 \t adv: -0.019\n",
      "epoch: 253 \t loss: 0.237 \t return: 110.742 \t ep_len: 1000.000 \t critic_loss: 308.863 \t adv: 0.242\n",
      "epoch: 254 \t loss: 0.251 \t return: 144.827 \t ep_len: 1000.000 \t critic_loss: 319.791 \t adv: 0.257\n",
      "epoch: 255 \t loss: 0.120 \t return: 113.624 \t ep_len: 1000.000 \t critic_loss: 251.840 \t adv: 0.149\n",
      "epoch: 256 \t loss: 0.054 \t return: 124.517 \t ep_len: 1000.000 \t critic_loss: 241.440 \t adv: 0.083\n",
      "epoch: 257 \t loss: 0.175 \t return: 84.518 \t ep_len: 1000.000 \t critic_loss: 334.299 \t adv: 0.202\n",
      "epoch: 258 \t loss: 0.021 \t return: 117.188 \t ep_len: 1000.000 \t critic_loss: 276.569 \t adv: 0.035\n",
      "epoch: 259 \t loss: -0.842 \t return: -38.327 \t ep_len: 285.000 \t critic_loss: 572.572 \t adv: -0.848\n",
      "epoch: 260 \t loss: -0.272 \t return: 138.317 \t ep_len: 719.000 \t critic_loss: 1294.877 \t adv: 0.061\n",
      "epoch: 261 \t loss: -0.090 \t return: 49.326 \t ep_len: 636.500 \t critic_loss: 418.022 \t adv: -0.096\n",
      "epoch: 262 \t loss: -0.066 \t return: 100.783 \t ep_len: 1000.000 \t critic_loss: 197.575 \t adv: -0.067\n",
      "epoch: 263 \t loss: -0.103 \t return: 74.015 \t ep_len: 1000.000 \t critic_loss: 400.993 \t adv: -0.079\n",
      "epoch: 264 \t loss: 0.024 \t return: 96.745 \t ep_len: 1000.000 \t critic_loss: 189.829 \t adv: 0.020\n",
      "epoch: 265 \t loss: -0.022 \t return: 121.828 \t ep_len: 1000.000 \t critic_loss: 299.227 \t adv: -0.014\n",
      "epoch: 266 \t loss: 0.074 \t return: 130.636 \t ep_len: 1000.000 \t critic_loss: 236.099 \t adv: 0.119\n",
      "epoch: 267 \t loss: 0.023 \t return: 93.996 \t ep_len: 1000.000 \t critic_loss: 367.604 \t adv: 0.015\n",
      "epoch: 268 \t loss: 0.028 \t return: 97.792 \t ep_len: 1000.000 \t critic_loss: 357.779 \t adv: 0.030\n",
      "epoch: 269 \t loss: 0.165 \t return: 108.789 \t ep_len: 1000.000 \t critic_loss: 195.729 \t adv: 0.198\n",
      "epoch: 270 \t loss: 0.070 \t return: 102.986 \t ep_len: 1000.000 \t critic_loss: 480.062 \t adv: 0.109\n",
      "epoch: 271 \t loss: 0.050 \t return: 125.624 \t ep_len: 1000.000 \t critic_loss: 239.813 \t adv: 0.089\n",
      "epoch: 272 \t loss: 0.045 \t return: 90.693 \t ep_len: 1000.000 \t critic_loss: 240.893 \t adv: 0.053\n",
      "epoch: 273 \t loss: 0.143 \t return: 148.639 \t ep_len: 1000.000 \t critic_loss: 205.044 \t adv: 0.158\n",
      "epoch: 274 \t loss: 0.051 \t return: 92.408 \t ep_len: 1000.000 \t critic_loss: 220.405 \t adv: 0.059\n",
      "epoch: 275 \t loss: -0.076 \t return: 57.678 \t ep_len: 1000.000 \t critic_loss: 165.836 \t adv: -0.053\n",
      "epoch: 276 \t loss: 0.144 \t return: 100.296 \t ep_len: 1000.000 \t critic_loss: 195.523 \t adv: 0.158\n",
      "epoch: 277 \t loss: 0.062 \t return: 87.383 \t ep_len: 1000.000 \t critic_loss: 237.046 \t adv: 0.082\n",
      "epoch: 278 \t loss: 0.099 \t return: 140.131 \t ep_len: 1000.000 \t critic_loss: 144.691 \t adv: 0.116\n",
      "epoch: 279 \t loss: 0.193 \t return: 168.977 \t ep_len: 1000.000 \t critic_loss: 332.135 \t adv: 0.254\n",
      "epoch: 280 \t loss: 0.046 \t return: 123.104 \t ep_len: 1000.000 \t critic_loss: 117.542 \t adv: 0.050\n",
      "epoch: 281 \t loss: 0.064 \t return: 128.391 \t ep_len: 1000.000 \t critic_loss: 99.191 \t adv: 0.085\n",
      "epoch: 282 \t loss: 0.048 \t return: 145.837 \t ep_len: 1000.000 \t critic_loss: 134.465 \t adv: 0.065\n",
      "epoch: 283 \t loss: 0.078 \t return: 110.929 \t ep_len: 1000.000 \t critic_loss: 84.141 \t adv: 0.082\n",
      "epoch: 284 \t loss: 0.085 \t return: 141.627 \t ep_len: 1000.000 \t critic_loss: 82.066 \t adv: 0.094\n",
      "epoch: 285 \t loss: -0.066 \t return: 148.565 \t ep_len: 1000.000 \t critic_loss: 66.408 \t adv: -0.079\n",
      "epoch: 286 \t loss: -0.052 \t return: 131.158 \t ep_len: 1000.000 \t critic_loss: 97.417 \t adv: -0.049\n",
      "epoch: 287 \t loss: -0.295 \t return: 193.735 \t ep_len: 664.500 \t critic_loss: 1251.079 \t adv: -0.245\n",
      "epoch: 288 \t loss: -0.004 \t return: 157.286 \t ep_len: 1000.000 \t critic_loss: 180.401 \t adv: 0.007\n",
      "epoch: 289 \t loss: 0.040 \t return: 127.204 \t ep_len: 1000.000 \t critic_loss: 69.591 \t adv: 0.045\n",
      "epoch: 290 \t loss: -0.007 \t return: 131.496 \t ep_len: 1000.000 \t critic_loss: 102.353 \t adv: -0.011\n",
      "epoch: 291 \t loss: -0.473 \t return: 61.006 \t ep_len: 470.333 \t critic_loss: 1232.929 \t adv: -0.466\n",
      "epoch: 292 \t loss: 0.021 \t return: 119.626 \t ep_len: 1000.000 \t critic_loss: 95.714 \t adv: 0.037\n",
      "epoch: 293 \t loss: -1.553 \t return: 28.933 \t ep_len: 190.000 \t critic_loss: 1336.941 \t adv: -1.469\n",
      "epoch: 294 \t loss: 0.129 \t return: 133.755 \t ep_len: 1000.000 \t critic_loss: 146.005 \t adv: 0.150\n",
      "epoch: 295 \t loss: -0.363 \t return: 53.993 \t ep_len: 632.500 \t critic_loss: 682.326 \t adv: -0.352\n",
      "epoch: 296 \t loss: 0.115 \t return: 92.719 \t ep_len: 1000.000 \t critic_loss: 119.486 \t adv: 0.133\n",
      "epoch: 297 \t loss: 0.225 \t return: 77.306 \t ep_len: 1000.000 \t critic_loss: 145.447 \t adv: 0.212\n",
      "epoch: 298 \t loss: 0.127 \t return: 45.018 \t ep_len: 1000.000 \t critic_loss: 163.819 \t adv: 0.136\n",
      "epoch: 299 \t loss: 0.172 \t return: 88.238 \t ep_len: 1000.000 \t critic_loss: 202.344 \t adv: 0.199\n",
      "epoch: 300 \t loss: 0.154 \t return: 83.137 \t ep_len: 1000.000 \t critic_loss: 255.956 \t adv: 0.181\n",
      "epoch: 301 \t loss: -0.189 \t return: 41.030 \t ep_len: 658.500 \t critic_loss: 532.244 \t adv: -0.165\n",
      "epoch: 302 \t loss: -0.963 \t return: -21.765 \t ep_len: 319.000 \t critic_loss: 755.185 \t adv: -0.931\n",
      "epoch: 303 \t loss: 0.115 \t return: 103.636 \t ep_len: 1000.000 \t critic_loss: 186.552 \t adv: 0.140\n",
      "epoch: 304 \t loss: -0.212 \t return: 7.020 \t ep_len: 718.000 \t critic_loss: 636.892 \t adv: -0.194\n",
      "epoch: 305 \t loss: -0.460 \t return: 246.130 \t ep_len: 543.000 \t critic_loss: 911.084 \t adv: -0.277\n",
      "epoch: 306 \t loss: -0.124 \t return: 204.049 \t ep_len: 632.000 \t critic_loss: 706.909 \t adv: -0.015\n",
      "epoch: 307 \t loss: -0.737 \t return: -7.332 \t ep_len: 327.000 \t critic_loss: 597.988 \t adv: -0.711\n",
      "epoch: 308 \t loss: -0.086 \t return: 155.052 \t ep_len: 672.500 \t critic_loss: 957.664 \t adv: -0.005\n",
      "epoch: 309 \t loss: -0.562 \t return: -18.881 \t ep_len: 307.000 \t critic_loss: 458.088 \t adv: -0.591\n",
      "epoch: 310 \t loss: -0.277 \t return: 17.899 \t ep_len: 621.000 \t critic_loss: 1182.143 \t adv: -0.134\n",
      "epoch: 311 \t loss: -0.441 \t return: 241.968 \t ep_len: 456.500 \t critic_loss: 1265.878 \t adv: -0.203\n",
      "epoch: 312 \t loss: -0.444 \t return: 206.586 \t ep_len: 427.500 \t critic_loss: 1363.304 \t adv: -0.173\n",
      "epoch: 313 \t loss: -0.127 \t return: 144.389 \t ep_len: 577.000 \t critic_loss: 611.860 \t adv: 0.023\n",
      "epoch: 314 \t loss: 0.033 \t return: 25.815 \t ep_len: 1000.000 \t critic_loss: 626.280 \t adv: 0.040\n",
      "epoch: 315 \t loss: 0.084 \t return: 63.659 \t ep_len: 1000.000 \t critic_loss: 677.182 \t adv: 0.058\n",
      "epoch: 316 \t loss: 0.076 \t return: 61.119 \t ep_len: 1000.000 \t critic_loss: 606.991 \t adv: 0.018\n",
      "epoch: 317 \t loss: -0.042 \t return: 186.999 \t ep_len: 839.000 \t critic_loss: 701.301 \t adv: -0.008\n",
      "epoch: 318 \t loss: -0.139 \t return: 234.291 \t ep_len: 732.000 \t critic_loss: 712.124 \t adv: -0.009\n",
      "epoch: 319 \t loss: 0.196 \t return: 50.189 \t ep_len: 1000.000 \t critic_loss: 676.048 \t adv: 0.052\n",
      "epoch: 320 \t loss: -0.111 \t return: 110.514 \t ep_len: 969.000 \t critic_loss: 1026.732 \t adv: 0.026\n",
      "epoch: 321 \t loss: -0.207 \t return: 184.227 \t ep_len: 722.000 \t critic_loss: 821.261 \t adv: -0.046\n",
      "epoch: 322 \t loss: -0.025 \t return: 134.598 \t ep_len: 731.000 \t critic_loss: 1289.408 \t adv: 0.024\n",
      "epoch: 323 \t loss: 0.163 \t return: 53.897 \t ep_len: 1000.000 \t critic_loss: 713.314 \t adv: 0.026\n",
      "epoch: 324 \t loss: -0.120 \t return: 204.597 \t ep_len: 668.000 \t critic_loss: 700.932 \t adv: 0.010\n",
      "epoch: 325 \t loss: -0.185 \t return: 235.586 \t ep_len: 736.000 \t critic_loss: 848.729 \t adv: -0.078\n",
      "epoch: 326 \t loss: 0.078 \t return: -55.772 \t ep_len: 567.000 \t critic_loss: 369.127 \t adv: -0.008\n",
      "epoch: 327 \t loss: -0.172 \t return: 123.810 \t ep_len: 687.000 \t critic_loss: 665.627 \t adv: -0.002\n",
      "epoch: 328 \t loss: -0.007 \t return: 192.333 \t ep_len: 792.000 \t critic_loss: 800.709 \t adv: 0.037\n",
      "epoch: 329 \t loss: 0.180 \t return: 40.448 \t ep_len: 1000.000 \t critic_loss: 708.194 \t adv: 0.070\n",
      "epoch: 330 \t loss: -0.096 \t return: 213.408 \t ep_len: 666.000 \t critic_loss: 680.832 \t adv: 0.023\n",
      "epoch: 331 \t loss: -0.153 \t return: 212.027 \t ep_len: 616.500 \t critic_loss: 1378.064 \t adv: -0.027\n",
      "epoch: 332 \t loss: -0.015 \t return: 210.404 \t ep_len: 671.500 \t critic_loss: 1368.840 \t adv: 0.015\n",
      "epoch: 333 \t loss: -0.051 \t return: 162.326 \t ep_len: 912.000 \t critic_loss: 754.812 \t adv: 0.030\n",
      "epoch: 334 \t loss: 0.141 \t return: 42.926 \t ep_len: 1000.000 \t critic_loss: 706.063 \t adv: 0.037\n",
      "epoch: 335 \t loss: 0.138 \t return: 65.657 \t ep_len: 1000.000 \t critic_loss: 732.141 \t adv: 0.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 336 \t loss: 0.123 \t return: 116.060 \t ep_len: 1000.000 \t critic_loss: 655.644 \t adv: 0.088\n",
      "epoch: 337 \t loss: 0.082 \t return: 63.566 \t ep_len: 680.500 \t critic_loss: 843.640 \t adv: 0.036\n",
      "epoch: 338 \t loss: -0.132 \t return: 12.089 \t ep_len: 279.000 \t critic_loss: 313.411 \t adv: -0.175\n",
      "epoch: 339 \t loss: 0.122 \t return: 109.766 \t ep_len: 1000.000 \t critic_loss: 604.513 \t adv: 0.149\n",
      "epoch: 340 \t loss: -0.297 \t return: 18.549 \t ep_len: 356.500 \t critic_loss: 384.122 \t adv: -0.313\n",
      "epoch: 341 \t loss: -0.295 \t return: -13.280 \t ep_len: 322.000 \t critic_loss: 312.264 \t adv: -0.289\n",
      "epoch: 342 \t loss: -0.462 \t return: 76.312 \t ep_len: 324.500 \t critic_loss: 790.728 \t adv: -0.304\n",
      "epoch: 343 \t loss: -0.040 \t return: 204.147 \t ep_len: 665.000 \t critic_loss: 1650.826 \t adv: 0.252\n",
      "epoch: 344 \t loss: 0.289 \t return: 99.093 \t ep_len: 1000.000 \t critic_loss: 440.680 \t adv: 0.317\n",
      "epoch: 345 \t loss: 0.273 \t return: 158.253 \t ep_len: 1000.000 \t critic_loss: 436.425 \t adv: 0.323\n",
      "epoch: 346 \t loss: 0.028 \t return: 172.274 \t ep_len: 708.500 \t critic_loss: 1295.386 \t adv: 0.177\n",
      "epoch: 347 \t loss: 0.039 \t return: 154.771 \t ep_len: 714.000 \t critic_loss: 1292.363 \t adv: 0.145\n",
      "epoch: 348 \t loss: -0.486 \t return: 126.759 \t ep_len: 346.500 \t critic_loss: 866.563 \t adv: -0.298\n",
      "epoch: 349 \t loss: 0.016 \t return: 152.521 \t ep_len: 692.000 \t critic_loss: 942.638 \t adv: 0.092\n",
      "epoch: 350 \t loss: 0.083 \t return: 107.844 \t ep_len: 1000.000 \t critic_loss: 396.077 \t adv: 0.087\n",
      "epoch: 351 \t loss: 0.096 \t return: 116.648 \t ep_len: 1000.000 \t critic_loss: 459.620 \t adv: 0.086\n",
      "epoch: 352 \t loss: -0.134 \t return: 60.474 \t ep_len: 645.000 \t critic_loss: 642.259 \t adv: -0.148\n",
      "epoch: 353 \t loss: -0.013 \t return: 93.194 \t ep_len: 1000.000 \t critic_loss: 454.934 \t adv: -0.040\n",
      "epoch: 354 \t loss: 0.098 \t return: 111.623 \t ep_len: 1000.000 \t critic_loss: 315.963 \t adv: 0.035\n",
      "epoch: 355 \t loss: 0.039 \t return: 130.128 \t ep_len: 1000.000 \t critic_loss: 348.000 \t adv: 0.032\n",
      "epoch: 356 \t loss: 0.106 \t return: 155.716 \t ep_len: 1000.000 \t critic_loss: 346.590 \t adv: 0.118\n",
      "epoch: 357 \t loss: 0.086 \t return: 127.353 \t ep_len: 1000.000 \t critic_loss: 213.212 \t adv: 0.075\n",
      "epoch: 358 \t loss: 0.196 \t return: 148.382 \t ep_len: 1000.000 \t critic_loss: 251.121 \t adv: 0.215\n",
      "epoch: 359 \t loss: 0.273 \t return: 139.381 \t ep_len: 1000.000 \t critic_loss: 276.177 \t adv: 0.302\n",
      "epoch: 360 \t loss: 0.180 \t return: 136.450 \t ep_len: 1000.000 \t critic_loss: 227.725 \t adv: 0.215\n",
      "epoch: 361 \t loss: 0.220 \t return: 138.568 \t ep_len: 1000.000 \t critic_loss: 194.922 \t adv: 0.272\n",
      "epoch: 362 \t loss: 0.145 \t return: 139.985 \t ep_len: 1000.000 \t critic_loss: 157.139 \t adv: 0.182\n",
      "epoch: 363 \t loss: 0.146 \t return: 151.887 \t ep_len: 1000.000 \t critic_loss: 199.981 \t adv: 0.179\n",
      "epoch: 364 \t loss: 0.065 \t return: 120.841 \t ep_len: 1000.000 \t critic_loss: 145.167 \t adv: 0.083\n",
      "epoch: 365 \t loss: -0.219 \t return: 76.693 \t ep_len: 642.500 \t critic_loss: 637.836 \t adv: -0.210\n",
      "epoch: 366 \t loss: 0.009 \t return: 134.074 \t ep_len: 1000.000 \t critic_loss: 62.561 \t adv: 0.015\n",
      "epoch: 367 \t loss: -0.011 \t return: 85.307 \t ep_len: 1000.000 \t critic_loss: 117.406 \t adv: 0.010\n",
      "epoch: 368 \t loss: 0.009 \t return: 113.160 \t ep_len: 1000.000 \t critic_loss: 109.078 \t adv: 0.021\n",
      "epoch: 369 \t loss: -0.260 \t return: 219.646 \t ep_len: 902.000 \t critic_loss: 643.970 \t adv: -0.101\n",
      "epoch: 370 \t loss: -0.386 \t return: 66.333 \t ep_len: 634.000 \t critic_loss: 848.633 \t adv: -0.421\n",
      "epoch: 371 \t loss: -0.037 \t return: 75.476 \t ep_len: 1000.000 \t critic_loss: 89.486 \t adv: -0.049\n",
      "epoch: 372 \t loss: -1.201 \t return: 82.833 \t ep_len: 345.000 \t critic_loss: 2138.443 \t adv: -1.058\n",
      "epoch: 373 \t loss: -0.277 \t return: 177.855 \t ep_len: 695.000 \t critic_loss: 1257.659 \t adv: -0.249\n",
      "epoch: 374 \t loss: -1.068 \t return: 61.051 \t ep_len: 364.500 \t critic_loss: 1746.734 \t adv: -0.904\n",
      "epoch: 375 \t loss: 0.078 \t return: 92.507 \t ep_len: 1000.000 \t critic_loss: 151.743 \t adv: 0.093\n",
      "epoch: 376 \t loss: -0.759 \t return: 202.179 \t ep_len: 403.000 \t critic_loss: 2071.181 \t adv: -0.486\n",
      "epoch: 377 \t loss: -0.120 \t return: 171.028 \t ep_len: 701.500 \t critic_loss: 1564.196 \t adv: 0.062\n",
      "epoch: 378 \t loss: 0.065 \t return: 70.577 \t ep_len: 1000.000 \t critic_loss: 573.679 \t adv: 0.092\n",
      "epoch: 379 \t loss: 0.015 \t return: 212.415 \t ep_len: 954.000 \t critic_loss: 817.479 \t adv: 0.187\n",
      "epoch: 380 \t loss: -0.129 \t return: 168.446 \t ep_len: 782.000 \t critic_loss: 902.359 \t adv: 0.007\n",
      "epoch: 381 \t loss: -0.541 \t return: 219.917 \t ep_len: 616.000 \t critic_loss: 1038.961 \t adv: -0.188\n",
      "epoch: 382 \t loss: -0.448 \t return: 159.522 \t ep_len: 552.000 \t critic_loss: 775.379 \t adv: -0.101\n",
      "epoch: 383 \t loss: -0.297 \t return: 44.724 \t ep_len: 392.000 \t critic_loss: 862.012 \t adv: -0.131\n",
      "epoch: 384 \t loss: -0.421 \t return: 151.917 \t ep_len: 604.000 \t critic_loss: 708.449 \t adv: -0.062\n",
      "epoch: 385 \t loss: -0.065 \t return: -112.456 \t ep_len: 522.000 \t critic_loss: 834.926 \t adv: -0.083\n",
      "epoch: 386 \t loss: -0.006 \t return: -43.084 \t ep_len: 476.500 \t critic_loss: 734.251 \t adv: -0.039\n",
      "epoch: 387 \t loss: 0.075 \t return: -150.170 \t ep_len: 647.000 \t critic_loss: 550.715 \t adv: 0.005\n",
      "epoch: 388 \t loss: -0.135 \t return: 118.556 \t ep_len: 884.000 \t critic_loss: 943.582 \t adv: 0.071\n",
      "epoch: 389 \t loss: 0.095 \t return: 92.469 \t ep_len: 1000.000 \t critic_loss: 916.871 \t adv: 0.075\n",
      "epoch: 390 \t loss: 0.053 \t return: -130.099 \t ep_len: 969.000 \t critic_loss: 856.229 \t adv: 0.065\n",
      "epoch: 391 \t loss: 0.024 \t return: -32.343 \t ep_len: 1000.000 \t critic_loss: 1018.502 \t adv: 0.056\n",
      "epoch: 392 \t loss: -0.003 \t return: -61.217 \t ep_len: 1000.000 \t critic_loss: 884.961 \t adv: 0.070\n",
      "epoch: 393 \t loss: -0.060 \t return: 17.524 \t ep_len: 1000.000 \t critic_loss: 849.274 \t adv: 0.054\n",
      "epoch: 394 \t loss: -0.001 \t return: -18.928 \t ep_len: 1000.000 \t critic_loss: 884.445 \t adv: 0.011\n",
      "epoch: 395 \t loss: -0.022 \t return: -48.312 \t ep_len: 1000.000 \t critic_loss: 834.553 \t adv: 0.040\n",
      "epoch: 396 \t loss: -0.081 \t return: -58.038 \t ep_len: 1000.000 \t critic_loss: 934.697 \t adv: -0.023\n",
      "epoch: 397 \t loss: -0.095 \t return: -10.358 \t ep_len: 1000.000 \t critic_loss: 915.927 \t adv: 0.013\n",
      "epoch: 398 \t loss: -0.021 \t return: 32.659 \t ep_len: 1000.000 \t critic_loss: 857.626 \t adv: -0.007\n",
      "epoch: 399 \t loss: -0.058 \t return: 51.693 \t ep_len: 1000.000 \t critic_loss: 970.772 \t adv: -0.029\n",
      "epoch: 400 \t loss: 0.029 \t return: 95.647 \t ep_len: 1000.000 \t critic_loss: 739.107 \t adv: 0.068\n",
      "epoch: 401 \t loss: 0.040 \t return: 67.997 \t ep_len: 1000.000 \t critic_loss: 869.542 \t adv: 0.014\n",
      "epoch: 402 \t loss: 0.021 \t return: 19.689 \t ep_len: 743.000 \t critic_loss: 1117.765 \t adv: 0.017\n",
      "epoch: 403 \t loss: 0.023 \t return: 138.260 \t ep_len: 1000.000 \t critic_loss: 658.508 \t adv: 0.040\n",
      "epoch: 404 \t loss: -0.001 \t return: 186.841 \t ep_len: 627.500 \t critic_loss: 799.510 \t adv: 0.017\n",
      "epoch: 405 \t loss: 0.034 \t return: 151.962 \t ep_len: 705.500 \t critic_loss: 1240.140 \t adv: 0.134\n",
      "epoch: 406 \t loss: 0.113 \t return: 55.522 \t ep_len: 687.000 \t critic_loss: 670.609 \t adv: 0.097\n",
      "epoch: 407 \t loss: 0.014 \t return: 166.834 \t ep_len: 682.000 \t critic_loss: 1232.829 \t adv: 0.187\n",
      "epoch: 408 \t loss: -0.351 \t return: -6.844 \t ep_len: 276.500 \t critic_loss: 271.087 \t adv: -0.370\n",
      "epoch: 409 \t loss: -0.423 \t return: 113.410 \t ep_len: 330.000 \t critic_loss: 896.864 \t adv: -0.210\n",
      "epoch: 410 \t loss: 0.285 \t return: 67.371 \t ep_len: 1000.000 \t critic_loss: 366.932 \t adv: 0.326\n",
      "epoch: 411 \t loss: -0.688 \t return: 102.668 \t ep_len: 303.000 \t critic_loss: 987.925 \t adv: -0.438\n",
      "epoch: 412 \t loss: -0.447 \t return: -13.332 \t ep_len: 240.667 \t critic_loss: 435.384 \t adv: -0.566\n",
      "epoch: 413 \t loss: -0.575 \t return: 59.069 \t ep_len: 308.000 \t critic_loss: 882.095 \t adv: -0.338\n",
      "epoch: 414 \t loss: 0.189 \t return: 129.725 \t ep_len: 1000.000 \t critic_loss: 230.323 \t adv: 0.200\n",
      "epoch: 415 \t loss: -0.366 \t return: -34.775 \t ep_len: 300.500 \t critic_loss: 255.815 \t adv: -0.415\n",
      "epoch: 416 \t loss: 0.303 \t return: 92.515 \t ep_len: 1000.000 \t critic_loss: 407.644 \t adv: 0.349\n",
      "epoch: 417 \t loss: 0.232 \t return: 106.226 \t ep_len: 1000.000 \t critic_loss: 329.469 \t adv: 0.276\n",
      "epoch: 418 \t loss: 0.253 \t return: 116.601 \t ep_len: 1000.000 \t critic_loss: 532.739 \t adv: 0.342\n",
      "epoch: 419 \t loss: 0.037 \t return: 43.822 \t ep_len: 625.500 \t critic_loss: 414.537 \t adv: 0.046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 420 \t loss: -0.547 \t return: 81.118 \t ep_len: 321.500 \t critic_loss: 797.904 \t adv: -0.367\n",
      "epoch: 421 \t loss: 0.196 \t return: 137.674 \t ep_len: 1000.000 \t critic_loss: 419.311 \t adv: 0.254\n",
      "epoch: 422 \t loss: 0.052 \t return: 44.070 \t ep_len: 632.500 \t critic_loss: 397.596 \t adv: 0.049\n",
      "epoch: 423 \t loss: 0.032 \t return: 116.172 \t ep_len: 1000.000 \t critic_loss: 336.798 \t adv: 0.048\n",
      "epoch: 424 \t loss: -0.370 \t return: 68.344 \t ep_len: 408.000 \t critic_loss: 916.248 \t adv: -0.247\n",
      "epoch: 425 \t loss: -0.521 \t return: 96.524 \t ep_len: 287.500 \t critic_loss: 717.796 \t adv: -0.396\n",
      "epoch: 426 \t loss: 0.139 \t return: 79.101 \t ep_len: 1000.000 \t critic_loss: 288.163 \t adv: 0.112\n",
      "epoch: 427 \t loss: -0.556 \t return: 34.949 \t ep_len: 226.667 \t critic_loss: 581.520 \t adv: -0.545\n",
      "epoch: 428 \t loss: 0.043 \t return: 190.265 \t ep_len: 1000.000 \t critic_loss: 388.900 \t adv: 0.078\n",
      "epoch: 429 \t loss: -0.392 \t return: 67.949 \t ep_len: 268.667 \t critic_loss: 649.097 \t adv: -0.410\n",
      "epoch: 430 \t loss: 0.111 \t return: 86.257 \t ep_len: 1000.000 \t critic_loss: 369.581 \t adv: 0.156\n",
      "epoch: 431 \t loss: -0.519 \t return: 100.143 \t ep_len: 263.500 \t critic_loss: 616.375 \t adv: -0.386\n",
      "epoch: 432 \t loss: -0.209 \t return: 62.547 \t ep_len: 342.333 \t critic_loss: 789.663 \t adv: -0.133\n",
      "epoch: 433 \t loss: -0.339 \t return: -9.881 \t ep_len: 221.333 \t critic_loss: 227.212 \t adv: -0.384\n",
      "epoch: 434 \t loss: 0.148 \t return: 48.238 \t ep_len: 603.500 \t critic_loss: 463.039 \t adv: 0.169\n",
      "epoch: 435 \t loss: 0.108 \t return: 133.159 \t ep_len: 657.500 \t critic_loss: 1060.935 \t adv: 0.267\n",
      "epoch: 436 \t loss: 0.220 \t return: 107.486 \t ep_len: 484.667 \t critic_loss: 991.362 \t adv: 0.325\n",
      "epoch: 437 \t loss: -0.418 \t return: 210.678 \t ep_len: 263.500 \t critic_loss: 803.873 \t adv: -0.220\n",
      "epoch: 438 \t loss: -0.428 \t return: 236.400 \t ep_len: 293.000 \t critic_loss: 800.615 \t adv: -0.228\n",
      "epoch: 439 \t loss: 0.069 \t return: 20.058 \t ep_len: 483.667 \t critic_loss: 724.864 \t adv: 0.051\n",
      "epoch: 440 \t loss: 0.185 \t return: 65.290 \t ep_len: 1000.000 \t critic_loss: 537.868 \t adv: 0.201\n",
      "epoch: 441 \t loss: 0.294 \t return: 165.008 \t ep_len: 921.000 \t critic_loss: 1054.090 \t adv: 0.453\n",
      "epoch: 442 \t loss: -0.170 \t return: 117.131 \t ep_len: 252.333 \t critic_loss: 902.383 \t adv: -0.223\n",
      "epoch: 443 \t loss: 0.085 \t return: -11.790 \t ep_len: 492.000 \t critic_loss: 728.282 \t adv: 0.065\n",
      "epoch: 444 \t loss: -0.162 \t return: -43.270 \t ep_len: 215.667 \t critic_loss: 245.140 \t adv: -0.260\n",
      "epoch: 445 \t loss: -0.364 \t return: -25.122 \t ep_len: 213.333 \t critic_loss: 312.665 \t adv: -0.458\n",
      "epoch: 446 \t loss: 0.203 \t return: 5.679 \t ep_len: 1000.000 \t critic_loss: 631.675 \t adv: 0.244\n",
      "epoch: 447 \t loss: -0.301 \t return: -26.044 \t ep_len: 175.000 \t critic_loss: 308.420 \t adv: -0.467\n",
      "epoch: 448 \t loss: -0.238 \t return: -64.847 \t ep_len: 194.333 \t critic_loss: 297.827 \t adv: -0.403\n",
      "epoch: 449 \t loss: -0.201 \t return: 40.136 \t ep_len: 234.333 \t critic_loss: 643.409 \t adv: -0.366\n",
      "epoch: 450 \t loss: -0.308 \t return: 215.220 \t ep_len: 323.500 \t critic_loss: 659.806 \t adv: -0.211\n",
      "epoch: 451 \t loss: -0.020 \t return: 176.194 \t ep_len: 525.000 \t critic_loss: 484.019 \t adv: 0.069\n",
      "epoch: 452 \t loss: -0.073 \t return: 24.514 \t ep_len: 387.000 \t critic_loss: 544.742 \t adv: -0.022\n",
      "epoch: 453 \t loss: -0.101 \t return: -49.169 \t ep_len: 413.000 \t critic_loss: 485.878 \t adv: -0.142\n",
      "epoch: 454 \t loss: -0.114 \t return: -16.310 \t ep_len: 184.667 \t critic_loss: 249.202 \t adv: -0.199\n",
      "epoch: 455 \t loss: -0.106 \t return: 24.524 \t ep_len: 335.500 \t critic_loss: 518.462 \t adv: 0.064\n",
      "epoch: 456 \t loss: 0.002 \t return: 72.551 \t ep_len: 1000.000 \t critic_loss: 624.237 \t adv: 0.069\n",
      "epoch: 457 \t loss: -0.036 \t return: -99.968 \t ep_len: 252.500 \t critic_loss: 181.800 \t adv: -0.001\n",
      "epoch: 458 \t loss: 0.206 \t return: -110.606 \t ep_len: 351.500 \t critic_loss: 392.403 \t adv: 0.208\n",
      "epoch: 459 \t loss: 0.202 \t return: -138.275 \t ep_len: 395.500 \t critic_loss: 458.918 \t adv: 0.251\n",
      "epoch: 460 \t loss: -0.070 \t return: -67.735 \t ep_len: 184.333 \t critic_loss: 276.581 \t adv: -0.030\n",
      "epoch: 461 \t loss: 0.149 \t return: -148.662 \t ep_len: 421.000 \t critic_loss: 416.644 \t adv: 0.124\n",
      "epoch: 462 \t loss: 0.412 \t return: -107.477 \t ep_len: 1000.000 \t critic_loss: 843.219 \t adv: 0.473\n",
      "epoch: 463 \t loss: -0.108 \t return: 38.604 \t ep_len: 302.500 \t critic_loss: 453.844 \t adv: 0.013\n",
      "epoch: 464 \t loss: 0.224 \t return: -83.986 \t ep_len: 683.000 \t critic_loss: 730.572 \t adv: 0.247\n",
      "epoch: 465 \t loss: 0.220 \t return: -18.041 \t ep_len: 553.500 \t critic_loss: 826.511 \t adv: 0.224\n",
      "epoch: 466 \t loss: 0.237 \t return: -61.899 \t ep_len: 1000.000 \t critic_loss: 780.943 \t adv: 0.312\n",
      "epoch: 467 \t loss: -0.399 \t return: 34.461 \t ep_len: 335.500 \t critic_loss: 677.760 \t adv: -0.254\n",
      "epoch: 468 \t loss: 0.066 \t return: -33.200 \t ep_len: 1000.000 \t critic_loss: 638.033 \t adv: 0.138\n",
      "epoch: 469 \t loss: 0.194 \t return: -170.995 \t ep_len: 921.000 \t critic_loss: 704.999 \t adv: 0.169\n",
      "epoch: 470 \t loss: -0.337 \t return: 44.750 \t ep_len: 408.500 \t critic_loss: 509.728 \t adv: -0.257\n",
      "epoch: 471 \t loss: -0.409 \t return: 175.283 \t ep_len: 527.000 \t critic_loss: 647.795 \t adv: -0.360\n",
      "epoch: 472 \t loss: -0.096 \t return: 27.439 \t ep_len: 1000.000 \t critic_loss: 520.739 \t adv: -0.019\n",
      "epoch: 473 \t loss: -0.160 \t return: -65.705 \t ep_len: 608.000 \t critic_loss: 902.067 \t adv: -0.152\n",
      "epoch: 474 \t loss: -0.310 \t return: 76.855 \t ep_len: 694.000 \t critic_loss: 784.516 \t adv: -0.091\n",
      "epoch: 475 \t loss: -0.396 \t return: -77.281 \t ep_len: 281.500 \t critic_loss: 295.889 \t adv: -0.425\n",
      "epoch: 476 \t loss: -0.252 \t return: 117.521 \t ep_len: 565.000 \t critic_loss: 614.477 \t adv: -0.137\n",
      "epoch: 477 \t loss: -0.173 \t return: 62.511 \t ep_len: 1000.000 \t critic_loss: 572.556 \t adv: -0.159\n",
      "epoch: 478 \t loss: -0.241 \t return: 41.246 \t ep_len: 435.000 \t critic_loss: 523.874 \t adv: -0.149\n",
      "epoch: 479 \t loss: -0.498 \t return: 45.869 \t ep_len: 265.667 \t critic_loss: 905.109 \t adv: -0.487\n",
      "epoch: 480 \t loss: -0.100 \t return: 76.330 \t ep_len: 703.000 \t critic_loss: 1309.745 \t adv: -0.142\n",
      "epoch: 481 \t loss: -0.145 \t return: -85.533 \t ep_len: 388.000 \t critic_loss: 361.693 \t adv: -0.205\n",
      "epoch: 482 \t loss: -0.115 \t return: 122.751 \t ep_len: 1000.000 \t critic_loss: 757.111 \t adv: -0.139\n",
      "epoch: 483 \t loss: -0.173 \t return: 234.299 \t ep_len: 355.500 \t critic_loss: 638.417 \t adv: -0.268\n",
      "epoch: 484 \t loss: 0.077 \t return: -63.407 \t ep_len: 432.500 \t critic_loss: 454.542 \t adv: 0.003\n",
      "epoch: 485 \t loss: -0.325 \t return: 166.561 \t ep_len: 572.000 \t critic_loss: 473.213 \t adv: -0.042\n",
      "epoch: 486 \t loss: -0.356 \t return: 188.463 \t ep_len: 513.000 \t critic_loss: 586.549 \t adv: 0.059\n",
      "epoch: 487 \t loss: 0.001 \t return: 125.575 \t ep_len: 721.000 \t critic_loss: 1303.932 \t adv: 0.091\n",
      "epoch: 488 \t loss: 0.005 \t return: -33.077 \t ep_len: 336.000 \t critic_loss: 341.672 \t adv: -0.001\n",
      "epoch: 489 \t loss: 0.213 \t return: -13.522 \t ep_len: 722.500 \t critic_loss: 983.096 \t adv: 0.182\n",
      "epoch: 490 \t loss: 0.136 \t return: -70.616 \t ep_len: 485.500 \t critic_loss: 602.006 \t adv: 0.085\n",
      "epoch: 491 \t loss: -0.005 \t return: 68.628 \t ep_len: 525.000 \t critic_loss: 789.016 \t adv: 0.019\n",
      "epoch: 492 \t loss: 0.011 \t return: 109.646 \t ep_len: 914.000 \t critic_loss: 940.355 \t adv: 0.196\n",
      "epoch: 493 \t loss: 0.085 \t return: 98.544 \t ep_len: 1000.000 \t critic_loss: 504.702 \t adv: 0.156\n",
      "epoch: 494 \t loss: 0.123 \t return: 111.747 \t ep_len: 1000.000 \t critic_loss: 456.644 \t adv: 0.094\n",
      "epoch: 495 \t loss: -0.351 \t return: 137.111 \t ep_len: 695.000 \t critic_loss: 781.210 \t adv: -0.036\n",
      "epoch: 496 \t loss: 0.013 \t return: -3.711 \t ep_len: 1000.000 \t critic_loss: 522.724 \t adv: 0.062\n",
      "epoch: 497 \t loss: 0.008 \t return: -32.869 \t ep_len: 1000.000 \t critic_loss: 575.896 \t adv: 0.029\n",
      "epoch: 498 \t loss: 0.027 \t return: -15.287 \t ep_len: 1000.000 \t critic_loss: 401.008 \t adv: 0.089\n",
      "epoch: 499 \t loss: 0.048 \t return: -23.344 \t ep_len: 1000.000 \t critic_loss: 428.133 \t adv: 0.109\n",
      "epoch: 500 \t loss: 0.009 \t return: 6.515 \t ep_len: 1000.000 \t critic_loss: 472.437 \t adv: 0.050\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "rew_req = 200\n",
    "i=0\n",
    "mean_rew = 0\n",
    "mean_rew_sum = 0\n",
    "avg_rew = 0\n",
    "\n",
    "while i<500:\n",
    "    i+=1\n",
    "    render = True if i%20==0 else False\n",
    "#     render = False\n",
    "    batch_loss,batch_ret, batch_len, critic_loss,advantage, entropy = train_one_epoch(env, net, critic, cont,batch_size=BATCH_SIZE, render=render)\n",
    "    mean_rew = np.mean(batch_ret) # mean return per episode\n",
    "    mean_rew_sum += mean_rew  # sum of returns of episodes from start\n",
    "    avg_rew = mean_rew_sum/i  # avg reward per episode from start\n",
    "    if render:\n",
    "        env.close()\n",
    "    print('epoch: %3d \\t loss: %.3f \\t return: %.3f \\t ep_len: %.3f \\t critic_loss: %.3f \\t adv: %.3f'%\n",
    "                (i, batch_loss, np.mean(batch_ret), np.mean(batch_len), critic_loss, np.mean(advantage)))\n",
    "    writer.add_scalar(\"loss\", batch_loss, i)\n",
    "    writer.add_scalar(\"reward_mean\", mean_rew, i)\n",
    "    writer.add_scalar('entropy', entropy,i)\n",
    "    writer.add_scalar('advantage',np.mean(advantage),i)\n",
    "    writer.add_scalar('critc_loss',critic_loss,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Categorical(logits = torch.FloatTensor([1,0,1]))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39, 13, 48]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [0,0,0]\n",
    "for i in range(0,100):\n",
    "    x = c.sample().item()\n",
    "    count[x]+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8620)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.log_prob(torch.as_tensor(0, dtype=torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =([2]*8)\n",
    "x = torch.FloatTensor(x)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ([1]*3 + [2]*5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.FloatTensor(x)*torch.FloatTensor(y)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reward_to_go' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-96499174c116>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreward_to_go\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reward_to_go' is not defined"
     ]
    }
   ],
   "source": [
    "reward_to_go([1,0,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([1,0,2,1,0]),np.std([1,0,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GAMMA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ee49a8486149>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_critic_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-53cfcde785c0>\u001b[0m in \u001b[0;36mget_critic_targets\u001b[1;34m(eps_rews)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps_rews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mGAMMA\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0meps_rews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GAMMA' is not defined"
     ]
    }
   ],
   "source": [
    "x = [1,1,0,0,0,1]\n",
    "get_critic_targets(x)\n",
    "y = [5,4]\n",
    "x.extend(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3]\n",
    "y = []\n",
    "y.append(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[4,2,3]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.append(x.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 2, 3]]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 2, 3], [4, 2, 3]]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.3292841e-01,  1.3936392e+38,  2.2844117e-02,  8.5078421e+37],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([79045296309277814133001641918405279744.,\n",
       "         8074543887068950992878338433657864192.], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.FloatTensor(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = Categorical(net(torch.FloatTensor(obs)))\n",
    "c2.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3786, grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.log_prob(torch.as_tensor(1, dtype = torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rew1(ep_rews):\n",
    "    rewards = []\n",
    "    disc_rew = 0\n",
    "    for rew in ep_rews[::-1]:\n",
    "        disc_rew = GAMMA*disc_rew + rew\n",
    "        rewards.append(disc_rew)\n",
    "    rewards = rewards[::-1]\n",
    "    return rewards\n",
    "        \n",
    "def test_rew2(ep_rews):\n",
    "    R = 0\n",
    "    returns = []\n",
    "    eps = 1e-6\n",
    "    for r in ep_rews[::-1]:\n",
    "        # calculate the discounted value\n",
    "        R = r + GAMMA * R\n",
    "        returns.insert(0, R)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.8519850599, 4.90099501, 3.9403989999999998, 2.9701, 1.99, 1.0]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,1,1,1,1,1]\n",
    "test_rew1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.8519850599, 4.90099501, 3.9403989999999998, 2.9701, 1.99, 1.0]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rew2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
